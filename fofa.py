# fofa_bot_v10.9.5.py (allfofa Key ç­‰çº§é™åˆ¶)
#
# v10.9.5 æ›´æ–°æ—¥å¿—:
# 1. ä¼˜åŒ– (/allfofa): `/allfofa` æµ·é‡ä¸‹è½½ä»»åŠ¡ç°åœ¨ä¼šä¼˜å…ˆä½¿ç”¨å¹¶è¦æ±‚è‡³å°‘ä¸ºâ€œä¸ªäººä¼šå‘˜â€ç­‰çº§çš„API Keyã€‚
#    - æ­¤ä¸¾æ—¨åœ¨é¿å…å› ä½¿ç”¨Fç‚¹ä¸è¶³çš„å…è´¹Keyè€Œå¯¼è‡´ä¸‹è½½ä»»åŠ¡ä¸­é€”å¤±è´¥ã€‚
#
# v10.9.4 æ›´æ–°æ—¥å¿—:
# 1. æ ¹æœ¬æ€§ä¿®å¤ (/allfofa): å½»åº•è§£å†³å› ä»£ç†IPå˜åŠ¨å¯¼è‡´çš„ "[820013] è¯·æŒ‰é¡ºåºè¿›è¡Œç¿»é¡µæŸ¥è¯¢" é”™è¯¯ã€‚
#    - `/allfofa` ä»»åŠ¡ç°åœ¨ä¼šâ€œé”å®šâ€ä¸€ä¸ªä»£ç†å’ŒAPI Keyç”¨äºæ•´ä¸ªä¸‹è½½ä¼šè¯ã€‚
#    - ä»é¢„æ£€åˆ°åå°ç¿»é¡µçš„æ‰€æœ‰è¯·æ±‚éƒ½å°†ä½¿ç”¨ç›¸åŒçš„ä»£ç†IPå’ŒKeyï¼Œç¡®ä¿äº†FOFA APIä¼šè¯çš„ç»å¯¹è¿ç»­æ€§ã€‚
# 2. æ ¹æœ¬æ€§ä¿®å¤ (è¿½æº¯æŸ¥è¯¢): å½»åº•è§£å†³å› æƒé™ä¸è¶³å¯¼è‡´çš„ "[820001] æ²¡æœ‰æƒé™æœç´¢lastupdatetimeå­—æ®µ" é”™è¯¯ã€‚
#    - æ·±åº¦è¿½æº¯åŠŸèƒ½ (`/kkfofa` > 1ä¸‡æ¡, `/batch` > 1ä¸‡æ¡) ç°åœ¨ä¼šæ ¹æ®å½“å‰Keyçš„ç­‰çº§åŠ¨æ€å†³å®šæ˜¯å¦è¯·æ±‚ `lastupdatetime` å­—æ®µã€‚
#    - ä½ç­‰çº§Keyå°†è‡ªåŠ¨å›é€€åˆ°ä¸å«æ—¶é—´æˆ³çš„è¿½æº¯æ¨¡å¼ï¼Œé¿å…ä»»åŠ¡å¤±è´¥ã€‚
# 3. å†…éƒ¨é‡æ„: è°ƒæ•´äº†å†…éƒ¨APIè°ƒç”¨å‡½æ•°ï¼Œä½¿å…¶èƒ½å¤Ÿæ„ŸçŸ¥Keyçš„ç­‰çº§å¹¶æ”¯æŒä»£ç†ä¼šè¯é”å®šï¼Œä¸ºä¸Šè¿°ä¿®å¤æä¾›æ”¯æŒã€‚
#
# v10.9.3 æ›´æ–°æ—¥å¿—:
# 1. ä¿®å¤ (/allfofa): è§£å†³äº†å› â€œé¢„æ£€â€å’Œâ€œä¸‹è½½â€æ­¥éª¤çŠ¶æ€ä¸ä¸€è‡´å¯¼è‡´çš„ç¿»é¡µé”™è¯¯ã€‚
#
# è¿è¡Œå‰è¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–:
# pip install pandas openpyxl pysocks "requests[socks]" tqdm "python-telegram-bot"
import os
import sys
import json
import logging
import base64
import time
import re
import requests
import signal
import socket
import hashlib
import shutil
import random
import csv
import asyncio
import pandas as pd
import threading
from functools import wraps
from datetime import datetime, timedelta
from dateutil import tz
from urllib.parse import urlparse

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand, ParseMode
from telegram.ext import (
    Updater,
    CommandHandler,
    CallbackContext,
    ConversationHandler,
    MessageHandler,
    CallbackQueryHandler,
    Filters,
)
from telegram.error import BadRequest, RetryAfter, TimedOut, NetworkError

# --- å…¨å±€å˜é‡å’Œå¸¸é‡ ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
LOG_FILE = 'fofa_bot.log'
FOFA_CACHE_DIR = 'fofa_file'
ANONYMOUS_KEYS_FILE = 'fofa_anonymous.json'
SCAN_TASKS_FILE = 'scan_tasks.json'
MAX_HISTORY_SIZE = 50
MAX_SCAN_TASKS = 50
CACHE_EXPIRATION_SECONDS = 24 * 60 * 60
MAX_BATCH_TARGETS = 10000
FOFA_SEARCH_URL = "https://fofa.info/api/v1/search/all"
FOFA_NEXT_URL = "https://fofa.info/api/v1/search/next"
FOFA_INFO_URL = "https://fofa.info/api/v1/info/my"
FOFA_STATS_URL = "https://fofa.info/api/v1/search/stats"
FOFA_HOST_BASE_URL = "https://fofa.info/api/v1/host/"

# --- å¤§æ´²å›½å®¶ä»£ç  ---
CONTINENT_COUNTRIES = {
    'Asia': ['AF', 'AM', 'AZ', 'BH', 'BD', 'BT', 'BN', 'KH', 'CN', 'CY', 'GE', 'IN', 'ID', 'IR', 'IQ', 'IL', 'JP', 'JO', 'KZ', 'KW', 'KG', 'LA', 'LB', 'MY', 'MV', 'MN', 'MM', 'NP', 'KP', 'OM', 'PK', 'PS', 'PH', 'QA', 'SA', 'SG', 'KR', 'LK', 'SY', 'TW', 'TJ', 'TH', 'TL', 'TR', 'TM', 'AE', 'UZ', 'VN', 'YE'],
    'Europe': ['AL', 'AD', 'AM', 'AT', 'BY', 'BE', 'BA', 'BG', 'HR', 'CY', 'CZ', 'DK', 'EE', 'FO', 'FI', 'FR', 'GE', 'DE', 'GI', 'GR', 'HU', 'IS', 'IE', 'IT', 'KZ', 'LV', 'LI', 'LT', 'LU', 'MK', 'MT', 'MD', 'MC', 'ME', 'NL', 'NO', 'PL', 'PT', 'RO', 'RU', 'SM', 'RS', 'SK', 'SI', 'ES', 'SE', 'CH', 'TR', 'UA', 'GB', 'VA'],
    'NorthAmerica': ['AG', 'BS', 'BB', 'BZ', 'CA', 'CR', 'CU', 'DM', 'DO', 'SV', 'GD', 'GT', 'HT', 'HN', 'JM', 'MX', 'NI', 'PA', 'KN', 'LC', 'VC', 'TT', 'US'],
    'SouthAmerica': ['AR', 'BO', 'BR', 'CL', 'CO', 'EC', 'GY', 'PY', 'PE', 'SR', 'UY', 'VE'],
    'Africa': ['DZ', 'AO', 'BJ', 'BW', 'BF', 'BI', 'CV', 'CM', 'CF', 'TD', 'KM', 'CD', 'CG', 'CI', 'DJ', 'EG', 'GQ', 'ER', 'SZ', 'ET', 'GA', 'GM', 'GH', 'GN', 'GW', 'KE', 'LS', 'LR', 'LY', 'MG', 'MW', 'ML', 'MR', 'MU', 'YT', 'MA', 'MZ', 'NA', 'NE', 'NG', 'RW', 'ST', 'SN', 'SC', 'SL', 'SO', 'ZA', 'SS', 'SD', 'TZ', 'TG', 'TN', 'UG', 'EH', 'ZM', 'ZW'],
    'Oceania': ['AS', 'AU', 'CK', 'FJ', 'PF', 'GU', 'KI', 'MH', 'FM', 'NR', 'NC', 'NZ', 'NU', 'NF', 'MP', 'PW', 'PG', 'PN', 'WS', 'SB', 'TK', 'TO', 'TV', 'VU', 'WF']
}

# --- FOFA å­—æ®µå®šä¹‰ ---
FOFA_STATS_FIELDS = "protocol,domain,port,title,os,server,country,asn,org,asset_type,fid,icp"
FREE_FIELDS = ["ip", "port", "protocol", "country", "country_name", "region", "city", "longitude", "latitude", "asn", "org", "host", "domain", "os", "server", "icp", "title", "jarm", "header", "banner", "cert", "base_protocol", "link", "cert.issuer.org", "cert.issuer.cn", "cert.subject.org", "cert.subject.cn", "tls.ja3s", "tls.version", "cert.sn", "cert.not_before", "cert.not_after", "cert.domain"]
PERSONAL_FIELDS = FREE_FIELDS + ["header_hash", "banner_hash", "banner_fid"]
BUSINESS_FIELDS = PERSONAL_FIELDS + ["cname", "lastupdatetime", "product", "product_category", "version", "icon_hash", "cert.is_valid", "cname_domain", "body", "cert.is_match", "cert.is_equal"]
ENTERPRISE_FIELDS = BUSINESS_FIELDS + ["icon", "fid", "structinfo"]
FIELD_CATEGORIES = {
    "å…è´¹å­—æ®µ": FREE_FIELDS,
    "ä¸ªäººä¼šå‘˜å­—æ®µ": list(set(PERSONAL_FIELDS) - set(FREE_FIELDS)),
    "å•†ä¸šç‰ˆæœ¬å­—æ®µ": list(set(BUSINESS_FIELDS) - set(PERSONAL_FIELDS)),
    "ä¼ä¸šç‰ˆæœ¬å­—æ®µ": list(set(ENTERPRISE_FIELDS) - set(BUSINESS_FIELDS)),
}
KEY_LEVELS = {}

# --- æ—¥å¿—é…ç½® ---
if os.path.exists(LOG_FILE) and os.path.getsize(LOG_FILE) > (5 * 1024 * 1024):
    try: os.rename(LOG_FILE, LOG_FILE + '.old')
    except OSError as e: print(f"æ— æ³•è½®æ¢æ—¥å¿—æ–‡ä»¶: {e}")
logging.basicConfig(
    level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler(LOG_FILE, encoding='utf-8'), logging.StreamHandler()]
)
logging.getLogger("requests").setLevel(logging.WARNING); logging.getLogger("urllib3").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# --- ä¼šè¯çŠ¶æ€å®šä¹‰ ---
(
    STATE_SETTINGS_MAIN, STATE_SETTINGS_ACTION, STATE_GET_KEY, STATE_REMOVE_API,
    STATE_KKFOFA_MODE, STATE_CACHE_CHOICE, STATE_GET_IMPORT_QUERY, STATE_GET_STATS_QUERY,
    STATE_PRESET_MENU, STATE_GET_PRESET_NAME, STATE_GET_PRESET_QUERY, STATE_REMOVE_PRESET,
    STATE_GET_UPDATE_URL, STATE_ASK_CONTINENT, STATE_CONTINENT_CHOICE,
    STATE_GET_BATCH_FILE, STATE_SELECT_BATCH_FEATURES, STATE_GET_RESTORE_FILE,
    STATE_PROXYPOOL_MENU, STATE_GET_PROXY_ADD, STATE_GET_PROXY_REMOVE,
    STATE_GET_TRACEBACK_LIMIT, STATE_GET_SCAN_CONCURRENCY, STATE_GET_SCAN_TIMEOUT,
    STATE_UPLOAD_API_MENU, STATE_GET_UPLOAD_URL, STATE_GET_UPLOAD_TOKEN,
    STATE_GET_GUEST_KEY, STATE_BATCH_GET_QUERY, STATE_BATCH_SELECT_FIELDS,
    STATE_GET_API_FILE, STATE_ALLFOFA_GET_LIMIT,
) = range(32)

# --- é…ç½®ç®¡ç† & ç¼“å­˜ ---
def load_json_file(filename, default_content):
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4); return default_content
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            config = json.load(f)
            if isinstance(default_content, dict):
                for key, value in default_content.items(): config.setdefault(key, value)
            return config
    except (json.JSONDecodeError, IOError):
        logger.error(f"{filename} æŸåï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®é‡å»ºã€‚");
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4); return default_content
def save_json_file(filename, data):
    with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=4, ensure_ascii=False)
DEFAULT_CONFIG = { "bot_token": "YOUR_BOT_TOKEN_HERE", "apis": [], "admins": [], "proxy": "", "proxies": [], "full_mode": False, "public_mode": False, "presets": [], "update_url": "", "upload_api_url": "", "upload_api_token": "" }
CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
HISTORY = load_json_file(HISTORY_FILE, {"queries": []})
ANONYMOUS_KEYS = load_json_file(ANONYMOUS_KEYS_FILE, {})
SCAN_TASKS = load_json_file(SCAN_TASKS_FILE, {})
def save_config(): save_json_file(CONFIG_FILE, CONFIG)
def save_anonymous_keys(): save_json_file(ANONYMOUS_KEYS_FILE, ANONYMOUS_KEYS)
def save_scan_tasks():
    logger.info(f"Saving {len(SCAN_TASKS)} scan tasks to {SCAN_TASKS_FILE}")
    save_json_file(SCAN_TASKS_FILE, SCAN_TASKS)
def add_or_update_query(query_text, cache_data=None):
    existing_query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if existing_query:
        HISTORY['queries'].remove(existing_query); existing_query['timestamp'] = datetime.now(tz.tzutc()).isoformat()
        if cache_data: existing_query['cache'] = cache_data
        HISTORY['queries'].insert(0, existing_query)
    else:
        new_query = {"query_text": query_text, "timestamp": datetime.now(tz.tzutc()).isoformat(), "cache": cache_data}
        HISTORY['queries'].insert(0, new_query)
    while len(HISTORY['queries']) > MAX_HISTORY_SIZE: HISTORY['queries'].pop()
    save_json_file(HISTORY_FILE, HISTORY)
def find_cached_query(query_text):
    query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if query and query.get('cache'):
        if 'file_path' in query['cache'] and os.path.exists(query['cache']['file_path']):
            return query
    return None

# --- è¾…åŠ©å‡½æ•°ä¸è£…é¥°å™¨ ---
def generate_filename_from_query(query_text: str, prefix: str = "fofa", ext: str = ".txt") -> str:
    sanitized_query = re.sub(r'[^a-z0-9\-_]+', '_', query_text.lower()).strip('_')
    max_len = 100
    if len(sanitized_query) > max_len: sanitized_query = sanitized_query[:max_len].rsplit('_', 1)[0]
    timestamp = int(time.time()); return f"{prefix}_{sanitized_query}_{timestamp}{ext}"
def get_proxies(proxy_to_use=None):
    """
    è¿”å›ä¸€ä¸ªä»£ç†é…ç½®å­—å…¸ã€‚
    å¦‚æœæä¾›äº† proxy_to_useï¼Œåˆ™ä¸“é—¨ä½¿ç”¨å®ƒã€‚
    å¦åˆ™ï¼Œä»ä»£ç†æ± ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªã€‚
    """
    proxy_str = proxy_to_use
    if proxy_str is None:
        proxies_list = CONFIG.get("proxies", [])
        if proxies_list:
            proxy_str = random.choice(proxies_list)
        else:
            proxy_str = CONFIG.get("proxy")
    
    if proxy_str:
        return {"http": proxy_str, "https": proxy_str}
    return None
def is_admin(user_id: int) -> bool: return user_id in CONFIG.get('admins', [])
def admin_only(func):
    @wraps(func)
    def wrapped(update: Update, context: CallbackContext, *args, **kwargs):
        if not is_admin(update.effective_user.id):
            message_text = "â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤ç®¡ç†æ“ä½œã€‚"
            if update.callback_query: update.callback_query.answer(message_text, show_alert=True)
            elif update.message: update.message.reply_text(message_text)
            return None
        return func(update, context, *args, **kwargs)
    return wrapped
def escape_markdown_v2(text: str) -> str:
    if not isinstance(text, str): text = str(text)
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)
def create_progress_bar(percentage: float, length: int = 10) -> str:
    if percentage < 0: percentage = 0
    if percentage > 100: percentage = 100
    filled_length = int(length * percentage // 100)
    bar = 'â–ˆ' * filled_length + 'â–‘' * (length - filled_length)
    return f"[{bar}] {percentage:.1f}%"

# --- æ–‡ä»¶ä¸Šä¼ è¾…åŠ©å‡½æ•° ---
def send_file_safely(context: CallbackContext, chat_id: int, file_path: str, caption: str = "", parse_mode: str = None, filename: str = None):
    """å®‰å…¨åœ°å‘é€æ–‡ä»¶ï¼Œå¤„ç†Telegram APIçš„å¤§å°é™åˆ¶ã€‚"""
    try:
        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
        TELEGRAM_MAX_FILE_SIZE_MB = 48

        if file_size_mb < TELEGRAM_MAX_FILE_SIZE_MB:
            with open(file_path, 'rb') as doc:
                context.bot.send_document(
                    chat_id, 
                    document=doc, 
                    filename=filename or os.path.basename(file_path), 
                    caption=caption, 
                    parse_mode=parse_mode, 
                    timeout=120 
                )
        else:
            message = (
                f"âš ï¸ *æ–‡ä»¶è¿‡å¤§*\n\n"
                f"æ–‡ä»¶ `{escape_markdown_v2(filename or os.path.basename(file_path))}` \\({file_size_mb:.2f} MB\\) "
                f"è¶…è¿‡äº†Telegramçš„å‘é€é™åˆ¶ \\({TELEGRAM_MAX_FILE_SIZE_MB} MB\\)\\."
            )
            context.bot.send_message(chat_id, message, parse_mode=ParseMode.MARKDOWN_V2)
    except FileNotFoundError:
        logger.error(f"å°è¯•å‘é€æ–‡ä»¶å¤±è´¥: æ–‡ä»¶æœªæ‰¾åˆ° at path {file_path}")
        context.bot.send_message(chat_id, f"âŒ å†…éƒ¨é”™è¯¯: å°è¯•å‘é€ç»“æœæ–‡ä»¶æ—¶æ‰¾ä¸åˆ°å®ƒã€‚")
    except (TimedOut, NetworkError) as e:
        logger.error(f"å‘é€æ–‡ä»¶ '{file_path}' æ—¶å‡ºç°ç½‘ç»œé”™è¯¯æˆ–è¶…æ—¶: {e}")
        context.bot.send_message(chat_id, f"âš ï¸ å‘é€æ–‡ä»¶æ—¶ç½‘ç»œè¶…æ—¶æˆ–å‡ºé”™ã€‚å¦‚æœé…ç½®äº†å¤–éƒ¨ä¸Šä¼ ï¼Œè¯·æ£€æŸ¥é‚£é‡Œçš„é“¾æ¥ã€‚")
    except Exception as e:
        logger.error(f"å‘é€æ–‡ä»¶ '{file_path}' æ—¶å‡ºç°æœªçŸ¥é”™è¯¯: {e}")
        context.bot.send_message(chat_id, f"âš ï¸ å‘é€æ–‡ä»¶æ—¶å‡ºç°æœªçŸ¥é”™è¯¯: `{escape_markdown_v2(str(e))}`", parse_mode=ParseMode.MARKDOWN_V2)

def upload_and_send_links(context: CallbackContext, chat_id: int, file_path: str):
    api_url = CONFIG.get("upload_api_url")
    api_token = CONFIG.get("upload_api_token")
    if not api_url or not api_token:
        logger.info("æœªé…ç½®ä¸Šä¼ APIçš„URLæˆ–Tokenï¼Œè·³è¿‡æ–‡ä»¶ä¸Šä¼ ã€‚")
        return
    try:
        with open(file_path, 'rb') as f:
            files = {'file': (os.path.basename(file_path), f)}
            headers = {'Authorization': api_token}
            response = requests.post(api_url, headers=headers, files=files, timeout=60, proxies=get_proxies())
            response.raise_for_status()
            result = response.json()
        if result and isinstance(result, list) and 'src' in result[0]:
            file_url_path = result[0]['src']
            parsed_main_url = urlparse(api_url)
            base_url = f"{parsed_main_url.scheme}://{parsed_main_url.netloc}"
            full_url = base_url + file_url_path
            file_name = os.path.basename(file_url_path)
            download_commands = (
                f"ğŸ“¥ *æ–‡ä»¶ä¸‹è½½å‘½ä»¤*\n\n"
                f"*cURL:*\n`curl -o \"{escape_markdown_v2(file_name)}\" \"{escape_markdown_v2(full_url)}\"`\n\n"
                f"*Wget:*\n`wget --content-disposition \"{escape_markdown_v2(full_url)}\"`"
            )
            context.bot.send_message(chat_id, download_commands, parse_mode=ParseMode.MARKDOWN_V2)
        else:
            raise ValueError(f"å“åº”æ ¼å¼ä¸æ­£ç¡®: {result}")
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        context.bot.send_message(chat_id, f"âš ï¸ æ–‡ä»¶ä¸Šä¼ åˆ°å¤–éƒ¨æœåŠ¡å™¨å¤±è´¥: `{escape_markdown_v2(str(e))}`", parse_mode=ParseMode.MARKDOWN_V2)

# --- FOFA API æ ¸å¿ƒé€»è¾‘ ---
def _make_api_request(url, params, timeout=60, use_b64=True, retries=10, proxy_session=None):
    if use_b64 and 'q' in params:
        params['qbase64'] = base64.b64encode(params.pop('q').encode('utf-8')).decode('utf-8')
    
    last_error = None
    # v10.9.4 FIX: ä¸ºæ•´ä¸ªé‡è¯•å¾ªç¯ç¡®å®šä»£ç†ã€‚
    # å¦‚æœä¼ é€’äº†ç‰¹å®šçš„ä¼šè¯ï¼Œåˆ™ä½¿ç”¨å®ƒã€‚å¦åˆ™ï¼Œä¸ºæ­¤å°è¯•è·å–ä¸€ä¸ªéšæœºçš„ã€‚
    request_proxies = get_proxies(proxy_to_use=proxy_session)

    for attempt in range(retries):
        try:
            response = requests.get(url, params=params, timeout=timeout, proxies=request_proxies, verify=False)
            if response.status_code == 429:
                wait_time = 5 * (attempt + 1)
                logger.warning(f"FOFA API rate limit hit (429). Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{retries})")
                time.sleep(wait_time)
                last_error = f"APIè¯·æ±‚å› é€Ÿç‡é™åˆ¶(429)å¤±è´¥"
                continue
            response.raise_for_status()
            data = response.json()
            if data.get("error"):
                return None, data.get("errmsg", "æœªçŸ¥çš„FOFAé”™è¯¯")
            return data, None
        except requests.exceptions.RequestException as e:
            last_error = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}"
            logger.error(f"RequestException on attempt {attempt + 1}: {e}")
            time.sleep(5)
        except json.JSONDecodeError as e:
            last_error = f"è§£æJSONå“åº”å¤±è´¥: {e}"
            break
    logger.error(f"API request failed after {retries} retries. Last error: {last_error}")
    return None, last_error if last_error else "APIè¯·æ±‚æœªçŸ¥é”™è¯¯"
def verify_fofa_api(key): return _make_api_request(FOFA_INFO_URL, {'key': key}, timeout=15, use_b64=False, retries=3)
def fetch_fofa_data(key, query, page=1, page_size=10000, fields="host", proxy_session=None):
    query_lower = query.lower()
    if 'body=' in query_lower: page_size = min(page_size, 500)
    elif 'cert=' in query_lower: page_size = min(page_size, 2000)
    params = {'key': key, 'q': query, 'size': page_size, 'page': page, 'fields': fields, 'full': CONFIG.get("full_mode", False)}
    return _make_api_request(FOFA_SEARCH_URL, params, proxy_session=proxy_session)
def fetch_fofa_stats(key, query, proxy_session=None):
    params = {'key': key, 'q': query, 'fields': FOFA_STATS_FIELDS}
    return _make_api_request(FOFA_STATS_URL, params, proxy_session=proxy_session)
def fetch_fofa_host_info(key, host, detail=False, proxy_session=None):
    url = FOFA_HOST_BASE_URL + host
    params = {'key': key, 'detail': str(detail).lower()}
    return _make_api_request(url, params, use_b64=False, proxy_session=proxy_session)
def fetch_fofa_next_data(key, query, next_id=None, page_size=10000, fields="host", proxy_session=None):
    params = {'key': key, 'q': query, 'size': page_size, 'fields': fields, 'full': CONFIG.get("full_mode", False)}
    # FIX: Ensure 'next' parameter is always present, and empty on the first call, to comply with API spec.
    params['next'] = next_id if next_id is not None else ""
    return _make_api_request(FOFA_NEXT_URL, params, proxy_session=proxy_session)

def check_and_classify_keys():
    logger.info("--- å¼€å§‹æ£€æŸ¥å¹¶åˆ†ç±»API Keys ---")
    global KEY_LEVELS
    KEY_LEVELS.clear()
    for key in CONFIG.get('apis', []):
        data, error = verify_fofa_api(key)
        if error:
            logger.warning(f"Key '...{key[-4:]}' æ— æ•ˆ: {error}")
            KEY_LEVELS[key] = -1
            continue
        is_vip = data.get('isvip', False)
        api_level = data.get('vip_level', 0)
        level = 0
        if not is_vip:
            level = 0
        else:
            if api_level == 2: level = 1
            elif api_level == 3: level = 2
            elif api_level >= 4: level = 3
            else: level = 1 
        KEY_LEVELS[key] = level
        level_name = {0: "å…è´¹ä¼šå‘˜", 1: "ä¸ªäººä¼šå‘˜", 2: "å•†ä¸šä¼šå‘˜", 3: "ä¼ä¸šä¼šå‘˜"}.get(level, "æœªçŸ¥ç­‰çº§")
        logger.info(f"Key '...{key[-4:]}' ({data.get('username', 'N/A')}) - ç­‰çº§: {level} ({level_name})")
    logger.info("--- API Keys åˆ†ç±»å®Œæˆ ---")

def get_fields_by_level(level):
    if level >= 3: return ENTERPRISE_FIELDS
    if level == 2: return BUSINESS_FIELDS
    if level == 1: return PERSONAL_FIELDS
    return FREE_FIELDS

def execute_query_with_fallback(query_func, preferred_key_index=None, proxy_session=None, min_level=0):
    if not CONFIG['apis']: return None, None, None, None, None, "æ²¡æœ‰é…ç½®ä»»ä½•API Keyã€‚"
    
    keys_to_try = [k for k in CONFIG['apis'] if KEY_LEVELS.get(k, -1) >= min_level]
    
    if not keys_to_try:
        if min_level > 0:
            return None, None, None, None, None, f"æ²¡æœ‰æ‰¾åˆ°ç­‰çº§ä¸ä½äºâ€œä¸ªäººä¼šå‘˜â€çš„æœ‰æ•ˆAPI Keyä»¥æ‰§è¡Œæ­¤æ“ä½œã€‚"
        return None, None, None, None, None, "æ‰€æœ‰é…ç½®çš„API Keyéƒ½æ— æ•ˆã€‚"
    
    start_index = 0
    if preferred_key_index is not None and 1 <= preferred_key_index <= len(CONFIG['apis']):
        preferred_key = CONFIG['apis'][preferred_key_index - 1]
        if preferred_key in keys_to_try:
            start_index = keys_to_try.index(preferred_key)

    # v10.9.4 FIX: å¦‚æœæœªé”å®šä»£ç†ä¼šè¯ï¼Œåˆ™åœ¨æ­¤å›é€€åºåˆ—çš„æŒç»­æ—¶é—´å†…é€‰æ‹©ä¸€ä¸ªã€‚
    current_proxy_session_str = proxy_session
    if current_proxy_session_str is None:
        proxies_list = CONFIG.get("proxies", [])
        if proxies_list:
            current_proxy_session_str = random.choice(proxies_list)
        else:
            current_proxy_session_str = CONFIG.get("proxy")

    for i in range(len(keys_to_try)):
        idx = (start_index + i) % len(keys_to_try)
        key = keys_to_try[idx]
        key_num = CONFIG['apis'].index(key) + 1
        key_level = KEY_LEVELS.get(key, 0)
        
        # v10.9.4 FIX: å°†keyã€key_levelå’Œä¸€è‡´çš„proxy_sessionä¼ é€’ç»™æŸ¥è¯¢å‡½æ•°ã€‚
        data, error = query_func(key, key_level, current_proxy_session_str)
        
        if not error:
            # è¿”å›æˆåŠŸä½¿ç”¨çš„ä»£ç†ã€‚
            return data, key, key_num, key_level, current_proxy_session_str, None
        if "[820031]" in str(error):
            logger.warning(f"Key [#{key_num}] Fç‚¹ä½™é¢ä¸è¶³...");
            continue
        # å¯¹äºå…¶ä»–é”™è¯¯ï¼Œå¿«é€Ÿå¤±è´¥å¹¶è¿”å›é—®é¢˜keyçš„ä¿¡æ¯
        return None, key, key_num, key_level, current_proxy_session_str, error
        
    return None, None, None, None, None, "æ‰€æœ‰Keyå‡å°è¯•å¤±è´¥ (å¯èƒ½Fç‚¹å‡ä¸è¶³)ã€‚"

# --- å¼‚æ­¥æ‰«æé€»è¾‘ ---
async def async_check_port(host, port, timeout):
    try:
        fut = asyncio.open_connection(host, port)
        _, writer = await asyncio.wait_for(fut, timeout=timeout)
        writer.close(); await writer.wait_closed()
        return f"{host}:{port}"
    except (asyncio.TimeoutError, ConnectionRefusedError, OSError, socket.gaierror): return None
    except Exception: return None
async def async_scanner_orchestrator(targets, concurrency, timeout, mode='tcping'):
    try:
        from tqdm.asyncio import tqdm as asyncio_tqdm
    except ImportError:
        logger.warning("tqdm æœªå®‰è£…ï¼Œæ§åˆ¶å°å°†ä¸æ˜¾ç¤ºè¿›åº¦æ¡ã€‚è¯·è¿è¡Œ: pip install tqdm")
        async def dummy_gather(*args, **kwargs):
            return await asyncio.gather(*args)
        asyncio_tqdm_gather = dummy_gather
    else:
        asyncio_tqdm_gather = asyncio_tqdm.gather
    semaphore = asyncio.Semaphore(concurrency)
    scan_targets = []
    if mode == 'tcping':
        for t in targets:
            try:
                host, port_str = t.split(':', 1)
                scan_targets.append((host, int(port_str)))
            except (ValueError, IndexError): continue
    elif mode == 'subnet':
        subnets_to_ports = {}
        for line in targets:
            try:
                ip_str, port_str = line.strip().split(':'); port = int(port_str)
                subnet = ".".join(ip_str.split('.')[:3])
                if subnet not in subnets_to_ports: subnets_to_ports[subnet] = set()
                subnets_to_ports[subnet].add(port)
            except ValueError: continue
        for subnet, ports in subnets_to_ports.items():
            for i in range(1, 255):
                for port in ports:
                    scan_targets.append((f"{subnet}.{i}", port))
    async def worker(host, port):
        async with semaphore:
            return await async_check_port(host, port, timeout)
    tasks = [worker(host, port) for host, port in scan_targets]
    results = await asyncio_tqdm_gather(*tasks, desc=f"Scanning ({mode})", total=len(tasks), unit="host")
    return [res for res in results if res is not None]
def run_async_scan_job(context: CallbackContext):
    job_context = context.job.context
    chat_id, msg, original_query, mode = job_context['chat_id'], job_context['msg'], job_context['original_query'], job_context['mode']
    concurrency, timeout = job_context['concurrency'], job_context['timeout']
    
    cached_item = find_cached_query(original_query)
    if not cached_item: msg.edit_text("âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶çš„æœ¬åœ°ç¼“å­˜è®°å½•ã€‚"); return
    msg.edit_text("1/3: æ­£åœ¨è¯»å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶...")
    try:
        with open(cached_item['cache']['file_path'], 'r', encoding='utf-8') as f:
            targets = [line.strip() for line in f if ':' in line.strip()]
    except Exception as e: msg.edit_text(f"âŒ è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    scan_type_text = "TCPå­˜æ´»æ‰«æ" if mode == 'tcping' else "å­ç½‘æ‰«æ"
    msg.edit_text(f"2/3: å·²åŠ è½½ {len(targets)} ä¸ªç›®æ ‡ï¼Œå¼€å§‹å¼‚æ­¥{scan_type_text} (å¹¶å‘: {concurrency}, è¶…æ—¶: {timeout}s)...")
    live_results = asyncio.run(async_scanner_orchestrator(targets, concurrency, timeout, mode))
    if not live_results: msg.edit_text("ğŸ¤·â€â™€ï¸ æ‰«æå®Œæˆï¼Œä½†æœªå‘ç°ä»»ä½•å­˜æ´»çš„ç›®æ ‡ã€‚"); return
    msg.edit_text("3/3: æ­£åœ¨æ‰“åŒ…å¹¶å‘é€æ–°ç»“æœ...")
    output_filename = generate_filename_from_query(original_query, prefix=f"{mode}_scan")
    with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(live_results))))
    # FIX: Corrected MarkdownV2 syntax error (removed extra asterisk).
    final_caption = f"âœ… *å¼‚æ­¥{escape_markdown_v2(scan_type_text)}å®Œæˆ\!*\n\nå…±å‘ç° *{len(live_results)}* ä¸ªå­˜æ´»ç›®æ ‡\\."
    send_file_safely(context, chat_id, output_filename, caption=final_caption, parse_mode=ParseMode.MARKDOWN_V2)
    upload_and_send_links(context, chat_id, output_filename)
    os.remove(output_filename); msg.delete()

# --- æ‰«ææµç¨‹å…¥å£ ---
def offer_post_download_actions(context: CallbackContext, chat_id, query_text):
    query_hash = hashlib.md5(query_text.encode()).hexdigest()
    SCAN_TASKS[query_hash] = query_text
    while len(SCAN_TASKS) > MAX_SCAN_TASKS:
        SCAN_TASKS.pop(next(iter(SCAN_TASKS)))
    save_scan_tasks()

    keyboard = [[
        InlineKeyboardButton("âš¡ï¸ å¼‚æ­¥TCPå­˜æ´»æ‰«æ", callback_data=f'start_scan_tcping_{query_hash}'),
        InlineKeyboardButton("ğŸŒ å¼‚æ­¥å­ç½‘æ‰«æ(/24)", callback_data=f'start_scan_subnet_{query_hash}')
    ]]
    context.bot.send_message(chat_id, "ä¸‹è½½å®Œæˆï¼Œéœ€è¦å¯¹ç»“æœè¿›è¡ŒäºŒæ¬¡æ‰«æå—ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard))
def start_scan_callback(update: Update, context: CallbackContext) -> int:
    query = update.callback_query; query.answer()
    # v10.9.1 FIX: Correctly parse callback data to get mode and query_hash
    try:
        _, _, mode, query_hash = query.data.split('_', 3)
    except ValueError:
        logger.error(f"æ— æ³•ä»å›è°ƒæ•°æ®è§£ææ‰«æä»»åŠ¡: {query.data}")
        query.message.edit_text("âŒ å†…éƒ¨é”™è¯¯ï¼šæ— æ³•è§£ææ‰«æä»»åŠ¡ã€‚")
        return ConversationHandler.END

    original_query = SCAN_TASKS.get(query_hash)
    if not original_query:
        query.message.edit_text("âŒ æ‰«æä»»åŠ¡å·²è¿‡æœŸæˆ–æœºå™¨äººåˆšåˆšé‡å¯ã€‚è¯·é‡æ–°å‘èµ·æŸ¥è¯¢ä»¥å¯ç”¨æ‰«æã€‚")
        return ConversationHandler.END

    context.user_data['scan_original_query'] = original_query
    context.user_data['scan_mode'] = mode
    query.message.edit_text("è¯·è¾“å…¥æ‰«æå¹¶å‘æ•° (å»ºè®® 100-1000):")
    return STATE_GET_SCAN_CONCURRENCY
def get_concurrency_callback(update: Update, context: CallbackContext) -> int:
    try:
        concurrency = int(update.message.text)
        if not 1 <= concurrency <= 5000: raise ValueError
        context.user_data['scan_concurrency'] = concurrency
        update.message.reply_text("è¯·è¾“å…¥è¿æ¥è¶…æ—¶æ—¶é—´ (ç§’, å»ºè®® 1-3):")
        return STATE_GET_SCAN_TIMEOUT
    except ValueError:
        update.message.reply_text("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 1-5000 ä¹‹é—´çš„æ•´æ•°ã€‚")
        return STATE_GET_SCAN_CONCURRENCY
def get_timeout_callback(update: Update, context: CallbackContext) -> int:
    try:
        timeout = float(update.message.text)
        if not 0.1 <= timeout <= 10: raise ValueError
        msg = update.message.reply_text("âœ… å‚æ•°è®¾ç½®å®Œæ¯•ï¼Œä»»åŠ¡å·²æäº¤åˆ°åå°ã€‚")
        job_context = {
            'chat_id': update.effective_chat.id, 'msg': msg,
            'original_query': context.user_data['scan_original_query'],
            'mode': context.user_data['scan_mode'],
            'concurrency': context.user_data['scan_concurrency'],
            'timeout': timeout
        }
        context.job_queue.run_once(run_async_scan_job, 1, context=job_context, name=f"scan_{update.effective_chat.id}")
        context.user_data.clear()
        return ConversationHandler.END
    except ValueError:
        update.message.reply_text("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 0.1-10 ä¹‹é—´çš„æ•°å­—ã€‚")
        return STATE_GET_SCAN_TIMEOUT

# --- åå°ä¸‹è½½ä»»åŠ¡ ---
def start_download_job(context: CallbackContext, callback_func, job_data):
    chat_id = job_data['chat_id']; job_name = f"download_job_{chat_id}"
    for job in context.job_queue.get_jobs_by_name(job_name): job.schedule_removal()
    context.bot_data.pop(f'stop_job_{chat_id}', None)
    context.job_queue.run_once(callback_func, 1, context=job_data, name=job_name)
def run_full_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, query_text, total_size = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size']
    output_filename = generate_filename_from_query(query_text); unique_results, stop_flag = set(), f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡..."); pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(unique_results)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except (BadRequest, RetryAfter, TimedOut): pass
        guest_key = job_data.get('guest_key')
        if guest_key:
            data, error = fetch_fofa_data(guest_key, query_text, page, 10000, "host")
        else:
            data, _, _, _, _, error = execute_query_with_fallback(
                lambda key, key_level, proxy_session: fetch_fofa_data(key, query_text, page, 10000, "host", proxy_session=proxy_session)
            )
        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        results = data.get('results', []);
        if not results: break
        unique_results.update(res for res in results if ':' in res)
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(unique_results))
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚æ­£åœ¨å‘é€...")
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        send_file_safely(context, chat_id, cache_path, filename=output_filename)
        upload_and_send_links(context, chat_id, cache_path)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(query_text, cache_data); offer_post_download_actions(context, chat_id, query_text)
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)
def run_traceback_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; limit = job_data.get('limit')
    output_filename = generate_filename_from_query(base_query); unique_results, page_count, last_page_date, termination_reason, stop_flag, last_update_time = set(), 0, None, "", f'stop_job_{chat_id}', 0
    msg = bot.send_message(chat_id, "â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query
    guest_key = job_data.get('guest_key')
    
    # v10.9.4 FIX: ä¸ºæ•´ä¸ªè¿½æº¯è¿‡ç¨‹é”å®šä¸€ä¸ªä»£ç†ä¼šè¯
    locked_proxy_session = None

    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break

        fields_were_extended = False
        if guest_key:
            # Guest keys are assumed to be low-level, don't request lastupdatetime
            data, error = fetch_fofa_data(guest_key, current_query, 1, 10000, fields="host")
        else:
            def query_logic(key, key_level, proxy_session):
                nonlocal fields_were_extended
                # Personal members and above can search this field.
                if key_level >= 1:
                    fields_were_extended = True
                    return fetch_fofa_data(key, current_query, 1, 10000, fields="host,lastupdatetime", proxy_session=proxy_session)
                else:
                    fields_were_extended = False
                    return fetch_fofa_data(key, current_query, 1, 10000, fields="host", proxy_session=proxy_session)
            
            # ä»…åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶é€‰æ‹©å¹¶é”å®šä»£ç†
            if locked_proxy_session is None:
                data, _, _, _, locked_proxy_session, error = execute_query_with_fallback(query_logic)
            else:
                data, _, _, _, _, error = execute_query_with_fallback(query_logic, proxy_session=locked_proxy_session)

        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break

        if fields_were_extended:
            newly_added = [r[0] for r in results if r and r[0] and ':' in r[0]]
        else:
            newly_added = [r for r in results if r and ':' in r]
        
        original_count = len(unique_results)
        unique_results.update(newly_added)
        newly_added_count = len(unique_results) - original_count

        if limit and len(unique_results) >= limit: unique_results = set(list(unique_results)[:limit]); termination_reason = f"\n\nâ„¹ï¸ å·²è¾¾åˆ°æ‚¨è®¾ç½®çš„ {limit} æ¡ç»“æœä¸Šé™ã€‚"; break
        current_time = time.time()
        if current_time - last_update_time > 2:
            try: msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
            except (BadRequest, RetryAfter, TimedOut): pass
            last_update_time = current_time

        if not fields_were_extended:
             termination_reason = "\n\nâš ï¸ å½“å‰Keyç­‰çº§ä¸æ”¯æŒæ—¶é—´è¿½æº¯ï¼Œå·²è·å–ç¬¬ä¸€é¡µç»“æœã€‚"
             break
        
        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][1]: continue
            try:
                timestamp_str = results[i][1]; current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                last_page_date = current_date_obj; current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'; valid_anchor_found = True
                break
            except (ValueError, TypeError): continue
        if not valid_anchor_found: termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; break
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(unique_results))))
        msg.edit_text(f"âœ… æ·±åº¦è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨å‘é€æ–‡ä»¶...")
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        send_file_safely(context, chat_id, cache_path, filename=output_filename)
        upload_and_send_links(context, chat_id, cache_path)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(base_query, cache_data); offer_post_download_actions(context, chat_id, base_query)
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)
def run_incremental_update_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; msg = bot.send_message(chat_id, "--- å¢é‡æ›´æ–°å¯åŠ¨ ---")
    msg.edit_text("1/5: æ­£åœ¨è·å–æ—§ç¼“å­˜..."); cached_item = find_cached_query(base_query)
    if not cached_item: msg.edit_text("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜é¡¹ã€‚"); return
    old_file_path = cached_item['cache']['file_path']; old_results = set()
    try:
        with open(old_file_path, 'r', encoding='utf-8') as f: old_results = set(line.strip() for line in f if line.strip() and ':' in line)
    except Exception as e: msg.edit_text(f"âŒ è¯»å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    msg.edit_text("2/5: æ­£åœ¨ç¡®å®šæ›´æ–°èµ·å§‹ç‚¹..."); 
    data, _, _, _, _, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_data(key, base_query, fields="lastupdatetime", proxy_session=proxy_session)
    )
    if error or not data.get('results'): msg.edit_text(f"âŒ æ— æ³•è·å–æœ€æ–°è®°å½•æ—¶é—´æˆ³: {error or 'æ— ç»“æœ'}"); return
    ts_str = data['results'][0][0] if isinstance(data['results'][0], list) else data['results'][0]; cutoff_date = ts_str.split(' ')[0]
    incremental_query = f'({base_query}) && after="{cutoff_date}"'
    msg.edit_text(f"3/5: æ­£åœ¨ä¾¦å¯Ÿè‡ª {cutoff_date} ä»¥æ¥çš„æ–°æ•°æ®..."); 
    data, _, _, _, _, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_data(key, incremental_query, page_size=1, proxy_session=proxy_session)
    )
    if error: msg.edit_text(f"âŒ ä¾¦å¯ŸæŸ¥è¯¢å¤±è´¥: {error}"); return
    total_new_size = data.get('size', 0)
    if total_new_size == 0: msg.edit_text("âœ… æœªå‘ç°æ–°æ•°æ®ã€‚ç¼“å­˜å·²æ˜¯æœ€æ–°ã€‚"); return
    new_results, stop_flag = set(), f'stop_job_{chat_id}'; pages_to_fetch = (total_new_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ å¢é‡æ›´æ–°å·²æ‰‹åŠ¨åœæ­¢ã€‚"); return
        msg.edit_text(f"3/5: æ­£åœ¨ä¸‹è½½æ–°æ•°æ®... ( Page {page}/{pages_to_fetch} )")
        data, _, _, _, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, incremental_query, page=page, page_size=10000, proxy_session=proxy_session)
        )
        if error: msg.edit_text(f"âŒ ä¸‹è½½æ–°æ•°æ®å¤±è´¥: {error}"); return
        if data.get('results'): new_results.update(res for res in data.get('results', []) if ':' in res)
    msg.edit_text(f"4/5: æ­£åœ¨åˆå¹¶æ•°æ®... (å‘ç° {len(new_results)} æ¡æ–°æ•°æ®)"); combined_results = sorted(list(new_results.union(old_results)))
    with open(old_file_path, 'w', encoding='utf-8') as f: f.write("\n".join(combined_results))
    msg.edit_text(f"5/5: å‘é€æ›´æ–°åçš„æ–‡ä»¶... (å…± {len(combined_results)} æ¡)")
    send_file_safely(context, chat_id, old_file_path)
    upload_and_send_links(context, chat_id, old_file_path)
    cache_data = {'file_path': old_file_path, 'result_count': len(combined_results)}
    add_or_update_query(base_query, cache_data)
    msg.delete(); bot.send_message(chat_id, f"âœ… å¢é‡æ›´æ–°å®Œæˆï¼"); offer_post_download_actions(context, chat_id, base_query)
def run_batch_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, query_text, total_size, fields = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size'], job_data['fields']
    output_filename = generate_filename_from_query(query_text, prefix="batch_export", ext=".csv"); results_list, stop_flag = [], f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹è‡ªå®šä¹‰å­—æ®µæ‰¹é‡å¯¼å‡ºä»»åŠ¡..."); pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(results_list)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except (BadRequest, RetryAfter, TimedOut): pass
        data, _, _, _, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query_text, page, 10000, fields, proxy_session=proxy_session)
        )
        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        page_results = data.get('results', [])
        if not page_results: break
        results_list.extend(page_results)
    if results_list:
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(results_list)} æ¡ã€‚æ­£åœ¨ç”ŸæˆCSVæ–‡ä»¶...")
        try:
            with open(output_filename, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f); writer.writerow(fields.split(',')); writer.writerows(results_list)
            send_file_safely(context, chat_id, output_filename, caption=f"âœ… è‡ªå®šä¹‰å¯¼å‡ºå®Œæˆ\næŸ¥è¯¢: `{escape_markdown_v2(query_text)}`", parse_mode=ParseMode.MARKDOWN_V2)
            upload_and_send_links(context, chat_id, output_filename)
        except Exception as e:
            msg.edit_text(f"âŒ ç”Ÿæˆæˆ–å‘é€CSVæ–‡ä»¶å¤±è´¥: {e}"); logger.error(f"Failed to generate/send CSV for batch command: {e}")
        finally:
            if os.path.exists(output_filename): os.remove(output_filename)
            msg.delete()
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)
def run_batch_traceback_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query, fields, limit = context.bot, job_data['chat_id'], job_data['query'], job_data['fields'], job_data.get('limit')
    output_filename = generate_filename_from_query(base_query, prefix="batch_traceback", ext=".csv")
    unique_results, page_count, last_page_date, termination_reason, stop_flag, last_update_time = [], 0, None, "", f'stop_job_{chat_id}', 0
    msg = bot.send_message(chat_id, "â³ å¼€å§‹è‡ªå®šä¹‰å­—æ®µæ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query; seen_hashes = set()
    
    # v10.9.4 FIX: ä¸ºæ•´ä¸ªè¿½æº¯è¿‡ç¨‹é”å®šä¸€ä¸ªä»£ç†ä¼šè¯
    locked_proxy_session = None

    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        
        fields_were_extended = False
        def query_logic(key, key_level, proxy_session):
            nonlocal fields_were_extended
            if key_level >= 1:
                fields_were_extended = True
                return fetch_fofa_data(key, current_query, 1, 10000, fields=fields + ",lastupdatetime", proxy_session=proxy_session)
            else:
                fields_were_extended = False
                return fetch_fofa_data(key, current_query, 1, 10000, fields=fields, proxy_session=proxy_session)

        # ä»…åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£æ—¶é€‰æ‹©å¹¶é”å®šä»£ç†
        if locked_proxy_session is None:
            data, _, _, _, locked_proxy_session, error = execute_query_with_fallback(query_logic)
        else:
            data, _, _, _, _, error = execute_query_with_fallback(query_logic, proxy_session=locked_proxy_session)

        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break

        newly_added_count = 0
        for r in results:
            r_hash = hashlib.md5(str(r).encode()).hexdigest()
            if r_hash not in seen_hashes:
                seen_hashes.add(r_hash)
                unique_results.append(r[:-1] if fields_were_extended else r)
                newly_added_count += 1
        if limit and len(unique_results) >= limit: unique_results = unique_results[:limit]; termination_reason = f"\n\nâ„¹ï¸ å·²è¾¾åˆ°æ‚¨è®¾ç½®çš„ {limit} æ¡ç»“æœä¸Šé™ã€‚"; break
        current_time = time.time()
        if current_time - last_update_time > 2:
            try: msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
            except (BadRequest, RetryAfter, TimedOut): pass
            last_update_time = current_time

        if not fields_were_extended:
             termination_reason = "\n\nâš ï¸ å½“å‰Keyç­‰çº§ä¸æ”¯æŒæ—¶é—´è¿½æº¯ï¼Œå·²è·å–ç¬¬ä¸€é¡µç»“æœã€‚"
             break
        
        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][-1]: continue
            try:
                timestamp_str = results[i][-1]; current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                last_page_date = current_date_obj; current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'; valid_anchor_found = True
                break
            except (ValueError, TypeError): continue
        if not valid_anchor_found: termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; break
    if unique_results:
        msg.edit_text(f"âœ… è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨ç”ŸæˆCSV...")
        try:
            with open(output_filename, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f); writer.writerow(fields.split(',')); writer.writerows(unique_results)
            send_file_safely(context, chat_id, output_filename)
            upload_and_send_links(context, chat_id, output_filename)
        except Exception as e:
            msg.edit_text(f"âŒ ç”Ÿæˆæˆ–å‘é€CSVæ–‡ä»¶å¤±è´¥: {e}"); logger.error(f"Failed to generate/send CSV for batch traceback: {e}")
        finally:
            if os.path.exists(output_filename): os.remove(output_filename)
            msg.delete()
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)

# --- æ ¸å¿ƒå‘½ä»¤å¤„ç† ---
def start_command(update: Update, context: CallbackContext):
    update.message.reply_text('ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Fofa æŸ¥è¯¢æœºå™¨äºº v10.9ï¼è¯·ä½¿ç”¨ /help æŸ¥çœ‹å‘½ä»¤æ‰‹å†Œã€‚')
    if not CONFIG['admins']: first_admin_id = update.effective_user.id; CONFIG.setdefault('admins', []).append(first_admin_id); save_config(); update.message.reply_text(f"â„¹ï¸ å·²è‡ªåŠ¨å°†æ‚¨ (ID: `{first_admin_id}`) æ·»åŠ ä¸ºç¬¬ä¸€ä¸ªç®¡ç†å‘˜ã€‚")
def help_command(update: Update, context: CallbackContext):
    help_text = ( "ğŸ“– *Fofa æœºå™¨äººæŒ‡ä»¤æ‰‹å†Œ v10\\.9*\n\n"
                  "*ğŸ” èµ„äº§æœç´¢ \\(å¸¸è§„\\)*\n`/kkfofa [key] <query>`\n_FOFAæœç´¢, é€‚ç”¨äº1ä¸‡æ¡ä»¥å†…æ•°æ®_\n\n"
                  "*ğŸšš èµ„äº§æœç´¢ \\(æµ·é‡\\)*\n`/allfofa <query>`\n_ä½¿ç”¨nextæ¥å£ç¨³å®šè·å–æµ·é‡æ•°æ® \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ“¦ ä¸»æœºè¯¦æŸ¥ \\(æ™ºèƒ½\\)*\n`/host <ip|domain>`\n_è‡ªé€‚åº”è·å–æœ€å…¨ä¸»æœºä¿¡æ¯ \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ”¬ ä¸»æœºé€ŸæŸ¥ \\(èšåˆ\\)*\n`/lowhost <ip|domain> [detail]`\n_å¿«é€Ÿè·å–ä¸»æœºèšåˆä¿¡æ¯ \\(æ‰€æœ‰ç”¨æˆ·\\)_\n\n"
                  "*ğŸ“Š èšåˆç»Ÿè®¡*\n`/stats <query>`\n_è·å–å…¨å±€èšåˆç»Ÿè®¡ \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ“‚ æ‰¹é‡æ™ºèƒ½åˆ†æ*\n`/batchfind`\n_ä¸Šä¼ IPåˆ—è¡¨, åˆ†æç‰¹å¾å¹¶ç”ŸæˆExcel \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ“¤ æ‰¹é‡è‡ªå®šä¹‰å¯¼å‡º \\(äº¤äº’å¼\\)*\n`/batch <query>`\n_è¿›å…¥äº¤äº’å¼èœå•é€‰æ‹©å­—æ®µå¯¼å‡º \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*âš™ï¸ ç®¡ç†ä¸è®¾ç½®*\n`/settings`\n_è¿›å…¥äº¤äº’å¼è®¾ç½®èœå• \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ”‘ Keyç®¡ç†*\n`/batchcheckapi`\n_ä¸Šä¼ æ–‡ä»¶æ‰¹é‡éªŒè¯API Key \\(ç®¡ç†å‘˜\\)_\n\n"
                  "*ğŸ’» ç³»ç»Ÿç®¡ç†*\n"
                  "`/check` \\- ç³»ç»Ÿè‡ªæ£€\n"
                  "`/update` \\- åœ¨çº¿æ›´æ–°è„šæœ¬\n"
                  "`/shutdown` \\- å®‰å…¨å…³é—­/é‡å¯\n\n"
                  "*ğŸ›‘ ä»»åŠ¡æ§åˆ¶*\n`/stop` \\- ç´§æ€¥åœæ­¢ä¸‹è½½ä»»åŠ¡\n`/cancel` \\- å–æ¶ˆå½“å‰æ“ä½œ" )
    update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN_V2)
def cancel(update: Update, context: CallbackContext) -> int:
    message = "æ“ä½œå·²å–æ¶ˆã€‚"
    if update.message: update.message.reply_text(message)
    elif update.callback_query: update.callback_query.edit_message_text(message)
    context.user_data.clear()
    return ConversationHandler.END

# --- /kkfofa, /allfofa & è®¿å®¢é€»è¾‘ ---
def query_entry_point(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    query_obj = update.callback_query
    message_obj = update.message

    if query_obj:
        query_obj.answer()
        context.user_data['command'] = '/kkfofa'
        
        if not is_admin(user_id):
            guest_key = ANONYMOUS_KEYS.get(str(user_id))
            if not guest_key:
                query_obj.message.edit_text("ğŸ‘‹ æ¬¢è¿ï¼ä½œä¸ºé¦–æ¬¡ä½¿ç”¨çš„è®¿å®¢ï¼Œè¯·å…ˆå‘é€æ‚¨çš„FOFA API Keyã€‚")
                return ConversationHandler.END
            context.user_data['guest_key'] = guest_key

        try:
            preset_index = int(query_obj.data.replace("run_preset_", ""))
            preset = CONFIG["presets"][preset_index]
            context.user_data['original_query'] = preset['query']
            context.user_data['key_index'] = None
            keyboard = [[InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"), InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")]]
            query_obj.message.edit_text(f"é¢„è®¾æŸ¥è¯¢: `{escape_markdown_v2(preset['query'])}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
            return STATE_ASK_CONTINENT
        except (ValueError, IndexError):
            query_obj.message.edit_text("âŒ é¢„è®¾æŸ¥è¯¢å¤±è´¥ã€‚")
            return ConversationHandler.END

    elif message_obj:
        command = message_obj.text.split()[0].lower()

        if command == '/allfofa' and not is_admin(user_id):
            message_obj.reply_text("â›”ï¸ æŠ±æ­‰ï¼Œ`/allfofa` å‘½ä»¤ä»…é™ç®¡ç†å‘˜ä½¿ç”¨ã€‚")
            return ConversationHandler.END

        if not is_admin(user_id):
            guest_key = ANONYMOUS_KEYS.get(str(user_id))
            if not guest_key:
                message_obj.reply_text("ğŸ‘‹ æ¬¢è¿ï¼ä½œä¸ºé¦–æ¬¡ä½¿ç”¨çš„è®¿å®¢ï¼Œè¯·è¾“å…¥æ‚¨çš„FOFA API Keyä»¥ç»§ç»­ã€‚æ‚¨çš„Keyåªä¼šè¢«æ‚¨è‡ªå·±ä½¿ç”¨ã€‚")
                if context.args:
                    context.user_data['pending_query'] = " ".join(context.args)
                return STATE_GET_GUEST_KEY
            context.user_data['guest_key'] = guest_key

        if not context.args:
            if command == '/kkfofa':
                presets = CONFIG.get("presets", [])
                if not presets:
                    message_obj.reply_text(f"æ¬¢è¿ä½¿ç”¨FOFAæŸ¥è¯¢æœºå™¨äººã€‚\n\nâ¡ï¸ ç›´æ¥è¾“å…¥æŸ¥è¯¢è¯­æ³•: `/kkfofa domain=\"example.com\"`\nâ„¹ï¸ å½“å‰æ²¡æœ‰å¯ç”¨çš„é¢„è®¾æŸ¥è¯¢ã€‚ç®¡ç†å‘˜å¯é€šè¿‡ /settings æ·»åŠ ã€‚")
                    return ConversationHandler.END
                keyboard = []
                for i, p in enumerate(presets):
                    query_preview = p['query'][:25] + '...' if len(p['query']) > 25 else p['query']
                    keyboard.append([InlineKeyboardButton(f"{p['name']} (`{query_preview}`)", callback_data=f"run_preset_{i}")])
                message_obj.reply_text("ğŸ‘‡ è¯·é€‰æ‹©ä¸€ä¸ªé¢„è®¾æŸ¥è¯¢:", reply_markup=InlineKeyboardMarkup(keyboard))
            else:
                 message_obj.reply_text(f"ç”¨æ³•: `{command} <fofa_query>`")
            return ConversationHandler.END

        key_index, query_text = None, " ".join(context.args)
        if context.args[0].isdigit() and is_admin(user_id):
            try:
                num = int(context.args[0])
                if 1 <= num <= len(CONFIG['apis']):
                    key_index = num
                    query_text = " ".join(context.args[1:])
            except ValueError:
                pass
        
        context.user_data['original_query'] = query_text
        context.user_data['key_index'] = key_index
        context.user_data['command'] = command

        keyboard = [[InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"), InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")]]
        message_obj.reply_text(f"æŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
        return STATE_ASK_CONTINENT
    
    else:
        logger.error("query_entry_point called with an unsupported update type.")
        return ConversationHandler.END

def get_guest_key(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    guest_key = update.message.text.strip()
    msg = update.message.reply_text("â³ æ­£åœ¨éªŒè¯æ‚¨çš„API Key...")
    data, error = verify_fofa_api(guest_key)
    if error:
        msg.edit_text(f"âŒ KeyéªŒè¯å¤±è´¥: {error}\nè¯·é‡æ–°è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„Keyï¼Œæˆ–ä½¿ç”¨ /cancel å–æ¶ˆã€‚")
        return STATE_GET_GUEST_KEY
    ANONYMOUS_KEYS[str(user_id)] = guest_key
    save_anonymous_keys()
    msg.edit_text(f"âœ… KeyéªŒè¯æˆåŠŸ ({data.get('username', 'N/A')})ï¼æ‚¨çš„Keyå·²ä¿å­˜ï¼Œç°åœ¨å¯ä»¥å¼€å§‹æŸ¥è¯¢äº†ã€‚")
    if 'pending_query' in context.user_data:
        context.args = context.user_data.pop('pending_query').split()
        return query_entry_point(update, context)
    return ConversationHandler.END

def ask_continent_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    command = context.user_data['command']

    if choice == 'skip':
        context.user_data['query'] = context.user_data['original_query']
        query.message.edit_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown_v2(context.user_data['query'])}`", parse_mode=ParseMode.MARKDOWN_V2)
        if command == '/kkfofa':
            return proceed_with_kkfofa_query(update, context, message_to_edit=query.message)
        elif command == '/allfofa':
            return start_allfofa_search(update, context, message_to_edit=query.message)
    elif choice == 'select':
        keyboard = [
            [InlineKeyboardButton("ğŸŒ äºšæ´²", callback_data="continent_Asia"), InlineKeyboardButton("ğŸŒ æ¬§æ´²", callback_data="continent_Europe")],
            [InlineKeyboardButton("ğŸŒ åŒ—ç¾æ´²", callback_data="continent_NorthAmerica"), InlineKeyboardButton("ğŸŒ å—ç¾æ´²", callback_data="continent_SouthAmerica")],
            [InlineKeyboardButton("ğŸŒ éæ´²", callback_data="continent_Africa"), InlineKeyboardButton("ğŸŒ å¤§æ´‹æ´²", callback_data="continent_Oceania")],
            [InlineKeyboardButton("â†©ï¸ è·³è¿‡", callback_data="continent_skip")]]
        query.message.edit_text("è¯·é€‰æ‹©ä¸€ä¸ªå¤§æ´²:", reply_markup=InlineKeyboardMarkup(keyboard)); return STATE_CONTINENT_CHOICE

def continent_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); continent = query.data.split('_', 1)[1]; original_query = context.user_data['original_query']
    command = context.user_data['command']

    if continent == 'skip':
        context.user_data['query'] = original_query
        query.message.edit_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown_v2(original_query)}`", parse_mode=ParseMode.MARKDOWN_V2)
    else:
        country_list = CONTINENT_COUNTRIES.get(continent)
        if not country_list: query.message.edit_text("âŒ é”™è¯¯ï¼šæ— æ•ˆçš„å¤§æ´²é€‰é¡¹ã€‚"); return ConversationHandler.END
        country_fofa_string = " || ".join([f'country="{code}"' for code in country_list]); final_query = f"({original_query}) && ({country_fofa_string})"
        context.user_data['query'] = final_query
        query.message.edit_text(f"æŸ¥è¯¢å·²æ„å»º:\n`{escape_markdown_v2(final_query)}`\n\næ­£åœ¨å¤„ç†\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)

    if command == '/kkfofa':
        return proceed_with_kkfofa_query(update, context, message_to_edit=query.message)
    elif command == '/allfofa':
        return start_allfofa_search(update, context, message_to_edit=query.message)

def proceed_with_kkfofa_query(update: Update, context: CallbackContext, message_to_edit):
    query_text = context.user_data['query']
    cached_item = find_cached_query(query_text)
    if cached_item:
        dt_utc = datetime.fromisoformat(cached_item['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        message_text = (f"âœ… *å‘ç°ç¼“å­˜*\n\næŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\nç¼“å­˜äº: *{escape_markdown_v2(time_str)}*\n\n")
        keyboard = []; is_expired = (datetime.now(tz.tzutc()) - dt_utc).total_seconds() > CACHE_EXPIRATION_SECONDS
        if is_expired or not is_admin(update.effective_user.id):
             message_text += "âš ï¸ *æ­¤ç¼“å­˜å·²è¿‡æœŸæˆ–æ‚¨æ˜¯è®¿å®¢ï¼Œæ— æ³•å¢é‡æ›´æ–°\\.*" if is_expired else ""
             keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½æ—§ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        else: 
            message_text += "è¯·é€‰æ‹©æ“ä½œï¼š"; keyboard.append([InlineKeyboardButton("ğŸ”„ å¢é‡æ›´æ–°", callback_data='cache_incremental')]); keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        keyboard.append([InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='cache_cancel')])
        message_to_edit.edit_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
        return STATE_CACHE_CHOICE
    return start_new_kkfofa_search(update, context, message_to_edit=message_to_edit)

def cache_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    if choice == 'download':
        cached_item = find_cached_query(context.user_data['query'])
        if cached_item:
            query.message.edit_text("â¬‡ï¸ æ­£åœ¨ä»æœ¬åœ°ç¼“å­˜å‘é€æ–‡ä»¶..."); file_path = cached_item['cache']['file_path']
            send_file_safely(context, update.effective_chat.id, file_path, filename=os.path.basename(file_path))
            upload_and_send_links(context, update.effective_chat.id, file_path)
            query.message.delete()
        else: query.message.edit_text("âŒ æ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜è®°å½•ã€‚")
        return ConversationHandler.END
    elif choice == 'newsearch': return start_new_kkfofa_search(update, context, message_to_edit=query.message)
    elif choice == 'incremental': query.edit_message_text("â³ å‡†å¤‡å¢é‡æ›´æ–°..."); start_download_job(context, run_incremental_update_query, context.user_data); query.message.delete(); return ConversationHandler.END
    elif choice == 'cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆã€‚"); return ConversationHandler.END

def start_new_kkfofa_search(update: Update, context: CallbackContext, message_to_edit=None):
    query_text = context.user_data['query']; key_index = context.user_data.get('key_index'); add_or_update_query(query_text)
    msg_text = f"ğŸ”„ æ­£åœ¨å¯¹ `{escape_markdown_v2(query_text)}` æ‰§è¡Œå…¨æ–°æŸ¥è¯¢\\.\\.\\."
    msg = message_to_edit if message_to_edit else update.effective_message.reply_text(msg_text, parse_mode=ParseMode.MARKDOWN_V2)
    if message_to_edit: msg.edit_text(msg_text, parse_mode=ParseMode.MARKDOWN_V2)
    
    guest_key = context.user_data.get('guest_key')
    if guest_key:
        data, error = fetch_fofa_data(guest_key, query_text, page_size=1, fields="host")
        used_key_info = "æ‚¨çš„Key"
    else:
        data, _, used_key_index, _, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query_text, page_size=1, fields="host", proxy_session=proxy_session),
            preferred_key_index=key_index
        )
        # v10.9 FIX: Escape the '#' character for MarkdownV2
        used_key_info = f"Key \\[\\#{used_key_index}\\]"
    if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
    total_size = data.get('size', 0)
    if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
    context.user_data.update({'total_size': total_size, 'chat_id': update.effective_chat.id, 'is_batch_mode': False})
    success_message = f"âœ… ä½¿ç”¨ {used_key_info} æ‰¾åˆ° {total_size} æ¡ç»“æœ\\."
    if total_size <= 10000:
        msg.edit_text(f"{success_message}\nå¼€å§‹ä¸‹è½½\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2); start_download_job(context, run_full_download_query, context.user_data)
        return ConversationHandler.END
    else:
        keyboard = [[InlineKeyboardButton("ğŸ’ å…¨éƒ¨ä¸‹è½½ (å‰1ä¸‡)", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯ä¸‹è½½", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
        msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2); return STATE_KKFOFA_MODE

def query_mode_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); mode = query.data.split('_')[1]
    if mode == 'cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆ."); return ConversationHandler.END
    if mode == 'traceback':
        keyboard = [[InlineKeyboardButton("â™¾ï¸ å…¨éƒ¨è·å–", callback_data='limit_none')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='limit_cancel')]]
        query.message.edit_text("è¯·è¾“å…¥æ·±åº¦è¿½æº¯è·å–çš„ç»“æœæ•°é‡ä¸Šé™ (ä¾‹å¦‚: 50000)ï¼Œæˆ–é€‰æ‹©å…¨éƒ¨è·å–ã€‚", reply_markup=InlineKeyboardMarkup(keyboard))
        return STATE_GET_TRACEBACK_LIMIT
    job_func = run_batch_download_query if context.user_data.get('is_batch_mode') else run_full_download_query
    if mode == 'full' and job_func:
        query.message.edit_text(f"â³ å¼€å§‹ä¸‹è½½..."); start_download_job(context, job_func, context.user_data); query.message.delete()
    return ConversationHandler.END

def get_traceback_limit(update: Update, context: CallbackContext):
    limit = None
    if update.callback_query:
        query = update.callback_query; query.answer()
        if query.data == 'limit_cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆ."); return ConversationHandler.END
    elif update.message:
        try:
            limit = int(update.message.text.strip()); assert limit > 0
        except (ValueError, AssertionError):
            update.message.reply_text("âŒ æ— æ•ˆçš„æ•°å­—ï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ­£æ•´æ•°ã€‚"); return STATE_GET_TRACEBACK_LIMIT
    context.user_data['limit'] = limit
    job_func = run_batch_traceback_query if context.user_data.get('is_batch_mode') else run_traceback_download_query
    msg_target = update.callback_query.message if update.callback_query else update.message
    msg_target.reply_text(f"â³ å¼€å§‹æ·±åº¦è¿½æº¯ (ä¸Šé™: {limit or 'æ— '})...")
    start_download_job(context, job_func, context.user_data)
    if update.callback_query: msg_target.delete()
    return ConversationHandler.END

# --- /host å’Œ /lowhost å‘½ä»¤ ---
def _create_dict_from_fofa_result(result_list, fields_list):
    return {fields_list[i]: result_list[i] for i in range(len(fields_list))}
def get_common_host_info(results, fields_list):
    if not results: return {}
    first_entry = _create_dict_from_fofa_result(results[0], fields_list)
    info = {
        "IP": first_entry.get('ip', 'N/A'),
        "åœ°ç†ä½ç½®": f"{first_entry.get('country_name', '')} {first_entry.get('region', '')} {first_entry.get('city', '')}".strip(),
        "ASN": f"{first_entry.get('asn', 'N/A')} ({first_entry.get('org', 'N/A')})",
        "æ“ä½œç³»ç»Ÿ": first_entry.get('os', 'N/A'),
    }
    port_index = fields_list.index('port') if 'port' in fields_list else -1
    if port_index != -1:
        all_ports = sorted(list(set(res[port_index] for res in results if len(res) > port_index)))
        info["å¼€æ”¾ç«¯å£"] = all_ports
    return info
def create_host_summary(host_arg, results, fields_list):
    info = get_common_host_info(results, fields_list)
    summary = [f"ğŸ“Œ *ä¸»æœºæ¦‚è§ˆ: `{escape_markdown_v2(host_arg)}`*"]
    for key, value in info.items():
        if value and value != 'N/A':
            if isinstance(value, list):
                summary.append(f"*{escape_markdown_v2(key)}:* `{escape_markdown_v2(', '.join(map(str, value)))}`")
            else:
                summary.append(f"*{escape_markdown_v2(key)}:* `{escape_markdown_v2(value)}`")
    summary.append("\nğŸ“„ *è¯¦ç»†æŠ¥å‘Šå·²ä½œä¸ºæ–‡ä»¶å‘é€\\.*")
    return "\n".join(summary)
def format_full_host_report(host_arg, results, fields_list):
    info = get_common_host_info(results, fields_list)
    report = [f"ğŸ“Œ *ä¸»æœºèšåˆæŠ¥å‘Š: `{escape_markdown_v2(host_arg)}`*\n"]
    for key, value in info.items():
        if value and value != 'N/A':
            if isinstance(value, list):
                report.append(f"*{escape_markdown_v2(key)}:* `{escape_markdown_v2(', '.join(map(str, value)))}`")
            else:
                report.append(f"*{escape_markdown_v2(key)}:* `{escape_markdown_v2(value)}`")
    report.append("\n\-\-\- *æœåŠ¡è¯¦æƒ…* \-\-\-\n")
    for res_list in results:
        d = _create_dict_from_fofa_result(res_list, fields_list)
        port_info = [f"ğŸŒ *Port `{d.get('port')}` \\({escape_markdown_v2(d.get('protocol', 'N/A'))}\\)*"]
        if d.get('title'): port_info.append(f"  - *æ ‡é¢˜:* `{escape_markdown_v2(d.get('title'))}`")
        if d.get('server'): port_info.append(f"  - *æœåŠ¡:* `{escape_markdown_v2(d.get('server'))}`")
        if d.get('icp'): port_info.append(f"  - *ICP:* `{escape_markdown_v2(d.get('icp'))}`")
        if d.get('jarm'): port_info.append(f"  - *JARM:* `{escape_markdown_v2(d.get('jarm'))}`")
        cert_str = d.get('cert', '{}')
        try:
            cert_info = json.loads(cert_str) if isinstance(cert_str, str) and cert_str.startswith('{') else {}
            if cert_info.get('issuer', {}).get('CN'): port_info.append(f"  - *è¯ä¹¦é¢å‘è€…:* `{escape_markdown_v2(cert_info['issuer']['CN'])}`")
            if cert_info.get('subject', {}).get('CN'): port_info.append(f"  - *è¯ä¹¦ä½¿ç”¨è€…:* `{escape_markdown_v2(cert_info['subject']['CN'])}`")
        except json.JSONDecodeError:
            pass
        if d.get('header'): port_info.append(f"  - *Header:* ```\n{d.get('header')}\n```")
        if d.get('banner'): port_info.append(f"  - *Banner:* ```\n{d.get('banner')}\n```")
        report.append("\n".join(port_info))
    return "\n".join(report)
def host_command_logic(update: Update, context: CallbackContext):
    if not context.args:
        update.message.reply_text(f"ç”¨æ³•: `/host <ip_or_domain>`\n\nç¤ºä¾‹:\n`/host 1\\.1\\.1\\.1`", parse_mode=ParseMode.MARKDOWN_V2)
        return
    host_arg = context.args[0]
    processing_message = update.message.reply_text(f"â³ æ­£åœ¨æŸ¥è¯¢ä¸»æœº `{escape_markdown_v2(host_arg)}`\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
    query = f'ip="{host_arg}"' if re.match(r"^\d{1,3}(\.\d{1,3}){3}$", host_arg) else f'domain="{host_arg}"'
    data, final_fields_list, error = None, [], None
    for level in range(3, -1, -1): 
        fields_to_try = get_fields_by_level(level)
        fields_str = ",".join(fields_to_try)
        try:
            processing_message.edit_text(f"â³ æ­£åœ¨å°è¯•ä»¥ *ç­‰çº§ {level}* å­—æ®µæŸ¥è¯¢\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
        except (BadRequest, RetryAfter, TimedOut):
            time.sleep(1)
        temp_data, _, _, _, _, temp_error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query, page_size=100, fields=fields_str, proxy_session=proxy_session)
        )
        if not temp_error:
            data = temp_data
            final_fields_list = fields_to_try
            error = None
            break
        if "[820001]" not in str(temp_error):
            error = temp_error
            break
        else:
            error = temp_error
            continue
    if error:
        processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{escape_markdown_v2(error)}`", parse_mode=ParseMode.MARKDOWN_V2)
        return
    raw_results = data.get('results', [])
    if not raw_results:
        processing_message.edit_text(f"ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°å…³äº `{escape_markdown_v2(host_arg)}` çš„ä»»ä½•ä¿¡æ¯\\.", parse_mode=ParseMode.MARKDOWN_V2)
        return
    
    unique_services = {}
    ip_idx = final_fields_list.index('ip') if 'ip' in final_fields_list else -1
    port_idx = final_fields_list.index('port') if 'port' in final_fields_list else -1
    protocol_idx = final_fields_list.index('protocol') if 'protocol' in final_fields_list else -1
    
    if port_idx != -1 and protocol_idx != -1:
        for res in raw_results:
            key = (res[ip_idx] if ip_idx != -1 else host_arg, res[port_idx], res[protocol_idx])
            if key not in unique_services:
                unique_services[key] = res
        results = list(unique_services.values())
    else:
        results = raw_results

    full_report = format_full_host_report(host_arg, results, final_fields_list)
    if len(full_report) > 3800:
        summary_report = create_host_summary(host_arg, results, final_fields_list)
        processing_message.edit_text(summary_report, parse_mode=ParseMode.MARKDOWN_V2, disable_web_page_preview=True)
        report_filename = f"host_details_{host_arg.replace('.', '_')}.txt"
        try:
            plain_text_report = re.sub(r'([*_`\[\]\\])', '', full_report)
            with open(report_filename, 'w', encoding='utf-8') as f: f.write(plain_text_report)
            send_file_safely(context, update.effective_chat.id, report_filename, caption="ğŸ“„ å®Œæ•´çš„è¯¦ç»†æŠ¥å‘Šå·²é™„ä¸Šã€‚")
            upload_and_send_links(context, update.effective_chat.id, report_filename)
        finally:
            if os.path.exists(report_filename): os.remove(report_filename)
    else:
        processing_message.edit_text(full_report, parse_mode=ParseMode.MARKDOWN_V2, disable_web_page_preview=True)
@admin_only
def host_command(update: Update, context: CallbackContext):
    host_command_logic(update, context)
def format_host_summary(data):
    parts = [f"ğŸ“Œ *ä¸»æœºèšåˆæ‘˜è¦: `{escape_markdown_v2(data.get('host', 'N/A'))}`*"]
    if data.get('ip'): parts.append(f"*IP:* `{escape_markdown_v2(data.get('ip'))}`")
    location = f"{data.get('country_name', '')} {data.get('region', '')} {data.get('city', '')}".strip()
    if location: parts.append(f"*ä½ç½®:* `{escape_markdown_v2(location)}`")
    if data.get('asn'): parts.append(f"*ASN:* `{data.get('asn')} \\({escape_markdown_v2(data.get('org', 'N/A'))}\\)`")
    
    if data.get('ports'):
        port_list = data.get('ports', [])
        if port_list and isinstance(port_list[0], dict):
            port_numbers = sorted([p.get('port') for p in port_list if p.get('port')])
            parts.append(f"*å¼€æ”¾ç«¯å£:* `{escape_markdown_v2(', '.join(map(str, port_numbers)))}`")
        else:
            parts.append(f"*å¼€æ”¾ç«¯å£:* `{escape_markdown_v2(', '.join(map(str, port_list)))}`")

    if data.get('protocols'): parts.append(f"*åè®®:* `{escape_markdown_v2(', '.join(data.get('protocols', [])))}`")
    if data.get('category'): parts.append(f"*èµ„äº§ç±»å‹:* `{escape_markdown_v2(', '.join(data.get('category', [])))}`")
    if data.get('products'):
        product_names = [p.get('name', 'N/A') for p in data.get('products', [])]
        parts.append(f"*äº§å“/ç»„ä»¶:* `{escape_markdown_v2(', '.join(product_names))}`")
    return "\n".join(parts)
def format_host_details(data):
    summary = format_host_summary(data)
    details = ["\n\-\-\- *ç«¯å£è¯¦æƒ…* \-\-\-"]
    for port_info in data.get('port_details', []):
        port_str = f"\nğŸŒ *Port `{port_info.get('port')}` \\({escape_markdown_v2(port_info.get('protocol', 'N/A'))}\\)*"
        if port_info.get('product'): port_str += f"\n  - *äº§å“:* `{escape_markdown_v2(port_info.get('product'))}`"
        if port_info.get('title'): port_str += f"\n  - *æ ‡é¢˜:* `{escape_markdown_v2(port_info.get('title'))}`"
        if port_info.get('jarm'): port_str += f"\n  - *JARM:* `{escape_markdown_v2(port_info.get('jarm'))}`"
        if port_info.get('banner'): port_str += f"\n  - *Banner:* ```\n{port_info.get('banner')}\n```"
        details.append(port_str)
    full_report = summary + "\n".join(details)
    return full_report
def lowhost_command(update: Update, context: CallbackContext) -> None:
    if not context.args:
        update.message.reply_text("ç”¨æ³•: `/lowhost <ip_or_domain> [detail]`\n\nç¤ºä¾‹:\n`/lowhost 1\\.1\\.1\\.1`\n`/lowhost example\\.com detail`", parse_mode=ParseMode.MARKDOWN_V2)
        return
    host = context.args[0]
    detail = len(context.args) > 1 and context.args[1].lower() == 'detail'
    processing_message = update.message.reply_text(f"æ­£åœ¨æŸ¥è¯¢ä¸»æœº `{escape_markdown_v2(host)}` çš„èšåˆä¿¡æ¯\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
    data, _, _, _, _, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_host_info(key, host, detail, proxy_session=proxy_session)
    )
    if error:
        processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{escape_markdown_v2(error)}`", parse_mode=ParseMode.MARKDOWN_V2)
        return
    if not data:
        processing_message.edit_text(f"ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°å…³äº `{escape_markdown_v2(host)}` çš„ä»»ä½•ä¿¡æ¯\\.", parse_mode=ParseMode.MARKDOWN_V2)
        return
    if detail:
        formatted_text = format_host_details(data)
    else:
        formatted_text = format_host_summary(data)
    if len(formatted_text) > 3800:
        processing_message.edit_text("æŠ¥å‘Šè¿‡é•¿ï¼Œå°†ä½œä¸ºæ–‡ä»¶å‘é€ã€‚")
        report_filename = f"lowhost_details_{host.replace('.', '_')}.txt"
        try:
            plain_text_report = re.sub(r'([*_`\[\]\\])', '', formatted_text)
            with open(report_filename, 'w', encoding='utf-8') as f: f.write(plain_text_report)
            send_file_safely(context, update.effective_chat.id, report_filename, caption="ğŸ“„ å®Œæ•´çš„èšåˆæŠ¥å‘Šå·²é™„ä¸Šã€‚")
            upload_and_send_links(context, update.effective_chat.id, report_filename)
        finally:
            if os.path.exists(report_filename): os.remove(report_filename)
    else:
        processing_message.edit_text(formatted_text, parse_mode=ParseMode.MARKDOWN_V2)

# --- /stats å‘½ä»¤ ---
@admin_only
def stats_command(update: Update, context: CallbackContext):
    if not context.args:
        update.message.reply_text("è¯·è¾“å…¥è¦è¿›è¡Œèšåˆç»Ÿè®¡çš„FOFAæŸ¥è¯¢è¯­æ³•:")
        return STATE_GET_STATS_QUERY
    return get_fofa_stats_query(update, context)
def get_fofa_stats_query(update: Update, context: CallbackContext):
    query_text = " ".join(context.args) if context.args else update.message.text
    msg = update.message.reply_text(f"â³ æ­£åœ¨å¯¹ `{escape_markdown_v2(query_text)}` è¿›è¡Œèšåˆç»Ÿè®¡\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
    data, _, _, _, _, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_stats(key, query_text, proxy_session=proxy_session)
    )
    if error: msg.edit_text(f"âŒ ç»Ÿè®¡å¤±è´¥: {error}"); return ConversationHandler.END
    report = [f"ğŸ“Š *èšåˆç»Ÿè®¡æŠ¥å‘Š for `{escape_markdown_v2(query_text)}`*\n"]
    for field, aggs in data.items():
        if aggs and isinstance(aggs, list):
            report.append(f"\-\-\- *{escape_markdown_v2(field.capitalize())}* \-\-\-")
            for item in aggs[:10]:
                report.append(f"`{escape_markdown_v2(item['name'])}`: {item['count']}")
            report.append("")
    msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN_V2)
    return ConversationHandler.END

# --- /batchfind å‘½ä»¤ ---
BATCH_FEATURES = { "protocol": "åè®®", "domain": "åŸŸå", "os": "æ“ä½œç³»ç»Ÿ", "server": "æœåŠ¡/ç»„ä»¶", "icp": "ICPå¤‡æ¡ˆå·", "title": "æ ‡é¢˜", "jarm": "JARMæŒ‡çº¹", "cert.issuer.org": "è¯ä¹¦é¢å‘ç»„ç»‡", "cert.issuer.cn": "è¯ä¹¦é¢å‘CN", "cert.subject.org": "è¯ä¹¦ä¸»ä½“ç»„ç»‡", "cert.subject.cn": "è¯ä¹¦ä¸»ä½“CN" }
@admin_only
def batchfind_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·ä¸Šä¼ ä¸€ä¸ªåŒ…å« IP:Port åˆ—è¡¨çš„ .txt æ–‡ä»¶ã€‚")
    return STATE_GET_BATCH_FILE
def get_batch_file_handler(update: Update, context: CallbackContext):
    doc = update.message.document
    file = doc.get_file()
    file_path = os.path.join(FOFA_CACHE_DIR, doc.file_name)
    file.download(custom_path=file_path)
    context.user_data['batch_file_path'] = file_path
    context.user_data['selected_features'] = set()
    keyboard = []
    features_list = list(BATCH_FEATURES.items())
    for i in range(0, len(features_list), 2):
        row = [InlineKeyboardButton(f"â˜ {features_list[i][1]}", callback_data=f"batchfeature_{features_list[i][0]}")]
        if i + 1 < len(features_list):
            row.append(InlineKeyboardButton(f"â˜ {features_list[i+1][1]}", callback_data=f"batchfeature_{features_list[i+1][0]}"))
        keyboard.append(row)
    keyboard.append([InlineKeyboardButton("âœ… å…¨éƒ¨é€‰æ‹©", callback_data="batchfeature_all"), InlineKeyboardButton("â¡ï¸ å¼€å§‹åˆ†æ", callback_data="batchfeature_done")])
    update.message.reply_text("è¯·é€‰æ‹©æ‚¨éœ€è¦åˆ†æçš„ç‰¹å¾:", reply_markup=InlineKeyboardMarkup(keyboard))
    return STATE_SELECT_BATCH_FEATURES
def select_batch_features_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); feature = query.data.split('_', 1)[1]
    selected = context.user_data['selected_features']
    if feature == 'done':
        if not selected: query.answer("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾ï¼", show_alert=True); return STATE_SELECT_BATCH_FEATURES
        query.message.edit_text("âœ… ç‰¹å¾é€‰æ‹©å®Œæ¯•ï¼Œä»»åŠ¡å·²æäº¤åˆ°åå°åˆ†æã€‚")
        job_context = {'chat_id': query.message.chat_id, 'file_path': context.user_data['batch_file_path'], 'features': list(selected)}
        context.job_queue.run_once(run_batch_find_job, 1, context=job_context, name=f"batchfind_{query.message.chat_id}")
        return ConversationHandler.END
    if feature == 'all':
        if len(selected) == len(BATCH_FEATURES): selected.clear()
        else: selected.update(BATCH_FEATURES.keys())
    elif feature in selected: selected.remove(feature)
    else: selected.add(feature)
    keyboard = []
    features_list = list(BATCH_FEATURES.items())
    for i in range(0, len(features_list), 2):
        row = []
        key1 = features_list[i][0]; row.append(InlineKeyboardButton(f"{'â˜‘' if key1 in selected else 'â˜'} {features_list[i][1]}", callback_data=f"batchfeature_{key1}"))
        if i + 1 < len(features_list):
            key2 = features_list[i+1][0]; row.append(InlineKeyboardButton(f"{'â˜‘' if key2 in selected else 'â˜'} {features_list[i+1][1]}", callback_data=f"batchfeature_{key2}"))
        keyboard.append(row)
    all_text = "âœ… å–æ¶ˆå…¨é€‰" if len(selected) == len(BATCH_FEATURES) else "âœ… å…¨éƒ¨é€‰æ‹©"
    keyboard.append([InlineKeyboardButton(all_text, callback_data="batchfeature_all"), InlineKeyboardButton("â¡ï¸ å¼€å§‹åˆ†æ", callback_data="batchfeature_done")])
    query.message.edit_reply_markup(reply_markup=InlineKeyboardMarkup(keyboard))
    return STATE_SELECT_BATCH_FEATURES
def run_batch_find_job(context: CallbackContext):
    job_data = context.job.context; chat_id, file_path, features = job_data['chat_id'], job_data['file_path'], job_data['features']
    bot = context.bot; msg = bot.send_message(chat_id, "â³ å¼€å§‹æ‰¹é‡åˆ†æä»»åŠ¡...")
    try:
        with open(file_path, 'r', encoding='utf-8') as f: targets = [line.strip() for line in f if line.strip()]
    except Exception as e: msg.edit_text(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}"); return
    if not targets: msg.edit_text("âŒ æ–‡ä»¶ä¸ºç©ºã€‚"); return
    total_targets = len(targets); processed_count = 0; detailed_results_for_excel = []
    for target in targets:
        processed_count += 1
        if processed_count % 10 == 0:
            try: msg.edit_text(f"åˆ†æè¿›åº¦: {create_progress_bar(processed_count/total_targets*100)} ({processed_count}/{total_targets})")
            except (BadRequest, RetryAfter, TimedOut): pass
        query = f'ip="{target}"' if ':' not in target else f'host="{target}"'
        data, _, _, _, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query, page_size=1, fields=",".join(features), proxy_session=proxy_session)
        )
        if not error and data.get('results'):
            result = data['results'][0]
            row_data = {'Target': target}
            row_data.update({BATCH_FEATURES.get(f, f): result[i] for i, f in enumerate(features)})
            detailed_results_for_excel.append(row_data)
    if detailed_results_for_excel:
        try:
            df = pd.DataFrame(detailed_results_for_excel)
            excel_filename = generate_filename_from_query(os.path.basename(file_path), prefix="analysis", ext=".xlsx")
            df.to_excel(excel_filename, index=False, engine='openpyxl')
            msg.edit_text("âœ… åˆ†æå®Œæˆï¼æ­£åœ¨å‘é€ExcelæŠ¥å‘Š...")
            send_file_safely(context, chat_id, excel_filename, caption="ğŸ“„ è¯¦ç»†ç‰¹å¾åˆ†æExcelæŠ¥å‘Š")
            upload_and_send_links(context, chat_id, excel_filename)
            os.remove(excel_filename)
        except Exception as e: msg.edit_text(f"âŒ ç”ŸæˆExcelå¤±è´¥: {e}")
    else: msg.edit_text("ğŸ¤·â€â™€ï¸ åˆ†æå®Œæˆï¼Œä½†æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„FOFAæ•°æ®ã€‚")
    if os.path.exists(file_path): os.remove(file_path)

# --- /batch (äº¤äº’å¼) ---
def build_batch_fields_keyboard(user_data):
    selected_fields = user_data.get('selected_fields', set())
    page = user_data.get('page', 0)
    flat_fields = []
    for category, fields in FIELD_CATEGORIES.items():
        for field in fields:
            flat_fields.append((field, category))
    items_per_page = 12
    start_index = page * items_per_page
    end_index = start_index + items_per_page
    page_items = flat_fields[start_index:end_index]
    keyboard = []
    for i in range(0, len(page_items), 2):
        row = []
        field1, cat1 = page_items[i]
        prefix1 = "â˜‘ï¸" if field1 in selected_fields else "â˜"
        row.append(InlineKeyboardButton(f"{prefix1} {field1}", callback_data=f"batchfield_toggle_{field1}"))
        if i + 1 < len(page_items):
            field2, cat2 = page_items[i+1]
            prefix2 = "â˜‘ï¸" if field2 in selected_fields else "â˜"
            row.append(InlineKeyboardButton(f"{prefix2} {field2}", callback_data=f"batchfield_toggle_{field2}"))
        keyboard.append(row)
    nav_row = []
    if page > 0:
        nav_row.append(InlineKeyboardButton("â¬…ï¸ ä¸Šä¸€é¡µ", callback_data="batchfield_prev"))
    if end_index < len(flat_fields):
        nav_row.append(InlineKeyboardButton("ä¸‹ä¸€é¡µ â¡ï¸", callback_data="batchfield_next"))
    keyboard.append(nav_row)
    keyboard.append([InlineKeyboardButton("âœ… å®Œæˆé€‰æ‹©å¹¶å¼€å§‹", callback_data="batchfield_done")])
    return InlineKeyboardMarkup(keyboard)
@admin_only
def batch_command(update: Update, context: CallbackContext):
    if not context.args:
        update.message.reply_text("ç”¨æ³•: `/batch <fofa_query>`")
        return ConversationHandler.END
    query_text = " ".join(context.args)
    context.user_data['query'] = query_text
    context.user_data['selected_fields'] = set(FREE_FIELDS[:5])
    context.user_data['page'] = 0
    keyboard = build_batch_fields_keyboard(context.user_data)
    update.message.reply_text(f"æŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\nè¯·é€‰æ‹©è¦å¯¼å‡ºçš„å­—æ®µ:", reply_markup=keyboard, parse_mode=ParseMode.MARKDOWN_V2)
    return STATE_BATCH_SELECT_FIELDS
def batch_select_fields_callback(update: Update, context: CallbackContext):
    query = update.callback_query
    query.answer()
    action = query.data.split('_', 1)[1]
    if action == "next":
        context.user_data['page'] += 1
    elif action == "prev":
        context.user_data['page'] -= 1
    elif action.startswith("toggle_"):
        field = action.replace("toggle_", "")
        if field in context.user_data['selected_fields']:
            context.user_data['selected_fields'].remove(field)
        else:
            context.user_data['selected_fields'].add(field)
    elif action == "done":
        selected_fields = context.user_data.get('selected_fields')
        if not selected_fields:
            query.answer("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå­—æ®µï¼", show_alert=True)
            return STATE_BATCH_SELECT_FIELDS
        query_text = context.user_data['query']
        fields_str = ",".join(list(selected_fields))
        msg = query.message.edit_text("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢ä»¥é¢„ä¼°æ•°æ®é‡...")
        data, _, used_key_index, key_level, _, error = execute_query_with_fallback(
            lambda key, key_level, proxy_session: fetch_fofa_data(key, query_text, page_size=1, fields="host", proxy_session=proxy_session)
        )
        if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
        total_size = data.get('size', 0)
        if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
        allowed_fields = get_fields_by_level(key_level)
        unauthorized_fields = [f for f in selected_fields if f not in allowed_fields]
        if unauthorized_fields:
            msg.edit_text(f"âš ï¸ è­¦å‘Š: æ‚¨é€‰æ‹©çš„å­—æ®µ `{', '.join(unauthorized_fields)}` è¶…å‡ºå½“å‰å¯ç”¨æœ€é«˜çº§Key (ç­‰çº§{key_level}) çš„æƒé™ã€‚è¯·é‡æ–°é€‰æ‹©æˆ–å‡çº§Keyã€‚")
            return ConversationHandler.END
        context.user_data.update({'chat_id': update.effective_chat.id, 'fields': fields_str, 'total_size': total_size, 'is_batch_mode': True })
        success_message = f"âœ… ä½¿ç”¨ Key \\[\\#{used_key_index}\\] \\(ç­‰çº§{key_level}\\) æ‰¾åˆ° {total_size} æ¡ç»“æœ\\."
        if total_size <= 10000:
            msg.edit_text(f"{success_message}\nå¼€å§‹è‡ªå®šä¹‰å­—æ®µæ‰¹é‡å¯¼å‡º\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2); start_download_job(context, run_batch_download_query, context.user_data)
            return ConversationHandler.END
        else:
            keyboard = [[InlineKeyboardButton("ğŸ’ å¯¼å‡ºå‰1ä¸‡æ¡", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯å¯¼å‡º", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
            msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©å¯¼å‡ºæ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2); return STATE_KKFOFA_MODE
    keyboard = build_batch_fields_keyboard(context.user_data)
    query.message.edit_reply_markup(reply_markup=keyboard)
    return STATE_BATCH_SELECT_FIELDS

# --- /batchcheckapi å‘½ä»¤ ---
@admin_only
def batch_check_api_command(update: Update, context: CallbackContext) -> int:
    update.message.reply_text("è¯·ä¸Šä¼ ä¸€ä¸ªåŒ…å« API Keys çš„ .txt æ–‡ä»¶ (æ¯è¡Œä¸€ä¸ª Key)ã€‚")
    return STATE_GET_API_FILE
def receive_api_file(update: Update, context: CallbackContext) -> int:
    doc = update.message.document
    if not doc.file_name.endswith('.txt'):
        update.message.reply_text("âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ä¸Šä¼  .txt æ–‡ä»¶ã€‚")
        return ConversationHandler.END
    file = doc.get_file()
    temp_path = os.path.join(FOFA_CACHE_DIR, f"api_check_{doc.file_id}.txt")
    file.download(custom_path=temp_path)
    try:
        with open(temp_path, 'r', encoding='utf-8') as f:
            keys_to_check = [line.strip() for line in f if line.strip()]
    except Exception as e:
        update.message.reply_text(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        if os.path.exists(temp_path): os.remove(temp_path)
        return ConversationHandler.END
    if not keys_to_check:
        update.message.reply_text("ğŸ¤·â€â™€ï¸ æ–‡ä»¶ä¸ºç©ºæˆ–ä¸åŒ…å«ä»»ä½•æœ‰æ•ˆçš„ Keyã€‚")
        if os.path.exists(temp_path): os.remove(temp_path)
        return ConversationHandler.END
    msg = update.message.reply_text(f"â³ å¼€å§‹æ‰¹é‡éªŒè¯ {len(keys_to_check)} ä¸ª API Key...")
    valid_keys, invalid_keys = [], []
    total = len(keys_to_check)
    for i, key in enumerate(keys_to_check):
        data, error = verify_fofa_api(key)
        if not error:
            is_vip = data.get('isvip', False)
            api_level = data.get('vip_level', 0)
            level = 0
            if is_vip:
                if api_level == 2: level = 1
                elif api_level == 3: level = 2
                elif api_level >= 4: level = 3
                else: level = 1
            level_name = {0: "å…è´¹", 1: "ä¸ªäºº", 2: "å•†ä¸š", 3: "ä¼ä¸š"}.get(level, "æœªçŸ¥")
            valid_keys.append(f"`...{key[-4:]}` \\- âœ… *æœ‰æ•ˆ* \\({escape_markdown_v2(data.get('username', 'N/A'))}, {level_name}ä¼šå‘˜\\)")
        else:
            invalid_keys.append(f"`...{key[-4:]}` \\- âŒ *æ— æ•ˆ* \\(åŸå› : {escape_markdown_v2(error)}\\)")
        if (i + 1) % 10 == 0 or (i + 1) == total:
            try:
                progress_text = f"â³ éªŒè¯è¿›åº¦: {create_progress_bar((i+1)/total*100)} ({i+1}/{total})"
                msg.edit_text(progress_text)
            except (BadRequest, RetryAfter, TimedOut):
                time.sleep(2)
    
    report = [f"ğŸ“‹ *æ‰¹é‡API KeyéªŒè¯æŠ¥å‘Š*"]
    report.append(f"\næ€»è®¡: {total} \\| æœ‰æ•ˆ: {len(valid_keys)} \\| æ— æ•ˆ: {len(invalid_keys)}\n")
    if valid_keys:
        report.append("\-\-\- *æœ‰æ•ˆ Keys* \-\-\-")
        report.extend(valid_keys)
    if invalid_keys:
        report.append("\n\-\-\- *æ— æ•ˆ Keys* \-\-\-")
        report.extend(invalid_keys)
    
    report_text = "\n".join(report)
    if len(report_text) > 3800:
        summary = f"âœ… éªŒè¯å®Œæˆï¼\næ€»è®¡: {total} \\| æœ‰æ•ˆ: {len(valid_keys)} \\| æ— æ•ˆ: {len(invalid_keys)}\n\næŠ¥å‘Šè¿‡é•¿ï¼Œå·²ä½œä¸ºæ–‡ä»¶å‘é€\\."
        msg.edit_text(summary)
        report_filename = f"api_check_report_{int(time.time())}.txt"
        try:
            plain_text_report = re.sub(r'([*_`\[\]\\])', '', report_text)
            with open(report_filename, 'w', encoding='utf-8') as f: f.write(plain_text_report)
            send_file_safely(context, update.effective_chat.id, report_filename)
        finally:
            if os.path.exists(report_filename): os.remove(report_filename)
    else:
        msg.edit_text(report_text, parse_mode=ParseMode.MARKDOWN_V2)

    if os.path.exists(temp_path): os.remove(temp_path)
    return ConversationHandler.END

# --- å…¶ä»–ç®¡ç†å‘½ä»¤ ---
@admin_only
def check_command(update: Update, context: CallbackContext):
    msg = update.message.reply_text("â³ æ­£åœ¨æ‰§è¡Œç³»ç»Ÿè‡ªæ£€...")
    report = ["*ğŸ“‹ ç³»ç»Ÿè‡ªæ£€æŠ¥å‘Š*"]
    try:
        global CONFIG; CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
        report.append("âœ… *é…ç½®æ–‡ä»¶*: `config\\.json` åŠ è½½æ­£å¸¸")
    except Exception as e:
        report.append(f"âŒ *é…ç½®æ–‡ä»¶*: åŠ è½½å¤±è´¥ \\- {escape_markdown_v2(str(e))}")
        msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN_V2); return
    report.append("\n*ğŸ”‘ API Keys:*")
    if not CONFIG.get('apis'): report.append("  \\- âš ï¸ æœªé…ç½®ä»»ä½• API Key")
    else:
        for i, key in enumerate(CONFIG['apis']):
            level = KEY_LEVELS.get(key, -1)
            level_name = {-1: "âŒ æ— æ•ˆ", 0: "âœ… å…è´¹", 1: "âœ… ä¸ªäºº", 2: "âœ… å•†ä¸š", 3: "âœ… ä¼ä¸š"}.get(level, "æœªçŸ¥")
            report.append(f"  `#{i+1}` (`...{key[-4:]}`): {level_name}")
    report.append("\n*ğŸŒ ä»£ç†:*")
    proxies_to_check = CONFIG.get("proxies", [])
    if not proxies_to_check and CONFIG.get("proxy"): proxies_to_check.append(CONFIG.get("proxy"))
    if not proxies_to_check: report.append("  \\- â„¹ï¸ æœªé…ç½®ä»£ç†")
    else:
        for p in proxies_to_check:
            try:
                requests.get("https://fofa.info", proxies={"http": p, "https": p}, timeout=10, verify=False)
                report.append(f"  \\- `{escape_markdown_v2(p)}`: âœ… è¿æ¥æˆåŠŸ")
            except Exception as e: report.append(f"  \\- `{escape_markdown_v2(p)}`: âŒ è¿æ¥å¤±è´¥ \\- `{escape_markdown_v2(str(e))}`")
    msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN_V2)
@admin_only
def stop_all_tasks(update: Update, context: CallbackContext):
    chat_id = update.effective_chat.id
    context.bot_data[f'stop_job_{chat_id}'] = True
    update.message.reply_text("ğŸ›‘ å·²å‘é€åœæ­¢ä¿¡å·ï¼Œå½“å‰ä¸‹è½½ä»»åŠ¡å°†åœ¨å®Œæˆæœ¬é¡µååœæ­¢ã€‚")
@admin_only
def backup_config_command(update: Update, context: CallbackContext):
    if os.path.exists(CONFIG_FILE):
        send_file_safely(context, update.effective_chat.id, CONFIG_FILE)
        upload_and_send_links(context, update.effective_chat.id, CONFIG_FILE)
    else: update.effective_chat.send_message("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ã€‚")
@admin_only
def restore_config_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·å‘é€æ‚¨çš„ `config.json` å¤‡ä»½æ–‡ä»¶ã€‚")
    return STATE_GET_RESTORE_FILE
def receive_config_file(update: Update, context: CallbackContext):
    doc = update.message.document
    if doc.file_name != 'config.json':
        update.message.reply_text("âŒ æ–‡ä»¶åé”™è¯¯ï¼Œè¯·ç¡®ä¿æ‚¨ä¸Šä¼ çš„æ˜¯ `config.json`ã€‚")
        return ConversationHandler.END
    file = doc.get_file()
    file.download(custom_path=CONFIG_FILE)
    global CONFIG; CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
    update.message.reply_text("âœ… é…ç½®æ–‡ä»¶å·²æ¢å¤ã€‚æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ä»¥åº”ç”¨æ›´æ”¹ã€‚")
    shutdown_command(update, context, restart=True)
    return ConversationHandler.END
@admin_only
def history_command(update: Update, context: CallbackContext):
    if not HISTORY['queries']: update.message.reply_text("æŸ¥è¯¢å†å²ä¸ºç©ºã€‚"); return
    history_text = "*ğŸ•°ï¸ æœ€è¿‘æŸ¥è¯¢å†å²*\n\n"
    for i, item in enumerate(HISTORY['queries'][:15]):
        dt_utc = datetime.fromisoformat(item['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        history_text += f"`{i+1}\\.` `{escape_markdown_v2(item['query_text'])}`\n   _{escape_markdown_v2(time_str)}_\n"
    update.message.reply_text(history_text, parse_mode=ParseMode.MARKDOWN_V2)
@admin_only
def import_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·å‘é€æ‚¨è¦å¯¼å…¥çš„æ—§ç¼“å­˜æ–‡ä»¶ (txtæ ¼å¼)ã€‚")
    return STATE_GET_IMPORT_QUERY
def get_import_query(update: Update, context: CallbackContext):
    doc = update.message.document
    if not doc.file_name.endswith('.txt'): update.message.reply_text("âŒ è¯·ä¸Šä¼  .txt æ–‡ä»¶ã€‚"); return ConversationHandler.END
    file = doc.get_file()
    temp_path = os.path.join(FOFA_CACHE_DIR, f"import_{doc.file_id}.txt")
    file.download(custom_path=temp_path)
    try:
        with open(temp_path, 'r', encoding='utf-8') as f: result_count = sum(1 for _ in f)
    except Exception as e: update.message.reply_text(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}"); os.remove(temp_path); return ConversationHandler.END
    query_text = update.message.text
    if not query_text: update.message.reply_text("è¯·è¾“å…¥ä¸æ­¤æ–‡ä»¶å…³è”çš„åŸå§‹FOFAæŸ¥è¯¢è¯­æ³•:"); return STATE_GET_IMPORT_QUERY
    final_filename = generate_filename_from_query(query_text)
    final_path = os.path.join(FOFA_CACHE_DIR, final_filename)
    shutil.move(temp_path, final_path)
    cache_data = {'file_path': final_path, 'result_count': result_count}
    add_or_update_query(query_text, cache_data)
    update.message.reply_text(f"âœ… æˆåŠŸå¯¼å…¥ç¼“å­˜ï¼\næŸ¥è¯¢: `{escape_markdown_v2(query_text)}`\nå…± {result_count} æ¡è®°å½•\\.", parse_mode=ParseMode.MARKDOWN_V2)
    return ConversationHandler.END
@admin_only
def get_log_command(update: Update, context: CallbackContext):
    if os.path.exists(LOG_FILE):
        send_file_safely(context, update.effective_chat.id, LOG_FILE)
        upload_and_send_links(context, update.effective_chat.id, LOG_FILE)
    else: update.message.reply_text("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚")

@admin_only
def shutdown_command(update: Update, context: CallbackContext, restart=False):
    message = "ğŸ¤– æœºå™¨äººæ­£åœ¨é‡å¯..." if restart else "ğŸ¤– æœºå™¨äººæ­£åœ¨å…³é—­..."
    update.message.reply_text(message)
    logger.info(f"Shutdown/Restart initiated by user {update.effective_user.id}")
    
    # v10.9 FIX: Use OS signals for a truly robust and deadlock-free shutdown.
    # This sends a SIGINT signal (like Ctrl+C) to the bot's own process,
    # which updater.idle() is designed to catch gracefully.
    threading.Thread(target=lambda: (time.sleep(1), os.kill(os.getpid(), signal.SIGINT))).start()

@admin_only
def update_script_command(update: Update, context: CallbackContext):
    update_url = CONFIG.get("update_url")
    if not update_url:
        update.message.reply_text("âŒ æœªåœ¨è®¾ç½®ä¸­é…ç½®æ›´æ–°URLã€‚è¯·ä½¿ç”¨ /settings \\-\\> è„šæœ¬æ›´æ–° \\-\\> è®¾ç½®URLã€‚")
        return
    msg = update.message.reply_text("â³ æ­£åœ¨ä»è¿œç¨‹URLä¸‹è½½æ–°è„šæœ¬...")
    try:
        response = requests.get(update_url, timeout=30, proxies=get_proxies())
        response.raise_for_status()
        script_content = response.text
        with open(__file__, 'w', encoding='utf-8') as f:
            f.write(script_content)
        msg.edit_text("âœ… è„šæœ¬æ›´æ–°æˆåŠŸï¼æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ä»¥åº”ç”¨æ–°ç‰ˆæœ¬ã€‚")
        shutdown_command(update, context, restart=True)
    except Exception as e:
        msg.edit_text(f"âŒ æ›´æ–°å¤±è´¥: {escape_markdown_v2(str(e))}", parse_mode=ParseMode.MARKDOWN_V2)

# --- è®¾ç½®èœå• ---
@admin_only
def settings_command(update: Update, context: CallbackContext):
    keyboard = [
        [InlineKeyboardButton("ğŸ”‘ API ç®¡ç†", callback_data='settings_api'), InlineKeyboardButton("âœ¨ é¢„è®¾ç®¡ç†", callback_data='settings_preset')],
        [InlineKeyboardButton("ğŸŒ ä»£ç†æ± ç®¡ç†", callback_data='settings_proxypool'), InlineKeyboardButton("ğŸ“¤ ä¸Šä¼ æ¥å£è®¾ç½®", callback_data='settings_upload')],
        [InlineKeyboardButton("ğŸ’¾ å¤‡ä»½ä¸æ¢å¤", callback_data='settings_backup'), InlineKeyboardButton("ğŸ”„ è„šæœ¬æ›´æ–°", callback_data='settings_update')],
        [InlineKeyboardButton("âŒ å…³é—­èœå•", callback_data='settings_close')]
    ]
    message_text = "âš™ï¸ *è®¾ç½®èœå•*"; reply_markup = InlineKeyboardMarkup(keyboard)
    if update.callback_query: update.callback_query.message.edit_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN_V2)
    else: update.message.reply_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN_V2)
    return STATE_SETTINGS_MAIN
def settings_callback_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); menu = query.data.split('_', 1)[1]
    if menu == 'api': return show_api_menu(update, context, force_check=False)
    if menu == 'proxypool': return show_proxypool_menu(update, context)
    if menu == 'backup': return show_backup_restore_menu(update, context)
    if menu == 'preset': return show_preset_menu(update, context)
    if menu == 'update': return show_update_menu(update, context)
    if menu == 'upload': return show_upload_api_menu(update, context)
    if menu == 'close': query.message.edit_text("èœå•å·²å…³é—­."); return ConversationHandler.END
    return STATE_SETTINGS_ACTION
def settings_action_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'add_api': query.message.edit_text("è¯·è¾“å…¥æ–°çš„FOFA API Key:"); return STATE_GET_KEY
    if action == 'remove_api': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„API Keyçš„ç¼–å·:"); return STATE_REMOVE_API
    if action == 'check_api': return show_api_menu(update, context, force_check=True)
    if action == 'back': return settings_command(update, context)
def show_api_menu(update: Update, context: CallbackContext, force_check=False):
    query = update.callback_query
    if force_check: 
        query.message.edit_text("â³ æ­£åœ¨é‡æ–°æ£€æŸ¥æ‰€æœ‰API KeyçŠ¶æ€...")
        check_and_classify_keys()
    api_list_text = ["*ğŸ”‘ å½“å‰ API Keys:*"]
    if not CONFIG['apis']: api_list_text.append("  \\- _ç©º_")
    else:
        for i, key in enumerate(CONFIG['apis']):
            level = KEY_LEVELS.get(key, -1)
            level_name = {-1: "âŒ æ— æ•ˆ", 0: "âœ… å…è´¹", 1: "âœ… ä¸ªäºº", 2: "âœ… å•†ä¸š", 3: "âœ… ä¼ä¸š"}.get(level, "æœªçŸ¥")
            api_list_text.append(f"  `\\#{i+1}` `...{key[-4:]}` \\- {level_name}")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='action_add_api'), InlineKeyboardButton("â– ç§»é™¤", callback_data='action_remove_api')],
        [InlineKeyboardButton("ğŸ”„ çŠ¶æ€æ£€æŸ¥", callback_data='action_check_api'), InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back')]
    ]
    query.message.edit_text("\n".join(api_list_text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return STATE_SETTINGS_ACTION
def get_key(update: Update, context: CallbackContext):
    new_key = update.message.text.strip()
    if new_key not in CONFIG['apis']: 
        CONFIG['apis'].append(new_key); save_config()
        check_and_classify_keys()
        update.message.reply_text("âœ… API Key å·²æ·»åŠ ã€‚")
    else: update.message.reply_text("âš ï¸ æ­¤ Key å·²å­˜åœ¨ã€‚")
    return settings_command(update, context)
def remove_api(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['apis']):
            removed_key = CONFIG['apis'].pop(index); save_config()
            check_and_classify_keys()
            update.message.reply_text(f"âœ… å·²ç§»é™¤ Key `...{removed_key[-4:]}`ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def show_preset_menu(update: Update, context: CallbackContext):
    query = update.callback_query; presets = CONFIG.get("presets", [])
    text = ["*âœ¨ é¢„è®¾æŸ¥è¯¢ç®¡ç†*"]
    if not presets: text.append("  \\- _ç©º_")
    else:
        for i, p in enumerate(presets): text.append(f"`{i+1}\\.` *{escape_markdown_v2(p['name'])}*: `{escape_markdown_v2(p['query'])}`")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='preset_add'), InlineKeyboardButton("â– ç§»é™¤", callback_data='preset_remove')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='preset_back')]
    ]
    query.message.edit_text("\n".join(text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return STATE_PRESET_MENU
def preset_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_')[1]
    if action == 'add': query.message.edit_text("è¯·è¾“å…¥é¢„è®¾çš„åç§°:"); return STATE_GET_PRESET_NAME
    if action == 'remove': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„é¢„è®¾çš„ç¼–å·:"); return STATE_REMOVE_PRESET
    if action == 'back': return settings_command(update, context)
def get_preset_name(update: Update, context: CallbackContext):
    context.user_data['preset_name'] = update.message.text.strip()
    update.message.reply_text("è¯·è¾“å…¥æ­¤é¢„è®¾çš„FOFAæŸ¥è¯¢è¯­æ³•:")
    return STATE_GET_PRESET_QUERY
def get_preset_query(update: Update, context: CallbackContext):
    preset_query = update.message.text.strip(); preset_name = context.user_data['preset_name']
    CONFIG.setdefault("presets", []).append({"name": preset_name, "query": preset_query}); save_config()
    update.message.reply_text("âœ… é¢„è®¾å·²æ·»åŠ ã€‚")
    return settings_command(update, context)
def remove_preset(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['presets']):
            CONFIG['presets'].pop(index); save_config()
            update.message.reply_text("âœ… é¢„è®¾å·²ç§»é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def show_update_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    url = CONFIG.get("update_url") or "æœªè®¾ç½®"
    text = f"ğŸ”„ *è„šæœ¬æ›´æ–°è®¾ç½®*\n\nå½“å‰æ›´æ–°URL: `{escape_markdown_v2(url)}`"
    keyboard = [[InlineKeyboardButton("âœï¸ è®¾ç½®URL", callback_data='update_set_url'), InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='update_back')]]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return STATE_SETTINGS_ACTION
def get_update_url(update: Update, context: CallbackContext):
    url = update.message.text.strip()
    if url.lower().startswith('http'): CONFIG['update_url'] = url; save_config(); update.message.reply_text("âœ… æ›´æ–°URLå·²è®¾ç½®ã€‚")
    else: update.message.reply_text("âŒ æ— æ•ˆçš„URLæ ¼å¼ã€‚")
    return settings_command(update, context)
def show_backup_restore_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    text = "ğŸ’¾ *å¤‡ä»½ä¸æ¢å¤*\n\n\\- *å¤‡ä»½*: å‘é€å½“å‰çš„ `config\\.json` æ–‡ä»¶ç»™æ‚¨ã€‚\n\\- *æ¢å¤*: æ‚¨éœ€è¦å‘æœºå™¨äººå‘é€ä¸€ä¸ª `config\\.json` æ–‡ä»¶æ¥è¦†ç›–å½“å‰é…ç½®ã€‚"
    keyboard = [[InlineKeyboardButton("ğŸ“¤ å¤‡ä»½", callback_data='backup_now'), InlineKeyboardButton("ğŸ“¥ æ¢å¤", callback_data='restore_now')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='backup_back')]]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return STATE_SETTINGS_ACTION
def show_proxypool_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    proxies = CONFIG.get("proxies", [])
    text = ["*ğŸŒ ä»£ç†æ± ç®¡ç†*"]
    if not proxies: text.append("  \\- _ç©º_")
    else:
        for i, p in enumerate(proxies): text.append(f"`{i+1}\\.` `{escape_markdown_v2(p)}`")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='proxypool_add'), InlineKeyboardButton("â– ç§»é™¤", callback_data='proxypool_remove')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='proxypool_back')]
    ]
    query.message.edit_text("\n".join(text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN_V2)
    return STATE_PROXYPOOL_MENU
def proxypool_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_')[1]
    if action == 'add': query.message.edit_text("è¯·è¾“å…¥è¦æ·»åŠ çš„ä»£ç† (æ ¼å¼: `http://user:pass@host:port`):"); return STATE_GET_PROXY_ADD
    if action == 'remove': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„ä»£ç†çš„ç¼–å·:"); return STATE_GET_PROXY_REMOVE
    if action == 'back': return settings_command(update, context)
def get_proxy_to_add(update: Update, context: CallbackContext):
    proxy = update.message.text.strip()
    if proxy not in CONFIG['proxies']: CONFIG['proxies'].append(proxy); save_config(); update.message.reply_text("âœ… ä»£ç†å·²æ·»åŠ ã€‚")
    else: update.message.reply_text("âš ï¸ æ­¤ä»£ç†å·²å­˜åœ¨ã€‚")
    return settings_command(update, context)
def get_proxy_to_remove(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['proxies']):
            CONFIG['proxies'].pop(index); save_config()
            update.message.reply_text("âœ… ä»£ç†å·²ç§»é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def show_upload_api_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    url = CONFIG.get("upload_api_url") or "æœªè®¾ç½®"
    token_status = "å·²è®¾ç½®" if CONFIG.get("upload_api_token") else "æœªè®¾ç½®"
    text = (f"ğŸ“¤ *ä¸Šä¼ æ¥å£è®¾ç½®*\n\n"
            f"æ­¤åŠŸèƒ½å¯å°†æœºå™¨äººç”Ÿæˆçš„æ‰€æœ‰æ–‡ä»¶è‡ªåŠ¨ä¸Šä¼ åˆ°æ‚¨æŒ‡å®šçš„æœåŠ¡å™¨ï¼Œå¹¶è¿”å›ä¸‹è½½å‘½ä»¤ã€‚\n\n"
            f"*API URL:* `{escape_markdown_v2(url)}`\n"
            f"*API Token:* `{token_status}`")
    kbd = [
        [InlineKeyboardButton("âœï¸ è®¾ç½® URL", callback_data='upload_set_url'), InlineKeyboardButton("ğŸ”‘ è®¾ç½® Token", callback_data='upload_set_token')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='upload_back')]
    ]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(kbd), parse_mode=ParseMode.MARKDOWN_V2)
    return STATE_UPLOAD_API_MENU
def upload_api_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back': return settings_command(update, context)
    if action == 'set_url': query.message.edit_text("è¯·è¾“å…¥æ‚¨çš„ä¸Šä¼ æ¥å£ URL:"); return STATE_GET_UPLOAD_URL
    if action == 'set_token': query.message.edit_text("è¯·è¾“å…¥æ‚¨çš„ä¸Šä¼ æ¥å£ Token:"); return STATE_GET_UPLOAD_TOKEN
    return STATE_UPLOAD_API_MENU
def get_upload_url(update: Update, context: CallbackContext):
    url = update.message.text.strip()
    if url.lower().startswith('http'):
        CONFIG['upload_api_url'] = url; save_config()
        update.message.reply_text("âœ… ä¸Šä¼  URL å·²æ›´æ–°ã€‚")
    else: update.message.reply_text("âŒ æ— æ•ˆçš„ URL æ ¼å¼ã€‚")
    return settings_command(update, context)
def get_upload_token(update: Update, context: CallbackContext):
    token = update.message.text.strip()
    CONFIG['upload_api_token'] = token; save_config()
    update.message.reply_text("âœ… ä¸Šä¼  Token å·²æ›´æ–°ã€‚")
    return settings_command(update, context)

# --- /allfofa Command Logic ---
def start_allfofa_search(update: Update, context: CallbackContext, message_to_edit=None):
    query_text = context.user_data['query']
    msg = message_to_edit if message_to_edit else update.effective_message.reply_text(f"ğŸšš æ­£åœ¨ä¸ºæŸ¥è¯¢ `{escape_markdown_v2(query_text)}` å‡†å¤‡æµ·é‡æ•°æ®è·å–ä»»åŠ¡\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
    
    # v10.9.5 FIX: Set min_level=1 for /allfofa pre-check to ensure a VIP key is used.
    data, used_key, _, _, used_proxy, error = execute_query_with_fallback(
        lambda key, key_level, proxy_session: fetch_fofa_next_data(key, query_text, page_size=10000, proxy_session=proxy_session),
        min_level=1
    )

    if error:
        msg.edit_text(f"âŒ æŸ¥è¯¢é¢„æ£€å¤±è´¥: {escape_markdown_v2(error)}", parse_mode=ParseMode.MARKDOWN_V2)
        return ConversationHandler.END
        
    total_size = data.get('size', 0)
    if total_size == 0:
        msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ä»»ä½•ç»“æœã€‚")
        return ConversationHandler.END

    initial_results = data.get('results', [])
    initial_next_id = data.get('next')

    context.user_data['query'] = query_text
    context.user_data['total_size'] = total_size
    context.user_data['chat_id'] = update.effective_chat.id
    context.user_data['start_key'] = used_key
    context.user_data['initial_results'] = initial_results
    context.user_data['initial_next_id'] = initial_next_id
    # v10.9.4 FIX: Lock the proxy session for the background job.
    context.user_data['proxy_session'] = used_proxy

    keyboard = [
        [InlineKeyboardButton(f"â™¾ï¸ å…¨éƒ¨è·å– ({total_size}æ¡)", callback_data='allfofa_limit_none')],
        [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='allfofa_limit_cancel')]
    ]
    msg.edit_text(
        f"âœ… æŸ¥è¯¢é¢„æ£€æˆåŠŸï¼Œå…±å‘ç° {total_size} æ¡ç»“æœã€‚\n\n"
        "è¯·è¾“å…¥æ‚¨å¸Œæœ›è·å–çš„æ•°é‡ä¸Šé™ (ä¾‹å¦‚: 50000)ï¼Œæˆ–é€‰æ‹©å…¨éƒ¨è·å–ã€‚",
        reply_markup=InlineKeyboardMarkup(keyboard)
    )
    return STATE_ALLFOFA_GET_LIMIT

def allfofa_get_limit(update: Update, context: CallbackContext):
    limit = None
    query = update.callback_query
    
    if query:
        query.answer()
        if query.data == 'allfofa_limit_cancel':
            query.message.edit_text("æ“ä½œå·²å–æ¶ˆ.")
            return ConversationHandler.END
        msg_target = query.message
    else:
        try:
            limit = int(update.message.text.strip())
            assert limit > 0
        except (ValueError, AssertionError):
            update.message.reply_text("âŒ æ— æ•ˆçš„æ•°å­—ï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ­£æ•´æ•°ã€‚")
            return STATE_ALLFOFA_GET_LIMIT
        msg_target = update.message

    context.user_data['limit'] = limit
    msg_target.reply_text(f"âœ… ä»»åŠ¡å·²æäº¤ï¼\nå°†ä½¿ç”¨ `next` æ¥å£è·å–æ•°æ® (ä¸Šé™: {limit or 'æ— '})...")
    start_download_job(context, run_allfofa_download_job, context.user_data)
    if query:
        msg_target.delete()
    return ConversationHandler.END

def run_allfofa_download_job(context: CallbackContext):
    job_data = context.job.context
    bot, chat_id, query_text = context.bot, job_data['chat_id'], job_data['query']
    limit, total_size = job_data.get('limit'), job_data.get('total_size')

    # v10.9.4 FIX: Receive the locked-in key AND proxy session from the pre-check.
    start_key = job_data.get('start_key')
    proxy_session = job_data.get('proxy_session')

    initial_results = job_data.get('initial_results', [])
    initial_next_id = job_data.get('initial_next_id')

    if not start_key or KEY_LEVELS.get(start_key, -1) == -1:
        bot.send_message(chat_id, "âŒ ä»»åŠ¡å¤±è´¥ï¼šæ²¡æœ‰å¯ç”¨çš„æœ‰æ•ˆAPI Keyæˆ–èµ·å§‹Keyæ— æ•ˆã€‚")
        return
    
    current_key = start_key
    output_filename = generate_filename_from_query(query_text, prefix="allfofa")
    
    unique_results = set(res for res in initial_results if isinstance(res, str) and ':' in res)
    
    stop_flag = f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹ä½¿ç”¨ `next` æ¥å£è¿›è¡Œæµ·é‡ä¸‹è½½...")
    
    next_id, termination_reason, last_update_time = initial_next_id, "", 0

    if not next_id:
        termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ (ä»…æœ‰ä¸€é¡µæ•°æ®)."
    elif limit and len(unique_results) >= limit:
        unique_results = set(list(unique_results)[:limit])
        termination_reason = f"\n\nâ„¹ï¸ å·²è¾¾åˆ°æ‚¨è®¾ç½®çš„ {limit} æ¡ç»“æœä¸Šé™ (ä»…æœ‰ä¸€é¡µæ•°æ®)ã€‚"
        next_id = None

    while next_id:
        if context.bot_data.get(stop_flag):
            termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."
            break

        # v10.9.4 FIX: Use the locked-in proxy for all subsequent `next` calls.
        data, error = fetch_fofa_next_data(current_key, query_text, next_id=next_id, fields="host", proxy_session=proxy_session)

        if error:
            termination_reason = f"\n\nâŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {escape_markdown_v2(error)}"
            break
        
        results = data.get('results', [])
        if not results:
            termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."
            break
        
        unique_results.update(res for res in results if isinstance(res, str) and ':' in res)

        if limit and len(unique_results) >= limit:
            unique_results = set(list(unique_results)[:limit])
            termination_reason = f"\n\nâ„¹ï¸ å·²è¾¾åˆ°æ‚¨è®¾ç½®çš„ {limit} æ¡ç»“æœä¸Šé™ã€‚"
            break

        current_time = time.time()
        if current_time - last_update_time > 2:
            try:
                progress_bar = create_progress_bar(len(unique_results) / (limit or total_size) * 100)
                msg.edit_text(f"ä¸‹è½½è¿›åº¦: {progress_bar} ({len(unique_results)} / {limit or total_size})")
            except (BadRequest, RetryAfter, TimedOut):
                pass
            last_update_time = current_time

        next_id = data.get('next')
        if not next_id:
            termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ (APIæœªè¿”å›next_id)."
            break

    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f:
            f.write("\n".join(sorted(list(unique_results))))
        
        msg.edit_text(f"âœ… æµ·é‡ä¸‹è½½å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨å‘é€æ–‡ä»¶\\.\\.\\.", parse_mode=ParseMode.MARKDOWN_V2)
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        
        send_file_safely(context, chat_id, cache_path, filename=output_filename)
        
        upload_and_send_links(context, chat_id, cache_path)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(query_text, cache_data)
        offer_post_download_actions(context, chat_id, query_text)
    else:
        msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®\\.{termination_reason}", parse_mode=ParseMode.MARKDOWN_V2)
    
    context.bot_data.pop(stop_flag, None)

# --- ä¸»å‡½æ•°ä¸è°ƒåº¦å™¨ ---
def main() -> None:
    global CONFIG
    os.makedirs(FOFA_CACHE_DIR, exist_ok=True)
    if not os.path.exists(CONFIG_FILE) or CONFIG.get("bot_token") == "YOUR_BOT_TOKEN_HERE":
        print("--- é¦–æ¬¡è¿è¡Œæˆ–é…ç½®ä¸å®Œæ•´ï¼Œè¿›å…¥äº¤äº’å¼è®¾ç½® ---")
        bot_token = input("è¯·è¾“å…¥æ‚¨çš„ Telegram Bot Token: ").strip()
        admin_id = input("è¯·è¾“å…¥æ‚¨çš„ Telegram User ID (ä½œä¸ºç¬¬ä¸€ä¸ªç®¡ç†å‘˜): ").strip()
        if not bot_token or not admin_id.isdigit(): print("é”™è¯¯ï¼šBot Token å’Œ Admin ID ä¸èƒ½ä¸ºç©ºä¸”IDå¿…é¡»æ˜¯æ•°å­—ã€‚è¯·é‡æ–°è¿è¡Œè„šæœ¬ã€‚"); sys.exit(1)
        CONFIG["bot_token"] = bot_token; CONFIG["admins"] = [int(admin_id)]
        fofa_keys = []; print("è¯·è¾“å…¥æ‚¨çš„ FOFA API Key (è¾“å…¥ç©ºè¡Œç»“æŸ):")
        while True:
            key = input(f"  - Key #{len(fofa_keys) + 1}: ").strip()
            if not key: break
            fofa_keys.append(key)
        CONFIG["apis"] = fofa_keys
        save_config(); print("âœ… é…ç½®å·²ä¿å­˜åˆ° config.jsonã€‚æ­£åœ¨å¯åŠ¨æœºå™¨äºº...")
        CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
    bot_token = CONFIG.get("bot_token")
    if not bot_token or bot_token == "YOUR_BOT_TOKEN_HERE": logger.critical("é”™è¯¯: 'bot_token' æœªåœ¨ config.json ä¸­è®¾ç½®!"); return
    check_and_classify_keys()
    updater = Updater(token=bot_token, use_context=True, request_kwargs={'read_timeout': 20, 'connect_timeout': 20})
    dispatcher = updater.dispatcher
    dispatcher.bot_data['updater'] = updater
    commands = [
        BotCommand("start", "ğŸš€ å¯åŠ¨æœºå™¨äºº"), BotCommand("help", "â“ å‘½ä»¤æ‰‹å†Œ"),
        BotCommand("kkfofa", "ğŸ” èµ„äº§æœç´¢ (å¸¸è§„)"), BotCommand("allfofa", "ğŸšš èµ„äº§æœç´¢ (æµ·é‡)"),
        BotCommand("host", "ğŸ“¦ ä¸»æœºè¯¦æŸ¥ (æ™ºèƒ½)"), BotCommand("lowhost", "ğŸ”¬ ä¸»æœºé€ŸæŸ¥ (èšåˆ)"),
        BotCommand("stats", "ğŸ“Š å…¨å±€èšåˆç»Ÿè®¡"), BotCommand("batchfind", "ğŸ“‚ æ‰¹é‡æ™ºèƒ½åˆ†æ (Excel)"),
        BotCommand("batch", "ğŸ“¤ æ‰¹é‡è‡ªå®šä¹‰å¯¼å‡º (äº¤äº’å¼)"), BotCommand("batchcheckapi", "ğŸ”‘ æ‰¹é‡éªŒè¯API Key"),
        BotCommand("check", "ğŸ©º ç³»ç»Ÿè‡ªæ£€"), BotCommand("settings", "âš™ï¸ è®¾ç½®èœå•"),
        BotCommand("history", "ğŸ•°ï¸ æŸ¥è¯¢å†å²"), BotCommand("import", "ğŸ–‡ï¸ å¯¼å…¥æ—§ç¼“å­˜"),
        BotCommand("backup", "ğŸ“¤ å¤‡ä»½é…ç½®"), BotCommand("restore", "ğŸ“¥ æ¢å¤é…ç½®"),
        BotCommand("update", "ğŸ”„ åœ¨çº¿æ›´æ–°è„šæœ¬"), BotCommand("getlog", "ğŸ“„ è·å–æ—¥å¿—"),
        BotCommand("shutdown", "ğŸ”Œ å…³é—­æœºå™¨äºº"), BotCommand("stop", "ğŸ›‘ åœæ­¢ä»»åŠ¡"),
        BotCommand("cancel", "âŒ å–æ¶ˆæ“ä½œ")
    ]
    try: updater.bot.set_my_commands(commands)
    except Exception as e: logger.warning(f"è®¾ç½®æœºå™¨äººå‘½ä»¤å¤±è´¥: {e}")
    settings_conv = ConversationHandler(
        entry_points=[CommandHandler("settings", settings_command)],
        states={
            STATE_SETTINGS_MAIN: [CallbackQueryHandler(settings_callback_handler, pattern=r"^settings_")],
            STATE_SETTINGS_ACTION: [
                CallbackQueryHandler(settings_action_handler, pattern=r"^action_"),
                CallbackQueryHandler(show_update_menu, pattern=r"^settings_update"),
                CallbackQueryHandler(show_backup_restore_menu, pattern=r"^settings_backup"),
                CallbackQueryHandler(lambda u,c: backup_config_command(u.callback_query, c), pattern=r"^backup_now"),
                CallbackQueryHandler(lambda u,c: restore_config_command(u.callback_query.message, c), pattern=r"^restore_now"),
                CallbackQueryHandler(get_update_url, pattern=r"^update_set_url"),
                CallbackQueryHandler(settings_command, pattern=r"^(update_back|backup_back)"),
            ],
            STATE_GET_KEY: [MessageHandler(Filters.text & ~Filters.command, get_key)],
            STATE_REMOVE_API: [MessageHandler(Filters.text & ~Filters.command, remove_api)],
            STATE_PRESET_MENU: [CallbackQueryHandler(preset_menu_callback, pattern=r"^preset_")],
            STATE_GET_PRESET_NAME: [MessageHandler(Filters.text & ~Filters.command, get_preset_name)],
            STATE_GET_PRESET_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_preset_query)],
            STATE_REMOVE_PRESET: [MessageHandler(Filters.text & ~Filters.command, remove_preset)],
            STATE_GET_UPDATE_URL: [MessageHandler(Filters.text & ~Filters.command, get_update_url)],
            STATE_PROXYPOOL_MENU: [CallbackQueryHandler(proxypool_menu_callback, pattern=r"^proxypool_")],
            STATE_GET_PROXY_ADD: [MessageHandler(Filters.text & ~Filters.command, get_proxy_to_add)],
            STATE_GET_PROXY_REMOVE: [MessageHandler(Filters.text & ~Filters.command, get_proxy_to_remove)],
            STATE_UPLOAD_API_MENU: [CallbackQueryHandler(upload_api_menu_callback, pattern=r"^upload_")],
            STATE_GET_UPLOAD_URL: [MessageHandler(Filters.text & ~Filters.command, get_upload_url)],
            STATE_GET_UPLOAD_TOKEN: [MessageHandler(Filters.text & ~Filters.command, get_upload_token)],
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300,
    )
    query_conv = ConversationHandler(
        entry_points=[ CommandHandler("kkfofa", query_entry_point), CommandHandler("allfofa", query_entry_point), CallbackQueryHandler(query_entry_point, pattern=r"^run_preset_") ],
        states={
            STATE_GET_GUEST_KEY: [MessageHandler(Filters.text & ~Filters.command, get_guest_key)],
            STATE_ASK_CONTINENT: [CallbackQueryHandler(ask_continent_callback, pattern=r"^continent_")], 
            STATE_CONTINENT_CHOICE: [CallbackQueryHandler(continent_choice_callback, pattern=r"^continent_")], 
            STATE_CACHE_CHOICE: [CallbackQueryHandler(cache_choice_callback, pattern=r"^cache_")],
            STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
            STATE_GET_TRACEBACK_LIMIT: [MessageHandler(Filters.text & ~Filters.command, get_traceback_limit), CallbackQueryHandler(get_traceback_limit, pattern=r"^limit_")],
            STATE_ALLFOFA_GET_LIMIT: [MessageHandler(Filters.text & ~Filters.command, allfofa_get_limit), CallbackQueryHandler(allfofa_get_limit, pattern=r"^allfofa_limit_")]
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300,
    )
    batch_conv = ConversationHandler(
        entry_points=[CommandHandler("batch", batch_command)], 
        states={
            STATE_BATCH_SELECT_FIELDS: [CallbackQueryHandler(batch_select_fields_callback, pattern=r"^batchfield_")],
            STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
            STATE_GET_TRACEBACK_LIMIT: [MessageHandler(Filters.text & ~Filters.command, get_traceback_limit), CallbackQueryHandler(get_traceback_limit, pattern=r"^limit_")]
        },
        fallbacks=[CommandHandler('cancel', cancel)], conversation_timeout=600,
    )
    import_conv = ConversationHandler(entry_points=[CommandHandler("import", import_command)], states={STATE_GET_IMPORT_QUERY: [MessageHandler(Filters.document.mime_type("text/plain"), get_import_query)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    stats_conv = ConversationHandler(entry_points=[CommandHandler("stats", stats_command)], states={STATE_GET_STATS_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_fofa_stats_query)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    batchfind_conv = ConversationHandler(entry_points=[CommandHandler("batchfind", batchfind_command)], states={STATE_GET_BATCH_FILE: [MessageHandler(Filters.document.mime_type("text/plain"), get_batch_file_handler)], STATE_SELECT_BATCH_FEATURES: [CallbackQueryHandler(select_batch_features_callback, pattern=r"^batchfeature_")]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    restore_conv = ConversationHandler(entry_points=[CommandHandler("restore", restore_config_command)], states={STATE_GET_RESTORE_FILE: [MessageHandler(Filters.document, receive_config_file)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    scan_conv = ConversationHandler(entry_points=[CallbackQueryHandler(start_scan_callback, pattern=r'^start_scan_')], states={STATE_GET_SCAN_CONCURRENCY: [MessageHandler(Filters.text & ~Filters.command, get_concurrency_callback)], STATE_GET_SCAN_TIMEOUT: [MessageHandler(Filters.text & ~Filters.command, get_timeout_callback)]}, fallbacks=[CommandHandler('cancel', cancel)], conversation_timeout=120)
    batch_check_api_conv = ConversationHandler(entry_points=[CommandHandler("batchcheckapi", batch_check_api_command)], states={STATE_GET_API_FILE: [MessageHandler(Filters.document.mime_type("text/plain"), receive_api_file)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    
    dispatcher.add_handler(CommandHandler("start", start_command)); dispatcher.add_handler(CommandHandler("help", help_command)); dispatcher.add_handler(CommandHandler("host", host_command)); dispatcher.add_handler(CommandHandler("lowhost", lowhost_command)); dispatcher.add_handler(CommandHandler("check", check_command)); dispatcher.add_handler(CommandHandler("stop", stop_all_tasks)); dispatcher.add_handler(CommandHandler("backup", backup_config_command)); dispatcher.add_handler(CommandHandler("history", history_command)); dispatcher.add_handler(CommandHandler("getlog", get_log_command)); dispatcher.add_handler(CommandHandler("shutdown", shutdown_command)); dispatcher.add_handler(CommandHandler("update", update_script_command));
    dispatcher.add_handler(settings_conv); dispatcher.add_handler(query_conv); dispatcher.add_handler(batch_conv); dispatcher.add_handler(import_conv); dispatcher.add_handler(stats_conv); dispatcher.add_handler(batchfind_conv); dispatcher.add_handler(restore_conv); dispatcher.add_handler(scan_conv); dispatcher.add_handler(batch_check_api_conv)
    
    logger.info(f"ğŸš€ Fofa Bot v10.9 (ç¨³å®šç‰ˆ) å·²å¯åŠ¨...")
    updater.start_polling()
    updater.idle()
    logger.info("Bot has been shut down gracefully.")

if __name__ == "__main__":
    main()
