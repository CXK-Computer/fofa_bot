#
# fofa_final_complete_v8.6.py (æœ€ç»ˆå®Œæ•´ç‰ˆ for python-telegram-bot v13.x)
#
# æ ¸å¿ƒä¿®æ”¹ (v8.6): 1. /host å‘½ä»¤ç”Ÿæˆçš„è¯¦ç»†æŠ¥å‘Šæ–‡ä»¶ä¸­ï¼ŒBannerå’ŒHeaderä¸å†è¢«æˆªæ–­ï¼Œä¿è¯ä¿¡æ¯å®Œæ•´æ€§ã€‚
# æ ¸å¿ƒä¿®æ”¹ (v8.6): 2. /batchfind åŠŸèƒ½å‡çº§ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ™ºèƒ½è§£ææ–‡ä»¶ï¼Œå…¼å®¹å„ç§å¤æ‚çš„ "ip:port..." æ ¼å¼ã€‚
#
import os
import sys
import json
import logging
import base64
import time
import re
import requests
import signal
import socket
import hashlib
import shutil
from functools import wraps
from datetime import datetime, timedelta
from dateutil import tz
from concurrent.futures import ThreadPoolExecutor, as_completed

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand, ParseMode
from telegram.ext import (
    Updater,
    CommandHandler,
    CallbackContext,
    ConversationHandler,
    MessageHandler,
    CallbackQueryHandler,
    Filters,
)
from telegram.error import BadRequest, RetryAfter

# --- å…¨å±€å˜é‡å’Œå¸¸é‡ ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
LOG_FILE = 'fofa_bot.log'
FOFA_CACHE_DIR = 'fofa_file'
MAX_HISTORY_SIZE = 50
CACHE_EXPIRATION_SECONDS = 24 * 60 * 60
FOFA_SEARCH_URL = "https://fofa.info/api/v1/search/all"
FOFA_INFO_URL = "https://fofa.info/api/v1/info/my"
FOFA_STATS_URL = "https://fofa.info/api/v1/search/stats"
FOFA_HOST_BASE_URL = "https://fofa.info/api/v1/host/"
FOFA_STATS_FIELDS = "protocol,domain,port,title,os,server,country,asn,org,asset_type,fid,icp"
SCAN_TIMEOUT = 3
SCAN_CONCURRENCY = 1000

# --- Banner/Header æŒ‡çº¹æå– ---
def normalize_banner(banner_text):
    if not isinstance(banner_text, str): return ""
    normalized = re.sub(r'(Date|Last-Modified|Expires):\s+.*?GMT', r'\1: [TIMESTAMP]', banner_text, flags=re.IGNORECASE)
    normalized = re.sub(r'CF-RAY:\s+[a-f0-9\-]+', 'CF-RAY: [ID]', normalized, flags=re.IGNORECASE)
    normalized = re.sub(r'ETag:\s+.*?"', 'ETag: [HASH]"', normalized, flags=re.IGNORECASE)
    normalized = re.sub(r'Set-Cookie:\s+([^=]+)=.*?(;|$)', r'Set-Cookie: \1=[SESSION];', normalized, flags=re.IGNORECASE)
    normalized = re.sub(r'(X-Request-Id|Trace-Id|Request-Id):\s+[a-zA-Z0-9\-]+', r'\1: [ID]', normalized, flags=re.IGNORECASE)
    normalized = re.sub(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}', '[IP_ADDRESS]', normalized)
    normalized = re.sub(r'[a-f0-9]{32,}', '[LONG_HASH]', normalized, flags=re.IGNORECASE)
    normalized = re.sub(r'\s+', ' ', normalized).strip()
    return normalized

# ç‰¹å¾åˆ†æåŠŸèƒ½ç›¸å…³
BATCH_FEATURES = {
    "protocol": "åè®®", "domain": "åŸŸå", "os": "æ“ä½œç³»ç»Ÿ", "server": "æœåŠ¡/ç»„ä»¶",
    "icp": "ICPå¤‡æ¡ˆå·", "title": "æ ‡é¢˜", "jarm": "JARMæŒ‡çº¹",
    "cert.issuer.org": "è¯ä¹¦é¢å‘ç»„ç»‡", "cert.issuer.cn": "è¯ä¹¦é¢å‘CN",
    "cert.subject.org": "è¯ä¹¦ä¸»ä½“ç»„ç»‡", "cert.subject.cn": "è¯ä¹¦ä¸»ä½“CN",
    "banner": "BanneræŒ‡çº¹", "header": "HeaderæŒ‡çº¹"
}

CONTINENT_COUNTRIES = {
    "Asia": ["AF", "AM", "AZ", "BH", "BD", "BT", "BN", "KH", "CN", "CY", "GE", "HK", "IN", "ID", "IR", "IQ", "IL", "JP", "JO", "KZ", "KW", "KG", "LA", "LB", "MO", "MY", "MV", "MN", "MM", "NP", "KP", "OM", "PK", "PS", "PH", "QA", "SA", "SG", "KR", "LK", "SY", "TW", "TJ", "TH", "TL", "TR", "TM", "AE", "UZ", "VN", "YE"],
    "Europe": ["AL", "AD", "AT", "BY", "BE", "BA", "BG", "HR", "CZ", "DK", "EE", "FO", "FI", "FR", "DE", "GI", "GR", "HU", "IS", "IE", "IT", "LV", "LI", "LT", "LU", "MK", "MT", "MD", "MC", "ME", "NL", "NO", "PL", "PT", "RO", "RU", "SM", "RS", "SK", "SI", "ES", "SE", "CH", "UA", "GB", "VA"],
    "NorthAmerica": ["AG", "BS", "BB", "BZ", "CA", "CR", "CU", "DM", "DO", "SV", "GD", "GT", "HT", "HN", "JM", "MX", "NI", "PA", "KN", "LC", "VC", "TT", "US"],
    "SouthAmerica": ["AR", "BO", "BR", "CL", "CO", "EC", "FK", "GY", "PY", "PE", "SR", "UY", "VE"],
    "Africa": ["DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CG", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MW", "ML", "MR", "MU", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "ST", "SN", "SC", "SL", "SO", "ZA", "SS", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW"],
    "Oceania": ["AS", "AU", "FJ", "GU", "KI", "MH", "FM", "NR", "NZ", "PW", "PG", "WS", "SB", "TO", "TV", "VU"]
}

# --- æ—¥å¿—é…ç½® ---
if os.path.exists(LOG_FILE) and os.path.getsize(LOG_FILE) > (5 * 1024 * 1024):
    try: os.rename(LOG_FILE, LOG_FILE + '.old')
    except OSError as e: print(f"æ— æ³•è½®æ¢æ—¥å¿—æ–‡ä»¶: {e}")
logging.basicConfig(
    level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler(LOG_FILE, encoding='utf-8'), logging.StreamHandler()]
)
logging.getLogger("requests").setLevel(logging.WARNING); logging.getLogger("urllib3").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# --- ä¼šè¯çŠ¶æ€å®šä¹‰ ---
(
    STATE_SETTINGS_MAIN, STATE_SETTINGS_ACTION, STATE_GET_KEY, STATE_REMOVE_API, STATE_GET_PROXY,
    STATE_KKFOFA_MODE, STATE_CACHE_CHOICE, STATE_GET_IMPORT_QUERY, STATE_GET_STATS_QUERY,
    STATE_PRESET_MENU, STATE_GET_PRESET_NAME, STATE_GET_PRESET_QUERY, STATE_REMOVE_PRESET,
    STATE_GET_UPDATE_URL,
    STATE_ASK_CONTINENT, STATE_CONTINENT_CHOICE,
    STATE_GET_BATCH_FILE, STATE_SELECT_BATCH_FEATURES,
    STATE_GET_RESTORE_FILE
) = range(19)

# --- é…ç½®ç®¡ç† & ç¼“å­˜ ---
def load_json_file(filename, default_content):
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4); return default_content
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            config = json.load(f)
            for key, value in default_content.items(): config.setdefault(key, value)
            return config
    except (json.JSONDecodeError, IOError):
        logger.error(f"{filename} æŸåï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®é‡å»ºã€‚");
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4); return default_content

def save_json_file(filename, data):
    with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=4, ensure_ascii=False)

DEFAULT_CONFIG = { "bot_token": "YOUR_BOT_TOKEN_HERE", "apis": [], "admins": [], "proxy": "", "full_mode": False, "public_mode": False, "presets": [], "update_url": "" }
CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
HISTORY = load_json_file(HISTORY_FILE, {"queries": []})

def save_config(): save_json_file(CONFIG_FILE, CONFIG)
def save_history(): save_json_file(HISTORY_FILE, HISTORY)
def add_or_update_query(query_text, cache_data=None):
    existing_query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if existing_query:
        HISTORY['queries'].remove(existing_query); existing_query['timestamp'] = datetime.now(tz.tzutc()).isoformat()
        if cache_data: existing_query['cache'] = cache_data
        HISTORY['queries'].insert(0, existing_query)
    else:
        new_query = {"query_text": query_text, "timestamp": datetime.now(tz.tzutc()).isoformat(), "cache": cache_data}
        HISTORY['queries'].insert(0, new_query)
    while len(HISTORY['queries']) > MAX_HISTORY_SIZE: HISTORY['queries'].pop()
    save_history()
def find_cached_query(query_text):
    query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if query and query.get('cache'):
        if 'file_path' in query['cache'] and os.path.exists(query['cache']['file_path']):
            return query
    return None

# --- è¾…åŠ©å‡½æ•°ä¸è£…é¥°å™¨ ---
def generate_filename_from_query(query_text: str, prefix: str = "fofa") -> str:
    sanitized_query = re.sub(r'[^a-z0-9\-_]+', '_', query_text.lower()).strip('_')
    max_len = 100
    if len(sanitized_query) > max_len: sanitized_query = sanitized_query[:max_len].rsplit('_', 1)[0]
    timestamp = int(time.time()); return f"{prefix}_{sanitized_query}_{timestamp}.txt"
def get_proxies():
    if CONFIG.get("proxy"): return {"http": CONFIG["proxy"], "https": CONFIG["proxy"]}
    return None
def is_admin(user_id: int) -> bool: return user_id in CONFIG.get('admins', [])
def admin_only(func):
    @wraps(func)
    def wrapped(update: Update, context: CallbackContext, *args, **kwargs):
        if not is_admin(update.effective_user.id):
            message_text = "â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤ç®¡ç†æ“ä½œã€‚"
            if update.callback_query: update.callback_query.answer(message_text, show_alert=True)
            elif update.message: update.message.reply_text(message_text)
            return None
        return func(update, context, *args, **kwargs)
    return wrapped
def escape_markdown(text: str) -> str:
    if not isinstance(text, str): text = str(text)
    escape_chars = r'_*`['; return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)
def create_progress_bar(percentage: float, length: int = 10) -> str:
    if percentage < 0: percentage = 0
    if percentage > 100: percentage = 100
    filled_length = int(length * percentage // 100)
    bar = 'â–ˆ' * filled_length + 'â–‘' * (length - filled_length)
    return f"[{bar}] {percentage:.1f}%"

# --- FOFA API æ ¸å¿ƒé€»è¾‘ ---
def _make_api_request(url, params, timeout=60, use_b64=True, retries=10):
    if use_b64 and 'q' in params:
        params['qbase64'] = base64.b64encode(params.pop('q').encode('utf-8')).decode('utf-8')
    
    last_error = None
    for attempt in range(retries):
        try:
            response = requests.get(url, params=params, timeout=timeout, proxies=get_proxies(), verify=False)
            
            if response.status_code == 429:
                wait_time = 5 * (attempt + 1)
                logger.warning(f"FOFA API rate limit hit (429). Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{retries})")
                time.sleep(wait_time)
                last_error = f"APIè¯·æ±‚å› é€Ÿç‡é™åˆ¶(429)å¤±è´¥"
                continue

            response.raise_for_status()
            data = response.json()
            if data.get("error"):
                return None, data.get("errmsg", "æœªçŸ¥çš„FOFAé”™è¯¯")
            return data, None

        except requests.exceptions.RequestException as e:
            last_error = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}"
            logger.error(f"RequestException on attempt {attempt + 1}: {e}")
            time.sleep(5)

        except json.JSONDecodeError as e:
            last_error = f"è§£æJSONå“åº”å¤±è´¥: {e}"
            break

    logger.error(f"API request failed after {retries} retries. Last error: {last_error}")
    return None, last_error if last_error else "APIè¯·æ±‚æœªçŸ¥é”™è¯¯"

def verify_fofa_api(key): return _make_api_request(FOFA_INFO_URL, {'key': key}, timeout=15, use_b64=False, retries=3)
def fetch_fofa_data(key, query, page=1, page_size=10000, fields="host"):
    query_lower = query.lower()
    if 'body=' in query_lower: page_size = min(page_size, 500)
    elif 'cert=' in query_lower: page_size = min(page_size, 2000)
    params = {'key': key, 'q': query, 'size': page_size, 'page': page, 'fields': fields, 'full': CONFIG.get("full_mode", False)}; return _make_api_request(FOFA_SEARCH_URL, params)
def fetch_fofa_stats(key, query):
    params = {'key': key, 'q': query, 'fields': FOFA_STATS_FIELDS}; return _make_api_request(FOFA_STATS_URL, params)
def execute_query_with_fallback(query_func, preferred_key_index=None):
    if not CONFIG['apis']: return None, None, "æ²¡æœ‰é…ç½®ä»»ä½•API Keyã€‚"
    keys_to_try = CONFIG['apis']; start_index = 0
    if preferred_key_index is not None and 1 <= preferred_key_index <= len(keys_to_try): start_index = preferred_key_index - 1
    for i in range(len(keys_to_try)):
        idx = (start_index + i) % len(keys_to_try); key = keys_to_try[idx]; key_num = idx + 1
        data, error = query_func(key)
        if not error: return data, key_num, None
        if "[820031]" in str(error): logger.warning(f"Key [#{key_num}] Fç‚¹ä½™é¢ä¸è¶³..."); continue
        return None, key_num, error
    return None, None, "æ‰€æœ‰Keyå‡å°è¯•å¤±è´¥ã€‚"

# --- /host & /stats å‘½ä»¤å¤„ç† ---
def get_common_host_info(data):
    fields = "ip,port,protocol,country,country_name,region,city,longitude,latitude,asn,org,host,domain,os,server,icp,title,jarm,header,banner,cert,base_protocol,link,cert.issuer.org,cert.issuer.cn,cert.subject.org,cert.subject.cn,tls.ja3s,tls.version,cert.sn,cert.not_before,cert.not_after,cert.domain".split(',')
    field_map = {name: idx for idx, name in enumerate(fields)}
    
    common_info = {'ip': set(), 'asn': set(), 'org': set(), 'country': set(), 'os': set(), 'domain': set()}
    for res in data['results']:
        common_info['ip'].add(res[field_map['ip']]); common_info['asn'].add(res[field_map['asn']]); common_info['org'].add(res[field_map['org']])
        common_info['country'].add(f"{res[field_map['country_name']]} ({res[field_map['country']]})")
        if res[field_map['os']]: common_info['os'].add(res[field_map['os']])
        if res[field_map['domain']]: common_info['domain'].add(res[field_map['domain']])
    
    ports_data = {}
    for res in data['results']:
        port = res[field_map['port']]; ports_data.setdefault(port, []).append(res)
        
    return common_info, ports_data, field_map

def create_host_summary(query_host, data):
    if not data or not data.get('results'):
        return f"ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°å…³äº `{escape_markdown(query_host)}` çš„è¯¦ç»†ä¿¡æ¯ã€‚"
    
    common_info, ports_data, field_map = get_common_host_info(data)
    
    def join_set(s):
        s_list = sorted([item for item in s if item])
        return '`, `'.join(map(escape_markdown, map(str, s_list))) if s_list else "N/A"

    lines = [f"ğŸ“‹ *ä¸»æœºæ‘˜è¦: `{escape_markdown(query_host)}`*"]
    lines.append(f"*IP:* `{join_set(common_info['ip'])}`"); lines.append(f"*ASN:* `{join_set(common_info['asn'])}`"); lines.append(f"*ç»„ç»‡:* `{join_set(common_info['org'])}`"); lines.append(f"*å›½å®¶:* `{join_set(common_info['country'])}`")
    if common_info['os']: lines.append(f"*æ“ä½œç³»ç»Ÿ:* `{join_set(common_info['os'])}`")
    if common_info['domain']: lines.append(f"*å…³è”åŸŸå:* `{join_set(common_info['domain'])}`")
    
    lines.append("\n*å¼€æ”¾ç«¯å£:*")
    if not ports_data:
        lines.append("  _æœªå‘ç°å¼€æ”¾ç«¯å£_")
    else:
        for port in sorted(ports_data.keys()):
            first_res = ports_data[port][0]
            protocol = first_res[field_map['protocol']]; title = first_res[field_map['title']]
            line = f"  - `{port}` ({protocol})"
            if title: line += f": `{escape_markdown(title)}`"
            lines.append(line)
            
    return "\n".join(lines)

def format_full_host_report(query_host, data):
    if not data or not data.get('results'):
        return f"ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°å…³äº `{escape_markdown(query_host)}` çš„è¯¦ç»†ä¿¡æ¯ã€‚"
    
    common_info, ports_data, field_map = get_common_host_info(data)
    
    def join_set(s):
        s_list = sorted([item for item in s if item])
        return '`, `'.join(map(escape_markdown, map(str, s_list))) if s_list else "N/A"

    lines = [f"ğŸ“‹ *ä¸»æœºè¯¦ç»†ä¿¡æ¯: `{escape_markdown(query_host)}`*"]
    lines.append(f"*IP:* `{join_set(common_info['ip'])}`"); lines.append(f"*ASN:* `{join_set(common_info['asn'])}`"); lines.append(f"*ç»„ç»‡:* `{join_set(common_info['org'])}`"); lines.append(f"*å›½å®¶:* `{join_set(common_info['country'])}`")
    if common_info['os']: lines.append(f"*æ“ä½œç³»ç»Ÿ:* `{join_set(common_info['os'])}`")
    if common_info['domain']: lines.append(f"*å…³è”åŸŸå:* `{join_set(common_info['domain'])}`")
    
    for port in sorted(ports_data.keys()):
        first_res = ports_data[port][0]; protocol = first_res[field_map['protocol']]
        lines.append(f"\n--- *ç«¯å£: {port}* ({protocol}) ---")
        if first_res[field_map['title']]: lines.append(f"  *æ ‡é¢˜:* `{escape_markdown(first_res[field_map['title']])}`")
        if first_res[field_map['server']]: lines.append(f"  *Server:* `{escape_markdown(first_res[field_map['server']])}`")
        if first_res[field_map['jarm']]: lines.append(f"  *JARM:* `{escape_markdown(first_res[field_map['jarm']])}`")
        if first_res[field_map['cert.subject.cn']]: lines.append(f"  *è¯ä¹¦ä¸»ä½“:* `{escape_markdown(first_res[field_map['cert.subject.cn']])}`")
        if first_res[field_map['cert.issuer.cn']]: lines.append(f"  *è¯ä¹¦é¢å‘è€…:* `{escape_markdown(first_res[field_map['cert.issuer.cn']])}`")
        if first_res[field_map['cert.domain']]:
            cert_domains = first_res[field_map['cert.domain']].split(',')
            lines.append(f"  *è¯ä¹¦åŸŸå:* `{escape_markdown(', '.join(cert_domains[:3]))}`" + ( "..." if len(cert_domains) > 3 else ""))
        
        header = first_res[field_map['header']]
        if header:
            lines.append(f"  *Header:*\n  ```\n{escape_markdown(header.strip())}\n  ```")
            
        banner = first_res[field_map['banner']]
        if banner:
            lines.append(f"  *Banner:*\n  ```\n{escape_markdown(banner.strip())}\n  ```")
            
    return "\n".join(lines)

@admin_only
def host_command(update: Update, context: CallbackContext) -> None:
    if not context.args:
        update.message.reply_text("ç”¨æ³•: `/host <ip_or_domain>`\n\nç¤ºä¾‹:\n`/host 1.1.1.1`\n`/host example.com`", parse_mode=ParseMode.MARKDOWN)
        return
    host_arg = context.args[0]; processing_message = update.message.reply_text(f"â³ æ­£åœ¨æŸ¥è¯¢ä¸»æœº `{escape_markdown(host_arg)}`...")
    query = f'ip="{host_arg}"' if re.match(r"^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}$", host_arg) else f'domain="{host_arg}"'
    fields = "ip,port,protocol,country,country_name,region,city,longitude,latitude,asn,org,host,domain,os,server,icp,title,jarm,header,banner,cert,base_protocol,link,cert.issuer.org,cert.issuer.cn,cert.subject.org,cert.subject.cn,tls.ja3s,tls.version,cert.sn,cert.not_before,cert.not_after,cert.domain"
    data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query, page_size=100, fields=fields))
    if error:
        processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{error}`", parse_mode=ParseMode.MARKDOWN)
        return
    
    full_report = format_full_host_report(host_arg, data)
    
    if len(full_report) > 1500:
        summary_report = create_host_summary(host_arg, data)
        processing_message.edit_text(summary_report, parse_mode=ParseMode.MARKDOWN, disable_web_page_preview=True)
        
        report_filename = f"host_details_{host_arg.replace('.', '_')}.txt"
        try:
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write(re.sub(r'([*_`])', '', full_report))
            with open(report_filename, 'rb') as doc:
                context.bot.send_document(chat_id=update.effective_chat.id, document=doc, caption="ğŸ“„ å®Œæ•´çš„è¯¦ç»†æŠ¥å‘Šå·²é™„ä¸Šã€‚")
        finally:
            if os.path.exists(report_filename):
                os.remove(report_filename)
    else:
        processing_message.edit_text(full_report, parse_mode=ParseMode.MARKDOWN, disable_web_page_preview=True)

@admin_only
def get_fofa_stats_query(update: Update, context: CallbackContext) -> int:
    query_text = update.message.text; processing_message = update.message.reply_text(f"â³ æ­£åœ¨ä¸º `{escape_markdown(query_text)}` æŸ¥è¯¢èšåˆç»Ÿè®¡...")
    data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_stats(key, query_text))
    if error: processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{error}`", parse_mode=ParseMode.MARKDOWN); return ConversationHandler.END
    stats_data = data; aggs = stats_data.get("aggs", {})
    try: total_size_formatted = f"{stats_data.get('size', 0):,}"
    except (ValueError, TypeError): total_size_formatted = str(stats_data.get('size', 'N/A'))
    message_lines = [ f"*ğŸ“Š FOFA èšåˆç»Ÿè®¡ä¿¡æ¯*", f"*æŸ¥è¯¢:* `{escape_markdown(query_text)}`", f"*æ€»æ•°:* *{total_size_formatted}*", f"*æœ€åæ›´æ–°:* `{stats_data.get('lastupdatetime', 'N/A')}`", "" ]
    display_map = { "ğŸŒ Top 5 å›½å®¶/åœ°åŒº": "countries", "ğŸ¢ Top 5 ç»„ç»‡ (ORG)": "org", "ğŸ“› Top 5 ASN": "asn", "ğŸ–¥ï¸ Top 5 æœåŠ¡/ç»„ä»¶": "server", "ğŸ”Œ Top 5 åè®®": "protocol", "âš™ï¸ Top 5 æ“ä½œç³»ç»Ÿ": "os", "ğŸšª Top 5 ç«¯å£": "port", }
    for title, key in display_map.items():
        items = aggs.get(key)
        if items:
            message_lines.append(f"*{title}:*")
            for item in items[:5]:
                try: name = escape_markdown(item.get('name', 'N/A')); count_formatted = f"{item.get('count', 0):,}"
                except (ValueError, TypeError): name = str(item.get('name', 'N/A')); count_formatted = str(item.get('count', 0))
                message_lines.append(f"  - `{name}`: *{count_formatted}*")
            message_lines.append("")
    processing_message.edit_text("\n".join(message_lines), parse_mode=ParseMode.MARKDOWN); return ConversationHandler.END
@admin_only
def stats_command(update: Update, context: CallbackContext) -> int:
    update.message.reply_text("è¯·è¾“å…¥ä½ æƒ³è¦è¿›è¡Œèšåˆç»Ÿè®¡çš„ FOFA è¯­æ³•ã€‚\nä¾‹å¦‚: `app=\"nginx\"`\n\néšæ—¶å¯ä»¥å‘é€ /cancel æ¥å–æ¶ˆã€‚", parse_mode=ParseMode.MARKDOWN); return STATE_GET_STATS_QUERY

# --- åå°ä»»åŠ¡ä¸æ‰«æé€»è¾‘ ---
def offer_post_download_actions(context: CallbackContext, chat_id, query_text):
    query_hash = hashlib.md5(query_text.encode()).hexdigest()
    context.bot_data[query_hash] = query_text
    keyboard = [[ InlineKeyboardButton("âš¡ï¸ å­˜æ´»æ£€æµ‹", callback_data=f'liveness_{query_hash}'), InlineKeyboardButton("ğŸŒ å­ç½‘æ‰«æ(/24)", callback_data=f'subnet_{query_hash}') ]]
    context.bot.send_message(chat_id, "ä¸‹è½½å®Œæˆï¼Œéœ€è¦å¯¹ç»“æœè¿›è¡ŒäºŒæ¬¡æ‰«æå—ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard))
def download_and_process_file(context: CallbackContext, query_hash, prefix, processor_func, final_message_func):
    bot = context.bot; job_context = context.job.context; chat_id, msg = job_context['chat_id'], job_context['msg']
    original_query = context.bot_data.get(query_hash)
    if not original_query: msg.edit_text("âŒ æ‰«æä»»åŠ¡å·²è¿‡æœŸæˆ–æ— æ³•æ‰¾åˆ°åŸå§‹æŸ¥è¯¢ã€‚"); return
    cached_item = find_cached_query(original_query)
    if not cached_item: msg.edit_text("âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶çš„æœ¬åœ°ç¼“å­˜è®°å½•ã€‚"); return
    msg.edit_text("1/3: æ­£åœ¨å‡†å¤‡æœ¬åœ°ç¼“å­˜æ–‡ä»¶...")
    cached_path = cached_item['cache']['file_path']
    temp_path = f"temp_{os.path.basename(cached_path)}"
    try: shutil.copy(cached_path, temp_path)
    except Exception as e: msg.edit_text(f"âŒ å¤åˆ¶æœ¬åœ°ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    try: results = processor_func(temp_path, msg)
    finally:
        if os.path.exists(temp_path): os.remove(temp_path)
    if not results: msg.edit_text("ğŸ¤·â€â™€ï¸ æ‰«æå®Œæˆï¼Œä½†æœªå‘ç°ä»»ä½•å­˜æ´»çš„ç›®æ ‡ã€‚"); return
    msg.edit_text("3/3: æ­£åœ¨æ‰“åŒ…å¹¶å‘é€æ–°ç»“æœ...")
    output_filename = generate_filename_from_query(original_query, prefix=prefix)
    with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(results))))
    final_caption = final_message_func(len(results))
    with open(output_filename, 'rb') as doc: bot.send_document(chat_id, document=doc, caption=final_caption, parse_mode=ParseMode.MARKDOWN)
    os.remove(output_filename); msg.delete()
def process_liveness_check(file_path, msg):
    with open(file_path, 'r', encoding='utf-8') as f: targets = [line.strip() for line in f if line.strip()]
    live_results = set(); total = len(targets)
    msg.edit_text(f"2/3: å·²åŠ è½½ {total} ä¸ªç›®æ ‡ï¼Œå¼€å§‹å­˜æ´»æ£€æµ‹...")
    def check_port(target):
        try:
            ip, port_str = target.split(':'); port = int(port_str)
            with socket.create_connection((ip, port), timeout=SCAN_TIMEOUT) as sock: live_results.add(target)
        except (ValueError, socket.error): pass
    with ThreadPoolExecutor(max_workers=SCAN_CONCURRENCY) as executor: executor.map(check_port, targets)
    return live_results
def process_subnet_scan(file_path, msg):
    subnets_to_ports = {}
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                ip_str, port_str = line.strip().split(':'); port = int(port_str); subnet = ".".join(ip_str.split('.')[:3]) + ".0/24"
                if subnet not in subnets_to_ports: subnets_to_ports[subnet] = set()
                subnets_to_ports[subnet].add(port)
            except ValueError: continue
    if not subnets_to_ports: return set()
    total_targets = sum(len(ports) * 254 for ports in subnets_to_ports.values())
    if total_targets == 0: return set()
    msg.edit_text(f"2/3: åˆ†æå‡º {len(subnets_to_ports)} ä¸ª/24å­ç½‘ï¼Œå…±è®¡ {total_targets} ä¸ªæ‰«æç›®æ ‡ã€‚å¼€å§‹æ‰«æ...")
    live_results = set(); completed_count = 0; last_update_time = time.time()
    def check_port(ip, port):
        try:
            with socket.create_connection((ip, port), timeout=SCAN_TIMEOUT) as sock: return f"{ip}:{port}"
        except socket.error: return None
    with ThreadPoolExecutor(max_workers=SCAN_CONCURRENCY) as executor:
        futures = []
        for subnet, ports in subnets_to_ports.items():
            base_ip = subnet.split('/')[0].rsplit('.', 1)[0]
            for i in range(1, 255):
                for port in ports: futures.append(executor.submit(check_port, f"{base_ip}.{i}", port))
        for future in as_completed(futures):
            completed_count += 1; result = future.result()
            if result: live_results.add(result)
            current_time = time.time()
            if current_time - last_update_time > 2.5:
                progress = (completed_count / total_targets) * 100
                try:
                    msg.edit_text(f"2/3: æ‰«æè¿›åº¦: {progress:.1f}% ({completed_count}/{total_targets})\nå·²å‘ç°: {len(live_results)} ä¸ª")
                    last_update_time = current_time
                except (BadRequest, RetryAfter): pass
    return live_results
def run_liveness_check_job(context: CallbackContext):
    download_and_process_file(context, context.job.context['query_hash'], prefix="live", processor_func=process_liveness_check, final_message_func=lambda count: f"âœ… **å­˜æ´»æ£€æµ‹å®Œæˆ!**\n\nå…±å‘ç° *{count}* ä¸ªå­˜æ´»ç›®æ ‡ã€‚")
def run_subnet_scan_job(context: CallbackContext):
    download_and_process_file(context, context.job.context['query_hash'], prefix="subnet_scan", processor_func=process_subnet_scan, final_message_func=lambda count: f"âœ… **å­ç½‘æ‰«æå®Œæˆ!**\n\nåœ¨æ–°IPä¸­é¢å¤–å‘ç° *{count}* ä¸ªå­˜æ´»ç›®æ ‡ã€‚")
def start_job(update: Update, context: CallbackContext, job_name_prefix, callback_func, query_hash):
    chat_id = update.effective_chat.id; msg = update.effective_message.reply_text("â³ ä»»åŠ¡å·²æäº¤ï¼Œå‡†å¤‡å¼€å§‹...")
    job_context = {'chat_id': chat_id, 'msg': msg, 'query_hash': query_hash}
    context.job_queue.run_once(callback_func, 1, context=job_context, name=f"{job_name_prefix}_{chat_id}")
@admin_only
def liveness_check_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); query_hash = query.data.split('_', 1)[1]; start_job(update, context, "liveness", run_liveness_check_job, query_hash)
@admin_only
def subnet_scan_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); query_hash = query.data.split('_', 1)[1]; start_job(update, context, "subnet", run_subnet_scan_job, query_hash)
def start_download_job(context: CallbackContext, callback_func, job_data):
    chat_id = job_data['chat_id']; job_name = f"download_job_{chat_id}"
    for job in context.job_queue.get_jobs_by_name(job_name): job.schedule_removal()
    context.bot_data.pop(f'stop_job_{chat_id}', None)
    context.job_queue.run_once(callback_func, 1, context=job_data, name=job_name)
def run_full_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, query_text, total_size = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size']
    output_filename = generate_filename_from_query(query_text); unique_results, stop_flag = set(), f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡..."); pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(unique_results)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except (BadRequest, RetryAfter): pass
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page, 10000, "host"))
        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        results = data.get('results', []);
        if not results: break
        unique_results.update(res for res in results if ':' in res)
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(unique_results))
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚æ­£åœ¨å‘é€...")
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        with open(cache_path, 'rb') as doc: bot.send_document(chat_id, document=doc, filename=output_filename)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(query_text, cache_data); offer_post_download_actions(context, chat_id, query_text)
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)
def run_traceback_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; output_filename = generate_filename_from_query(base_query)
    unique_results, page_count, last_page_date, termination_reason, stop_flag, last_update_time = set(), 0, None, "", f'stop_job_{chat_id}', 0
    msg = bot.send_message(chat_id, "â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query
    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, current_query, 1, 10000, "host,lastupdatetime"))
        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break
        original_count = len(unique_results); unique_results.update([r[0] for r in results if r and r[0] and ':' in r[0]]); newly_added_count = len(unique_results) - original_count
        current_time = time.time()
        if current_time - last_update_time > 2:
            try:
                msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
                last_update_time = current_time
            except RetryAfter as e:
                logger.warning(f"Telegram flood control triggered. Waiting for {e.retry_after} seconds.")
                time.sleep(e.retry_after)
            except BadRequest: pass
        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][1]: continue
            try:
                timestamp_str = results[i][1]; current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                last_page_date = current_date_obj; current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'; valid_anchor_found = True
                break
            except (ValueError, TypeError): continue
        if not valid_anchor_found: termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; break
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(unique_results))))
        msg.edit_text(f"âœ… æ·±åº¦è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨å‘é€æ–‡ä»¶...")
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        with open(cache_path, 'rb') as doc: bot.send_document(chat_id, document=doc, filename=output_filename)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(base_query, cache_data); offer_post_download_actions(context, chat_id, base_query)
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)
def run_incremental_update_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; msg = bot.send_message(chat_id, "--- å¢é‡æ›´æ–°å¯åŠ¨ ---")
    msg.edit_text("1/5: æ­£åœ¨è·å–æ—§ç¼“å­˜..."); cached_item = find_cached_query(base_query)
    if not cached_item: msg.edit_text("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜é¡¹ã€‚"); return
    old_file_path = cached_item['cache']['file_path']; old_results = set()
    try:
        with open(old_file_path, 'r', encoding='utf-8') as f: old_results = set(line.strip() for line in f if line.strip() and ':' in line)
    except Exception as e: msg.edit_text(f"âŒ è¯»å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    msg.edit_text("2/5: æ­£åœ¨ç¡®å®šæ›´æ–°èµ·å§‹ç‚¹..."); data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, base_query, fields="lastupdatetime"))
    if error or not data.get('results'): msg.edit_text(f"âŒ æ— æ³•è·å–æœ€æ–°è®°å½•æ—¶é—´æˆ³: {error or 'æ— ç»“æœ'}"); return
    ts_str = data['results'][0][0] if isinstance(data['results'][0], list) else data['results'][0]; cutoff_date = ts_str.split(' ')[0]
    incremental_query = f'({base_query}) && after="{cutoff_date}"'
    msg.edit_text(f"3/5: æ­£åœ¨ä¾¦å¯Ÿè‡ª {cutoff_date} ä»¥æ¥çš„æ–°æ•°æ®..."); data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page_size=1))
    if error: msg.edit_text(f"âŒ ä¾¦å¯ŸæŸ¥è¯¢å¤±è´¥: {error}"); return
    total_new_size = data.get('size', 0)
    if total_new_size == 0: msg.edit_text("âœ… æœªå‘ç°æ–°æ•°æ®ã€‚ç¼“å­˜å·²æ˜¯æœ€æ–°ã€‚"); return
    new_results, stop_flag = set(), f'stop_job_{chat_id}'; pages_to_fetch = (total_new_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ å¢é‡æ›´æ–°å·²æ‰‹åŠ¨åœæ­¢ã€‚"); return
        msg.edit_text(f"3/5: æ­£åœ¨ä¸‹è½½æ–°æ•°æ®... ( Page {page}/{pages_to_fetch} )")
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page=page, page_size=10000))
        if error: msg.edit_text(f"âŒ ä¸‹è½½æ–°æ•°æ®å¤±è´¥: {error}"); return
        if data.get('results'): new_results.update(res for res in data.get('results', []) if ':' in res)
    msg.edit_text(f"4/5: æ­£åœ¨åˆå¹¶æ•°æ®... (å‘ç° {len(new_results)} æ¡æ–°æ•°æ®)"); combined_results = sorted(list(new_results.union(old_results)))
    with open(old_file_path, 'w', encoding='utf-8') as f: f.write("\n".join(combined_results))
    msg.edit_text(f"5/5: å‘é€æ›´æ–°åçš„æ–‡ä»¶... (å…± {len(combined_results)} æ¡)")
    with open(old_file_path, 'rb') as doc: bot.send_document(chat_id, document=doc, filename=os.path.basename(old_file_path))
    cache_data = {'file_path': old_file_path, 'result_count': len(combined_results)}
    add_or_update_query(base_query, cache_data)
    msg.delete(); bot.send_message(chat_id, f"âœ… å¢é‡æ›´æ–°å®Œæˆï¼"); offer_post_download_actions(context, chat_id, base_query)

# --- æ ¸å¿ƒå‘½ä»¤å¤„ç† ---
def start_command(update: Update, context: CallbackContext):
    update.message.reply_text('ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Fofa æŸ¥è¯¢æœºå™¨äººï¼è¯·ä½¿ç”¨ /help æŸ¥çœ‹å‘½ä»¤æ‰‹å†Œã€‚')
    if not CONFIG['admins']: first_admin_id = update.effective_user.id; CONFIG.setdefault('admins', []).append(first_admin_id); save_config(); update.message.reply_text(f"â„¹ï¸ å·²è‡ªåŠ¨å°†æ‚¨ (ID: `{first_admin_id}`) æ·»åŠ ä¸ºç¬¬ä¸€ä¸ªç®¡ç†å‘˜ã€‚")
def help_command(update: Update, context: CallbackContext):
    help_text = ( "ğŸ“– *Fofa æœºå™¨äººæŒ‡ä»¤æ‰‹å†Œ*\n\n"
                  "*ğŸ” èµ„äº§æŸ¥è¯¢*\n`/kkfofa [key] <query>` - FOFAæœç´¢\n_ä¸å¸¦å‚æ•°åˆ™æ˜¾ç¤ºé¢„è®¾èœå•_\n\n"
                  "*ğŸ“¦ ä¸»æœºè¯¦æŸ¥*\n`/host <ip|domain>`\n_è·å–å•ä¸ªä¸»æœºçš„è¯¦ç»†èšåˆä¿¡æ¯_\n\n"
                  "*ğŸ“Š èšåˆç»Ÿè®¡*\n`/stats <query>` - è·å–å…¨å±€èšåˆç»Ÿè®¡\n\n"
                  "*ğŸ“‚ æ‰¹é‡åˆ†æ*\n`/batchfind` - ä¸Šä¼ IPåˆ—è¡¨ä»¥åˆ†æå…±åŒç‰¹å¾\n\n"
                  "*âš™ï¸ ç®¡ç†ä¸è®¾ç½®*\n`/settings` - è¿›å…¥äº¤äº’å¼è®¾ç½®èœå•\n\n"
                  "*ğŸ’¾ é«˜çº§åŠŸèƒ½*\n"
                  "`/backup` / `/restore` - å¤‡ä»½/æ¢å¤\n"
                  "`/history` - æŸ¥è¯¢å†å²\n"
                  "`/import` - å¯¼å…¥æ—§ç»“æœ\n\n"
                  "*ğŸ’» ç³»ç»Ÿç®¡ç†*\n"
                  "`/update` - åœ¨çº¿æ›´æ–°è„šæœ¬\n"
                  "`/getlog` - è·å–æ—¥å¿—\n"
                  "`/shutdown` - å®‰å…¨å…³é—­æœºå™¨äºº\n\n"
                  "*ğŸ›‘ ä»»åŠ¡æ§åˆ¶*\n`/stop` - ç´§æ€¥åœæ­¢ä¸‹è½½ä»»åŠ¡\n`/cancel` - å–æ¶ˆå½“å‰æ“ä½œ" )
    update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

# --- /kkfofa æŸ¥è¯¢æµç¨‹ ---
def start_new_search(update: Update, context: CallbackContext, message_to_edit=None):
    query_text = context.user_data['query']; key_index = context.user_data.get('key_index'); add_or_update_query(query_text)
    msg = message_to_edit if message_to_edit else update.effective_message.reply_text("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    if message_to_edit: msg.edit_text("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    data, used_key_index, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page_size=1, fields="host"), key_index)
    if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
    total_size = data.get('size', 0)
    if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
    context.user_data.update({'total_size': total_size, 'chat_id': update.effective_chat.id})
    success_message = f"âœ… ä½¿ç”¨ Key [#{used_key_index}] æ‰¾åˆ° {total_size} æ¡ç»“æœã€‚"
    if total_size <= 10000:
        msg.edit_text(f"{success_message}\nå¼€å§‹ä¸‹è½½..."); start_download_job(context, run_full_download_query, context.user_data)
        return ConversationHandler.END
    else:
        keyboard = [[InlineKeyboardButton("ğŸ’ å…¨éƒ¨ä¸‹è½½ (å‰1ä¸‡)", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯ä¸‹è½½", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
        msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard)); return STATE_KKFOFA_MODE
def proceed_with_query(update: Update, context: CallbackContext, message_to_edit):
    query_text = context.user_data['query']
    cached_item = find_cached_query(query_text)
    if cached_item:
        dt_utc = datetime.fromisoformat(cached_item['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        message_text = (f"âœ… *å‘ç°ç¼“å­˜*\n\næŸ¥è¯¢: `{escape_markdown(query_text)}`\nç¼“å­˜äº: *{time_str}*\n\n")
        keyboard = []; is_expired = (datetime.now(tz.tzutc()) - dt_utc).total_seconds() > CACHE_EXPIRATION_SECONDS
        if is_expired: message_text += "âš ï¸ *æ­¤ç¼“å­˜å·²è¿‡æœŸï¼Œæ— æ³•å¢é‡æ›´æ–°ã€‚*"; keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½æ—§ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        else: message_text += "è¯·é€‰æ‹©æ“ä½œï¼š"; keyboard.append([InlineKeyboardButton("ğŸ”„ å¢é‡æ›´æ–°", callback_data='cache_incremental')]); keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        keyboard.append([InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='cache_cancel')])
        message_to_edit.edit_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
        return STATE_CACHE_CHOICE
    return start_new_search(update, context, message_to_edit=message_to_edit)

def kkfofa_entry(update: Update, context: CallbackContext):
    query_obj = update.callback_query
    message_obj = update.message
    
    if query_obj:
        query_obj.answer()
        try:
            preset_index = int(query_obj.data.replace("run_preset_", ""))
            preset = CONFIG["presets"][preset_index]
            query_text = preset['query']
            context.user_data['original_query'] = query_text
            context.user_data['key_index'] = None
            
            keyboard = [[InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"), InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")]]
            query_obj.message.edit_text(
                f"é¢„è®¾æŸ¥è¯¢: `{escape_markdown(query_text)}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ",
                reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN
            )
            return STATE_ASK_CONTINENT
        except (ValueError, IndexError):
            query_obj.message.edit_text("âŒ é¢„è®¾æŸ¥è¯¢å¤±è´¥ã€‚")
            return ConversationHandler.END

    if not context.args:
        presets = CONFIG.get("presets", [])
        if not presets:
            message_obj.reply_text("æ¬¢è¿ä½¿ç”¨FOFAæŸ¥è¯¢æœºå™¨äººã€‚\n\nâ¡ï¸ ç›´æ¥è¾“å…¥æŸ¥è¯¢è¯­æ³•: `/kkfofa domain=\"example.com\"`\nâ„¹ï¸ å½“å‰æ²¡æœ‰å¯ç”¨çš„é¢„è®¾æŸ¥è¯¢ã€‚ç®¡ç†å‘˜å¯é€šè¿‡ /settings æ·»åŠ ã€‚")
            return ConversationHandler.END
        
        keyboard = []
        for i, p in enumerate(presets):
            query_preview = p['query']
            if len(query_preview) > 25: query_preview = query_preview[:25] + '...'
            button_text = f"{p['name']} (`{query_preview}`)"
            keyboard.append([InlineKeyboardButton(button_text, callback_data=f"run_preset_{i}")])
        
        message_obj.reply_text("ğŸ‘‡ è¯·é€‰æ‹©ä¸€ä¸ªé¢„è®¾æŸ¥è¯¢:", reply_markup=InlineKeyboardMarkup(keyboard))
        return ConversationHandler.END
    
    key_index, query_text = None, " ".join(context.args)
    if context.args[0].isdigit():
        try:
            num = int(context.args[0])
            if 1 <= num <= len(CONFIG['apis']): key_index = num; query_text = " ".join(context.args[1:])
        except ValueError: pass
    
    context.user_data['original_query'] = query_text
    context.user_data['key_index'] = key_index
    
    keyboard = [[InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"), InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")]]
    message_obj.reply_text(
        f"æŸ¥è¯¢: `{escape_markdown(query_text)}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ",
        reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN
    )
    return STATE_ASK_CONTINENT

def ask_continent_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    if choice == 'skip':
        context.user_data['query'] = context.user_data['original_query']
        query.message.edit_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown(context.user_data['query'])}`", parse_mode=ParseMode.MARKDOWN)
        return proceed_with_query(update, context, message_to_edit=query.message)
    elif choice == 'select':
        keyboard = [
            [InlineKeyboardButton("ğŸŒ äºšæ´²", callback_data="continent_Asia"), InlineKeyboardButton("ğŸŒ æ¬§æ´²", callback_data="continent_Europe")],
            [InlineKeyboardButton("ğŸŒ åŒ—ç¾æ´²", callback_data="continent_NorthAmerica"), InlineKeyboardButton("ğŸŒ å—ç¾æ´²", callback_data="continent_SouthAmerica")],
            [InlineKeyboardButton("ğŸŒ éæ´²", callback_data="continent_Africa"), InlineKeyboardButton("ğŸŒ å¤§æ´‹æ´²", callback_data="continent_Oceania")],
            [InlineKeyboardButton("â†©ï¸ è·³è¿‡", callback_data="continent_skip")]]
        query.message.edit_text("è¯·é€‰æ‹©ä¸€ä¸ªå¤§æ´²:", reply_markup=InlineKeyboardMarkup(keyboard)); return STATE_CONTINENT_CHOICE
def continent_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); continent = query.data.split('_', 1)[1]
    original_query = context.user_data['original_query']
    if continent == 'skip':
        context.user_data['query'] = original_query
        query.message.edit_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown(original_query)}`", parse_mode=ParseMode.MARKDOWN)
        return proceed_with_query(update, context, message_to_edit=query.message)
    country_list = CONTINENT_COUNTRIES.get(continent)
    if not country_list: query.message.edit_text("âŒ é”™è¯¯ï¼šæ— æ•ˆçš„å¤§æ´²é€‰é¡¹ã€‚"); return ConversationHandler.END
    country_fofa_string = " || ".join([f'country="{code}"' for code in country_list])
    final_query = f"({original_query}) && ({country_fofa_string})"
    context.user_data['query'] = final_query
    query.message.edit_text(f"æŸ¥è¯¢å·²æ„å»º:\n`{escape_markdown(final_query)}`\n\næ­£åœ¨å¤„ç†...", parse_mode=ParseMode.MARKDOWN)
    return proceed_with_query(update, context, message_to_edit=query.message)
def cache_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    if choice == 'download':
        cached_item = find_cached_query(context.user_data['query'])
        if cached_item:
            query.message.edit_text("â¬‡ï¸ æ­£åœ¨ä»æœ¬åœ°ç¼“å­˜å‘é€æ–‡ä»¶...");
            file_path = cached_item['cache']['file_path']
            try:
                with open(file_path, 'rb') as doc:
                    context.bot.send_document(chat_id=update.effective_chat.id, document=doc, filename=os.path.basename(file_path))
                query.message.delete()
            except Exception as e: query.message.edit_text(f"âŒ å‘é€ç¼“å­˜å¤±è´¥: {e}")
        else: query.message.edit_text("âŒ æ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜è®°å½•ã€‚")
        return ConversationHandler.END
    elif choice == 'newsearch': return start_new_search(update, context, message_to_edit=query.message)
    elif choice == 'incremental': query.edit_message_text("â³ å‡†å¤‡å¢é‡æ›´æ–°..."); start_download_job(context, run_incremental_update_query, context.user_data); query.message.delete(); return ConversationHandler.END
    elif choice == 'cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆã€‚"); return ConversationHandler.END
def query_mode_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); mode = query.data.split('_')[1]
    if mode == 'full': query.message.edit_text(f"â³ å¼€å§‹å…¨é‡ä¸‹è½½..."); start_download_job(context, run_full_download_query, context.user_data); query.message.delete()
    elif mode == 'traceback': query.message.edit_text(f"â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½..."); start_download_job(context, run_traceback_download_query, context.user_data); query.message.delete()
    elif mode == 'cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆã€‚")
    return ConversationHandler.END

# --- /batchfind æ‰¹é‡ç‰¹å¾åˆ†æ ---
@admin_only
def batchfind_command(update: Update, context: CallbackContext) -> int:
    update.message.reply_text("è¯·ä¸Šä¼ ä¸€ä¸ªåŒ…å« `ip:port` åˆ—è¡¨çš„ `.txt` æ–‡ä»¶ (æ¯è¡Œä¸€ä¸ª)ã€‚\n\næˆ‘å°†æå–å‰100è¡Œè¿›è¡Œæ‰¹é‡ç‰¹å¾åˆ†æã€‚")
    return STATE_GET_BATCH_FILE

def build_feature_keyboard(selected_features=None):
    if selected_features is None: selected_features = set()
    keyboard = []
    features = list(BATCH_FEATURES.items())
    for i in range(0, len(features), 2):
        row = []
        key, name = features[i]
        text = f"{'âœ… ' if key in selected_features else ''}{name}"
        row.append(InlineKeyboardButton(text, callback_data=f"batchfeature_{key}"))
        if i + 1 < len(features):
            key, name = features[i+1]
            text = f"{'âœ… ' if key in selected_features else ''}{name}"
            row.append(InlineKeyboardButton(text, callback_data=f"batchfeature_{key}"))
        keyboard.append(row)
    keyboard.append([InlineKeyboardButton("ğŸš€ å¼€å§‹åˆ†æ", callback_data="batchfeature_done")])
    keyboard.append([InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data="batchfeature_cancel")])
    return InlineKeyboardMarkup(keyboard)

@admin_only
def get_batch_file_handler(update: Update, context: CallbackContext) -> int:
    doc = update.message.document
    if not doc.file_name.lower().endswith('.txt'):
        update.message.reply_text("âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ä¸Šä¼  `.txt` æ–‡ä»¶ã€‚")
        return ConversationHandler.END

    msg = update.message.reply_text("æ­£åœ¨ä¸‹è½½å¹¶è§£ææ–‡ä»¶...")
    try:
        file = doc.get_file()
        temp_path = os.path.join(FOFA_CACHE_DIR, f"batch_{doc.file_id}.txt")
        file.download(temp_path)
        context.user_data['batch_file_path'] = temp_path
        context.user_data['selected_features'] = set()
        
        targets = []
        # Regex to find an IP:PORT at the beginning of a line, ignoring surrounding whitespace
        ip_port_pattern = re.compile(r"^\s*(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5})")
        with open(temp_path, 'r', encoding='utf-8') as f:
            for line in f:
                if len(targets) >= 100:
                    break
                match = ip_port_pattern.match(line)
                if match:
                    targets.append(match.group(1))
        
        if not targets:
            msg.edit_text("âŒ æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•ä»ä¸­æå–ä»»ä½• `ip:port` æ ¼å¼çš„æ•°æ®ï¼Œæ“ä½œå·²å–æ¶ˆã€‚")
            os.remove(temp_path)
            return ConversationHandler.END

        context.user_data['targets'] = targets
        msg.edit_text(f"âœ… æ–‡ä»¶å¤„ç†æˆåŠŸï¼Œå…±æå– {len(targets)} ä¸ªç›®æ ‡ã€‚\n\nè¯·é€‰æ‹©æ‚¨æƒ³åˆ†æçš„ç‰¹å¾ (å¯å¤šé€‰):",
                      reply_markup=build_feature_keyboard())
        return STATE_SELECT_BATCH_FEATURES

    except Exception as e:
        logger.error(f"å¤„ç†æ‰¹é‡æ–‡ä»¶å¤±è´¥: {e}")
        msg.edit_text(f"âŒ å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return ConversationHandler.END

@admin_only
def select_batch_features_callback(update: Update, context: CallbackContext) -> int:
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]

    if action == 'cancel':
        query.message.edit_text("æ“ä½œå·²å–æ¶ˆã€‚")
        if 'batch_file_path' in context.user_data and os.path.exists(context.user_data['batch_file_path']):
            os.remove(context.user_data['batch_file_path'])
        return ConversationHandler.END

    if action == 'done':
        if not context.user_data.get('selected_features'):
            query.answer("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè¦åˆ†æçš„ç‰¹å¾!", show_alert=True)
            return STATE_SELECT_BATCH_FEATURES
        
        query.message.edit_text("â³ ä»»åŠ¡å·²æäº¤åˆ°åå°ï¼Œæ­£åœ¨æ‰¹é‡æŸ¥è¯¢å’Œåˆ†æ...")
        job_data = {
            'chat_id': update.effective_chat.id,
            'targets': context.user_data['targets'],
            'selected_features': list(context.user_data['selected_features']),
            'file_path': context.user_data['batch_file_path'],
            'msg_id': query.message.message_id
        }
        context.job_queue.run_once(run_batch_find_job, 1, context=job_data)
        return ConversationHandler.END

    selected_features = context.user_data.get('selected_features', set())
    if action in selected_features: selected_features.remove(action)
    else: selected_features.add(action)
    context.user_data['selected_features'] = selected_features
    query.message.edit_reply_markup(reply_markup=build_feature_keyboard(selected_features))
    return STATE_SELECT_BATCH_FEATURES

def run_batch_find_job(context: CallbackContext):
    job_context = context.job.context
    chat_id, targets, selected_features, file_path, msg_id = job_context['chat_id'], job_context['targets'], job_context['selected_features'], job_context['file_path'], job_context['msg_id']
    bot = context.bot; feature_analysis = {feature: {} for feature in selected_features}
    
    fields_to_fetch_set = set(selected_features)
    fields_to_fetch_set.update(["ip", "port", "banner", "header"])
    fields_to_fetch = ",".join(list(fields_to_fetch_set))
    
    total_targets = len(targets); completed_count = 0; last_update_time = time.time()

    def fetch_single_target(target):
        nonlocal completed_count, last_update_time
        try:
            try: ip, port = target.rsplit(':', 1)
            except ValueError: logger.warning(f"Skipping malformed target in batchfind: {target}"); return None
            query_text = f'ip="{ip}" && port="{port}"'
            data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page_size=1, fields=fields_to_fetch))
            if not error and data and data.get('results'): return data['results'][0]
            return None
        finally:
            completed_count += 1; current_time = time.time()
            if current_time - last_update_time > 2.5:
                try:
                    progress_percent = (completed_count / total_targets) * 100
                    progress_bar = create_progress_bar(progress_percent)
                    bot.edit_message_text(f"â³ æ­£åœ¨åˆ†æ...\n`{progress_bar}`", chat_id=chat_id, message_id=msg_id, parse_mode=ParseMode.MARKDOWN)
                    last_update_time = current_time
                except (BadRequest, RetryAfter): pass

    with ThreadPoolExecutor(max_workers=20) as executor:
        all_results = list(executor.map(fetch_single_target, targets))

    field_map = {name: idx for idx, name in enumerate(fields_to_fetch.split(','))}
    
    success_count = 0
    for result in all_results:
        if result is None: continue
        success_count += 1
        for feature in selected_features:
            value = result[field_map[feature]]
            if value is not None and value != '':
                if feature in ['banner', 'header']:
                    fingerprint = normalize_banner(value)
                    if not fingerprint: continue
                    if fingerprint in feature_analysis[feature]: feature_analysis[feature][fingerprint]['count'] += 1
                    else: feature_analysis[feature][fingerprint] = {'count': 1, 'example': value}
                else:
                    feature_analysis[feature].setdefault(value, 0); feature_analysis[feature][value] += 1
    
    report_lines = [f"ğŸ“Š *æ‰¹é‡ç‰¹å¾åˆ†ææŠ¥å‘Š*"]
    report_lines.append("\n--- *æŸ¥è¯¢æ¦‚è§ˆ* ---")
    report_lines.append(f"*   æ€»ç›®æ ‡æ•°:* `{total_targets}`")
    report_lines.append(f"*   æˆåŠŸæ‰¾åˆ°:* `{success_count}`")
    report_lines.append(f"*   æœªæ‰¾åˆ°æ•°æ®:* `{total_targets - success_count}`")
    if success_count > 0:
        report_lines.append(f"\n*ï¼ˆæ³¨æ„ï¼šä»¥ä¸‹ç‰¹å¾åˆ†æä»…åŸºäºæˆåŠŸæ‰¾åˆ°çš„ {success_count} ä¸ªç›®æ ‡ï¼‰*")
    report_lines.append("")

    if success_count > 0:
        for feature, counts in feature_analysis.items():
            feature_name = BATCH_FEATURES.get(feature, feature)
            report_lines.append(f"--- *Top 5 {feature_name}* ---")
            if not counts: report_lines.append("_æœªå‘ç°è¯¥ç‰¹å¾çš„æ•°æ®_")
            else:
                if feature in ['banner', 'header']:
                    sorted_items = sorted(counts.values(), key=lambda item: item['count'], reverse=True)
                    for item in sorted_items[:5]:
                        count = item['count']; display_value = (item['example'][:70] + '...') if len(item['example']) > 70 else item['example']
                        report_lines.append(f"`{escape_markdown(display_value)}`: *{count}*")
                else:
                    sorted_items = sorted(counts.items(), key=lambda item: item[1], reverse=True)
                    for value, count in sorted_items[:5]:
                        display_value = (str(value)[:70] + '...') if len(str(value)) > 70 else value
                        report_lines.append(f"`{escape_markdown(display_value)}`: *{count}*")
            report_lines.append("")

        dominant_query_parts = []
        query_builder_features = ["protocol", "os", "server", "cert.issuer.cn", "cert.subject.org", "domain", "icp"]
        threshold = success_count / 2

        for feature in query_builder_features:
            if feature in feature_analysis and feature_analysis[feature]:
                counts = feature_analysis[feature]
                top_item = max(counts.items(), key=lambda item: item[1])
                top_value, top_count = top_item
                if top_count >= threshold:
                    dominant_query_parts.append(f'{feature}="{top_value}"' if " " in str(top_value) else f'{feature}={top_value}')

        if dominant_query_parts:
            suggested_query = " && ".join(dominant_query_parts)
            report_lines.append("--- *ğŸ’¡ å»ºè®®çš„FOFAæŸ¥è¯¢* ---")
            report_lines.append("æ ¹æ®åˆ†æï¼Œä»¥ä¸‹æŸ¥è¯¢å¯è¦†ç›–å¤§éƒ¨åˆ†*å·²æ‰¾åˆ°*çš„ç›®æ ‡:")
            report_lines.append(f"`{escape_markdown(suggested_query)}`")
            report_lines.append("")

    final_report = "\n".join(report_lines)
    if len(final_report) > 4096: final_report = final_report[:4090] + "\n...å†…å®¹è¿‡é•¿å·²æˆªæ–­..."
    bot.edit_message_text(final_report, chat_id=chat_id, message_id=msg_id, parse_mode=ParseMode.MARKDOWN, disable_web_page_preview=True)
    if os.path.exists(file_path): os.remove(file_path)

# --- å…¶ä»–ç®¡ç†å‘½ä»¤ ---
@admin_only
def stop_all_tasks(update: Update, context: CallbackContext): context.bot_data[f'stop_job_{update.effective_chat.id}'] = True; update.message.reply_text("âœ… å·²å‘é€åœæ­¢ä¿¡å·ã€‚")
@admin_only
def backup_config_command(update: Update, context: CallbackContext):
    if os.path.exists(CONFIG_FILE): update.effective_chat.send_document(document=open(CONFIG_FILE, 'rb'))
    else: update.effective_chat.send_message("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ã€‚")

@admin_only
def restore_config_command(update: Update, context: CallbackContext) -> int:
    update.message.reply_text("ğŸ“¥ è¯·ä¸Šä¼ æ‚¨çš„ `config.json` æ–‡ä»¶ä»¥æ¢å¤é…ç½®ã€‚\n\néšæ—¶å¯ä»¥å‘é€ /cancel æ¥å–æ¶ˆã€‚")
    return STATE_GET_RESTORE_FILE

@admin_only
def receive_config_file(update: Update, context: CallbackContext) -> int:
    global CONFIG
    if not update.message.document or update.message.document.file_name != CONFIG_FILE:
        update.message.reply_text(f"âŒ æ“ä½œå¤±è´¥ï¼Œå¿…é¡»ä¸Šä¼ ä¸€ä¸ªåä¸º `{CONFIG_FILE}` çš„æ–‡ä»¶ã€‚")
        return ConversationHandler.END
    
    try:
        file = update.message.document.get_file(); temp_path = f"{CONFIG_FILE}.tmp"; file.download(temp_path)
        with open(temp_path, 'r', encoding='utf-8') as f: json.load(f)
        os.replace(temp_path, CONFIG_FILE); CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
        update.message.reply_text("âœ… é…ç½®å·²æˆåŠŸæ¢å¤ï¼æœºå™¨äººåŠŸèƒ½å¯èƒ½éœ€è¦é‡å¯åå®Œå…¨ç”Ÿæ•ˆã€‚")
    except Exception as e:
        logger.error(f"æ¢å¤é…ç½®å¤±è´¥: {e}"); update.message.reply_text(f"âŒ æ¢å¤å¤±è´¥: {e}")
        if os.path.exists(temp_path): os.remove(temp_path)
    
    return ConversationHandler.END

@admin_only
def history_command(update: Update, context: CallbackContext):
    if not HISTORY['queries']: update.message.reply_text("ğŸ•°ï¸ æš‚æ— å†å²è®°å½•ã€‚"); return
    message_text = "ğŸ•°ï¸ *æœ€è¿‘10æ¡æŸ¥è¯¢è®°å½•:*\n\n"
    for i, query_hist in enumerate(HISTORY['queries'][:10]):
        dt_utc = datetime.fromisoformat(query_hist['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M'); cache_icon = "âœ…" if query_hist.get('cache') else "âŒ"
        message_text += f"`{i+1}.` {escape_markdown(query_hist['query_text'])}\n_{time_str}_  (ç¼“å­˜: {cache_icon})\n\n"
    update.message.reply_text(message_text, parse_mode=ParseMode.MARKDOWN)
@admin_only
def import_command(update: Update, context: CallbackContext):
    if not update.message.reply_to_message or not update.message.reply_to_message.document: update.message.reply_text("âŒ *ç”¨æ³•é”™è¯¯*\nè¯·*å›å¤ (Reply)*ä¸€ä¸ªæ‚¨æƒ³å¯¼å…¥çš„`.txt`æ–‡ä»¶ï¼Œå†è¾“å…¥æ­¤å‘½ä»¤ã€‚", parse_mode=ParseMode.MARKDOWN); return
    context.user_data['import_doc'] = update.message.reply_to_message.document; update.message.reply_text("å¥½çš„ï¼Œå·²æ”¶åˆ°æ–‡ä»¶ã€‚\nç°åœ¨è¯·è¾“å…¥ä¸æ­¤æ–‡ä»¶å…³è”çš„ *FOFA æŸ¥è¯¢è¯­å¥*ï¼š", parse_mode=ParseMode.MARKDOWN); return STATE_GET_IMPORT_QUERY
def get_import_query(update: Update, context: CallbackContext):
    doc = context.user_data.get('import_doc'); query_text = update.message.text.strip()
    if not doc or not query_text: update.message.reply_text("âŒ æ“ä½œå·²è¿‡æ—¶æˆ–æŸ¥è¯¢ä¸ºç©ºã€‚"); return ConversationHandler.END
    cache_path = os.path.join(FOFA_CACHE_DIR, f"imported_{doc.file_name}_{int(time.time())}.txt")
    msg = update.message.reply_text("æ­£åœ¨ä¸‹è½½å¹¶ä¿å­˜å¯¼å…¥æ–‡ä»¶åˆ°æœ¬åœ°ç¼“å­˜...")
    try:
        file = doc.get_file(); file.download(cache_path)
        with open(cache_path, 'r', encoding='utf-8') as f: counted_lines = sum(1 for line in f if line.strip())
        cache_data = {'file_path': cache_path, 'result_count': counted_lines}
        add_or_update_query(query_text, cache_data)
        msg.edit_text(f"âœ… *å¯¼å…¥æˆåŠŸï¼*\n\næŸ¥è¯¢ `{escape_markdown(query_text)}` å·²æˆåŠŸå…³è”æœ¬åœ°ç¼“å­˜ï¼Œå…± *{counted_lines}* æ¡ç»“æœã€‚", parse_mode=ParseMode.MARKDOWN)
    except Exception as e:
        logger.error(f"å¯¼å…¥æ–‡ä»¶å¤±è´¥: {e}"); msg.edit_text(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        if os.path.exists(cache_path): os.remove(cache_path)
    context.user_data.clear(); return ConversationHandler.END
@admin_only
def get_log_command(update: Update, context: CallbackContext):
    if os.path.exists(LOG_FILE): update.message.reply_document(document=open(LOG_FILE, 'rb'))
    else: update.message.reply_text("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚")
@admin_only
def shutdown_command(update: Update, context: CallbackContext):
    update.message.reply_text("âœ… æ”¶åˆ°æŒ‡ä»¤ï¼æœºå™¨äººæ­£åœ¨å¹³ç¨³å…³é—­..."); logger.info(f"æ¥æ”¶åˆ°æ¥è‡ªç”¨æˆ· {update.effective_user.id} çš„å…³é—­æŒ‡ä»¤ã€‚")
    context.job_queue.run_once(lambda _: os.kill(os.getpid(), signal.SIGINT), 1)
@admin_only
def update_script_command(update: Update, context: CallbackContext, from_menu=False):
    url = CONFIG.get("update_url")
    if not url:
        msg_target = update.callback_query.message if from_menu else update.message
        msg_target.reply_text("âŒ æœªåœ¨é…ç½®ä¸­è®¾ç½®æ›´æ–°URLã€‚\nè¯·åœ¨ /settings -> è„šæœ¬æ›´æ–° ä¸­è®¾ç½®ã€‚")
        return
    msg = update.callback_query.message if from_menu else update.message.reply_text("â³ æ­£åœ¨ä»é…ç½®çš„URLæ£€æŸ¥æ›´æ–°...")
    if from_menu: msg.edit_text("â³ æ­£åœ¨ä»é…ç½®çš„URLæ£€æŸ¥æ›´æ–°...")
    try:
        response = requests.get(url, timeout=30, proxies=get_proxies()); response.raise_for_status()
        new_script_content = response.text
    except requests.exceptions.RequestException as e: msg.edit_text(f"âŒ ä¸‹è½½æ›´æ–°å¤±è´¥: {e}"); return
    if 'if __name__ == "__main__":' not in new_script_content or 'Updater(' not in new_script_content:
        msg.edit_text("âŒ ä¸‹è½½çš„æ–‡ä»¶ä¼¼ä¹ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æœºå™¨äººè„šæœ¬ï¼Œå·²ä¸­æ­¢æ›´æ–°ã€‚"); return
    script_path = os.path.abspath(sys.argv[0]); temp_path = script_path + ".new"
    try:
        with open(temp_path, 'w', encoding='utf-8') as f: f.write(new_script_content)
    except IOError as e: msg.edit_text(f"âŒ æ— æ³•å†™å…¥ä¸´æ—¶æ–‡ä»¶: {e}"); return
    try: os.replace(temp_path, script_path)
    except OSError as e:
        msg.edit_text(f"âŒ æ›¿æ¢è„šæœ¬æ–‡ä»¶å¤±è´¥: {e}")
        if os.path.exists(temp_path): os.remove(temp_path)
        return
    msg.edit_text("âœ… æ›´æ–°æˆåŠŸï¼æœºå™¨äººå°†åœ¨2ç§’åé‡å¯ä»¥åº”ç”¨æ–°ç‰ˆæœ¬...")
    logger.info(f"è„šæœ¬å·²ç”±ç”¨æˆ· {update.effective_user.id} æ›´æ–°ã€‚æ­£åœ¨é‡å¯...")
    def restart(context: CallbackContext): os.execv(sys.executable, [sys.executable] + sys.argv)
    context.job_queue.run_once(restart, 2)

# --- è®¾ç½®èœå• (Settings Conversation) ---
@admin_only
def settings_command(update: Update, context: CallbackContext):
    keyboard = [
        [InlineKeyboardButton("ğŸ”‘ API ç®¡ç†", callback_data='settings_api')],
        [InlineKeyboardButton("âœ¨ é¢„è®¾ç®¡ç†", callback_data='settings_preset')],
        [InlineKeyboardButton("ğŸŒ ä»£ç†è®¾ç½®", callback_data='settings_proxy')],
        [InlineKeyboardButton("ğŸ’¾ å¤‡ä»½ä¸æ¢å¤", callback_data='settings_backup')],
        [InlineKeyboardButton("ğŸ”„ è„šæœ¬æ›´æ–°", callback_data='settings_update')],
        [InlineKeyboardButton("âŒ å…³é—­èœå•", callback_data='settings_close')]
    ]
    message_text = "âš™ï¸ *è®¾ç½®èœå•*"; reply_markup = InlineKeyboardMarkup(keyboard)
    if update.callback_query: update.callback_query.message.edit_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    else: update.message.reply_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_MAIN
def settings_callback_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); menu = query.data.split('_', 1)[1]
    if menu == 'api': return show_api_menu(update, context)
    if menu == 'proxy': return show_proxy_menu(update, context)
    if menu == 'backup': return show_backup_restore_menu(update, context)
    if menu == 'preset': return show_preset_menu(update, context)
    if menu == 'update': return show_update_menu(update, context)
    if menu == 'close': query.message.edit_text("èœå•å·²å…³é—­."); return ConversationHandler.END
    return STATE_SETTINGS_ACTION
def show_api_menu(update: Update, context: CallbackContext):
    msg = update.callback_query.message
    msg.edit_text("ğŸ”„ æ­£åœ¨æŸ¥è¯¢API KeyçŠ¶æ€...")
    api_details = []
    for i, key in enumerate(CONFIG['apis']):
        data, error = verify_fofa_api(key)
        key_masked = f"`...{key[-4:]}`"
        if error: status = f"âŒ *æ— æ•ˆ*: {error}"
        else:
            username = escape_markdown(data.get('username', 'N/A')); vip_level = data.get('vip_level', 0)
            vip_status = f"ğŸ‘‘ VIP L{vip_level}" if data.get('is_vip') else "ğŸ‘¤ æ™®é€š"
            f_points = data.get('fofa_point', 0); free_points = data.get('remain_free_point', 0)
            status = f"{vip_status} ({username}) | Fç‚¹: *{f_points}*, å…è´¹ç‚¹: *{free_points}*"
        api_details.append(f"`#{i+1}` {key_masked}\n  {status}")
    api_message = "\n\n".join(api_details) if api_details else "_æ— _"
    keyboard = [[InlineKeyboardButton(f"æŸ¥è¯¢èŒƒå›´: {'âœ… å®Œæ•´å†å²' if CONFIG.get('full_mode') else 'â³ è¿‘ä¸€å¹´'}", callback_data='action_toggle_full')], [InlineKeyboardButton("â• æ·»åŠ Key", callback_data='action_add_api'), InlineKeyboardButton("â– åˆ é™¤Key", callback_data='action_remove_api')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back_main')]]
    msg.edit_text(f"ğŸ”‘ *API ç®¡ç†*\n\n{api_message}", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_ACTION
def show_proxy_menu(update: Update, context: CallbackContext):
    keyboard = [[InlineKeyboardButton("âœï¸ è®¾ç½®/æ›´æ–°", callback_data='action_set_proxy')], [InlineKeyboardButton("ğŸ—‘ï¸ æ¸…é™¤", callback_data='action_delete_proxy')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back_main')]]
    update.callback_query.message.edit_text(f"ğŸŒ *ä»£ç†è®¾ç½®*\nå½“å‰: `{CONFIG.get('proxy') or 'æœªè®¾ç½®'}`", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN); return STATE_SETTINGS_ACTION
def show_backup_restore_menu(update: Update, context: CallbackContext):
    message_text = ("ğŸ’¾ *å¤‡ä»½ä¸æ¢å¤*\n\nğŸ“¤ *å¤‡ä»½*\nç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œæˆ–ä½¿ç”¨ /backup å‘½ä»¤ã€‚\n\nğŸ“¥ *æ¢å¤*\nä½¿ç”¨ /restore å‘½ä»¤ï¼Œç„¶åæŒ‰æç¤ºä¸Šä¼ æ–‡ä»¶ã€‚"); keyboard = [[InlineKeyboardButton("ğŸ“¤ ç«‹å³å¤‡ä»½", callback_data='action_backup_now')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back_main')]]
    update.callback_query.message.edit_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN); return STATE_SETTINGS_ACTION
def show_update_menu(update: Update, context: CallbackContext):
    current_url = CONFIG.get("update_url") or "æœªè®¾ç½®"
    message_text = f"ğŸ”„ *è„šæœ¬æ›´æ–°*\n\næ­¤åŠŸèƒ½å…è®¸æœºå™¨äººä»æŒ‡å®šçš„URLä¸‹è½½æœ€æ–°è„šæœ¬å¹¶è‡ªåŠ¨é‡å¯ã€‚\n\n*å½“å‰æ›´æ–°æº URL:*\n`{escape_markdown(current_url)}`"
    keyboard = [
        [InlineKeyboardButton("âœï¸ è®¾ç½®/æ›´æ–° URL", callback_data='action_set_update_url')],
        [InlineKeyboardButton("ğŸš€ ç«‹å³æ›´æ–°", callback_data='action_run_update')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back_main')]
    ]
    update.callback_query.message.edit_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_ACTION
def settings_action_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back_main': return settings_command(update, context)
    elif action == 'toggle_full': CONFIG["full_mode"] = not CONFIG.get("full_mode", False); save_config(); return show_api_menu(update, context)
    elif action == 'add_api': query.message.edit_text("è¯·å‘é€æ‚¨çš„ Fofa API Keyã€‚"); return STATE_GET_KEY
    elif action == 'remove_api': query.message.edit_text("è¯·è¾“å…¥è¦åˆ é™¤çš„API Keyç¼–å·(#)ã€‚"); return STATE_REMOVE_API
    elif action == 'set_proxy': query.message.edit_text("è¯·è¾“å…¥ä»£ç†åœ°å€ (ä¾‹å¦‚ http://127.0.0.1:7890)ã€‚"); return STATE_GET_PROXY
    elif action == 'delete_proxy': CONFIG['proxy'] = ""; save_config(); query.answer("ä»£ç†å·²æ¸…é™¤"); return show_proxy_menu(update, context)
    elif action == 'backup_now': backup_config_command(update, context); return STATE_SETTINGS_ACTION
    elif action == 'set_update_url': query.message.edit_text("è¯·å‘é€æ–°çš„è„šæœ¬æ›´æ–°URL (å¿…é¡»æ˜¯å¯ç›´æ¥è®¿é—®çš„ raw æ–‡ä»¶é“¾æ¥)ã€‚"); return STATE_GET_UPDATE_URL
    elif action == 'run_update': update_script_command(query, context, from_menu=True); return ConversationHandler.END
    return STATE_SETTINGS_ACTION
def get_key(update: Update, context: CallbackContext):
    key = update.message.text.strip(); msg = update.message.reply_text("æ­£åœ¨éªŒè¯...")
    data, error = verify_fofa_api(key)
    if not error: CONFIG['apis'].append(key); save_config(); msg.edit_text(f"âœ… æ·»åŠ æˆåŠŸï¼")
    else: msg.edit_text(f"âŒ éªŒè¯å¤±è´¥: {error}")
    return settings_command(update, context)
def get_proxy(update: Update, context: CallbackContext):
    CONFIG['proxy'] = update.message.text.strip(); save_config(); update.message.reply_text(f"âœ… ä»£ç†å·²æ›´æ–°ã€‚"); return settings_command(update, context)
def remove_api(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['apis']): CONFIG['apis'].pop(index); save_config(); update.message.reply_text(f"âœ… Keyå·²åˆ é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆç¼–å·ã€‚")
    except (ValueError, IndexError): update.message.reply_text("âŒ è¯·è¾“å…¥æ•°å­—ã€‚")
    return settings_command(update, context)
def get_update_url(update: Update, context: CallbackContext):
    url = update.message.text.strip()
    if url.startswith("http://") or url.startswith("https://"):
        CONFIG['update_url'] = url; save_config(); update.message.reply_text("âœ… æ›´æ–°URLå·²è®¾ç½®ã€‚")
    else: update.message.reply_text("âŒ URLæ ¼å¼æ— æ•ˆï¼Œè¯·è¾“å…¥ä»¥ http:// æˆ– https:// å¼€å¤´çš„é“¾æ¥ã€‚")
    return settings_command(update, context)
def show_preset_menu(update: Update, context: CallbackContext):
    preset_list = "\n".join([f"`#{i+1}`: `{p['name']}`" for i, p in enumerate(CONFIG['presets'])]) or "_æ— _"
    text = f"âœ¨ *é¢„è®¾ç®¡ç†*\n\n{preset_list}"; kbd = [[InlineKeyboardButton("â• æ·»åŠ ", callback_data='preset_add'), InlineKeyboardButton("â– ç§»é™¤", callback_data='preset_remove')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='preset_back')]]
    update.callback_query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(kbd), parse_mode=ParseMode.MARKDOWN); return STATE_PRESET_MENU
def preset_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back': return settings_command(update, context)
    if action == 'add': query.message.edit_text("è¯·è¾“å…¥é¢„è®¾çš„åç§° (ä¾‹å¦‚: æµ·åº·å¨è§†æ‘„åƒå¤´):"); return STATE_GET_PRESET_NAME
    if action == 'remove': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„é¢„è®¾çš„ç¼–å·(#):"); return STATE_REMOVE_PRESET
    return STATE_PRESET_MENU
def get_preset_name(update: Update, context: CallbackContext):
    context.user_data['preset_name'] = update.message.text.strip(); update.message.reply_text(f"åç§°: `{context.user_data['preset_name']}`\n\nç°åœ¨è¯·è¾“å…¥å®Œæ•´çš„FOFAæŸ¥è¯¢è¯­æ³•:"); return STATE_GET_PRESET_QUERY
def get_preset_query(update: Update, context: CallbackContext):
    new_preset = {"name": context.user_data['preset_name'], "query": update.message.text.strip()}; CONFIG['presets'].append(new_preset); save_config()
    update.message.reply_text("âœ… é¢„è®¾æ·»åŠ æˆåŠŸï¼"); context.user_data.clear(); return settings_command(update, context)
def remove_preset(update: Update, context: CallbackContext):
    try:
        idx = int(update.message.text.strip()) - 1
        if 0 <= idx < len(CONFIG['presets']): CONFIG['presets'].pop(idx); save_config(); update.message.reply_text("âœ… é¢„è®¾å·²ç§»é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def cancel(update: Update, context: CallbackContext):
    if update.callback_query: update.callback_query.message.edit_text('æ“ä½œå·²å–æ¶ˆã€‚')
    elif update.message: update.message.reply_text('æ“ä½œå·²å–æ¶ˆã€‚')
    context.user_data.clear(); return ConversationHandler.END

# --- ä¸»å‡½æ•°ä¸è°ƒåº¦å™¨ ---
def main() -> None:
    os.makedirs(FOFA_CACHE_DIR, exist_ok=True)
    bot_token = CONFIG.get("bot_token")
    if not bot_token or bot_token == "YOUR_BOT_TOKEN_HERE":
        logger.critical("ä¸¥é‡é”™è¯¯ï¼šconfig.json ä¸­çš„ 'bot_token' æœªè®¾ç½®ï¼")
        if not os.path.exists(CONFIG_FILE): save_config()
        return

    updater = Updater(token=bot_token, use_context=True)
    dispatcher = updater.dispatcher
    commands = [
        BotCommand("start", "ğŸš€ å¯åŠ¨ä¸å¸®åŠ©"), BotCommand("help", "â“ å‘½ä»¤æ‰‹å†Œ"),
        BotCommand("kkfofa", "ğŸ” èµ„äº§æœç´¢/é¢„è®¾"), BotCommand("host", "ğŸ“¦ ä¸»æœºè¯¦æŸ¥"),
        BotCommand("stats", "ğŸ“Š å…¨å±€èšåˆç»Ÿè®¡"), BotCommand("batchfind", "ğŸ“‚ æ‰¹é‡ç‰¹å¾åˆ†æ"),
        BotCommand("settings", "âš™ï¸ è®¾ç½®èœå•"), BotCommand("history", "ğŸ•°ï¸ æŸ¥è¯¢å†å²"),
        BotCommand("import", "ğŸ–‡ï¸ å¯¼å…¥æ—§ç¼“å­˜"), BotCommand("backup", "ğŸ“¤ å¤‡ä»½é…ç½®"),
        BotCommand("restore", "ğŸ“¥ æ¢å¤é…ç½®"), BotCommand("update", "ğŸ”„ åœ¨çº¿æ›´æ–°è„šæœ¬"),
        BotCommand("getlog", "ğŸ“„ è·å–æ—¥å¿—"), BotCommand("shutdown", "ğŸ”Œ å…³é—­æœºå™¨äºº"),
        BotCommand("stop", "ğŸ›‘ åœæ­¢ä»»åŠ¡"), BotCommand("cancel", "âŒ å–æ¶ˆæ“ä½œ")
    ]
    try: updater.bot.set_my_commands(commands)
    except Exception as e: logger.warning(f"è®¾ç½®æœºå™¨äººå‘½ä»¤å¤±è´¥: {e}")

    settings_conv = ConversationHandler(
        entry_points=[CommandHandler("settings", settings_command)],
        states={
            STATE_SETTINGS_MAIN: [CallbackQueryHandler(settings_callback_handler, pattern=r"^settings_")],
            STATE_SETTINGS_ACTION: [CallbackQueryHandler(settings_action_handler, pattern=r"^action_")],
            STATE_GET_KEY: [MessageHandler(Filters.text & ~Filters.command, get_key)],
            STATE_GET_PROXY: [MessageHandler(Filters.text & ~Filters.command, get_proxy)],
            STATE_REMOVE_API: [MessageHandler(Filters.text & ~Filters.command, remove_api)],
            STATE_PRESET_MENU: [CallbackQueryHandler(preset_menu_callback, pattern=r"^preset_")],
            STATE_GET_PRESET_NAME: [MessageHandler(Filters.text & ~Filters.command, get_preset_name)],
            STATE_GET_PRESET_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_preset_query)],
            STATE_REMOVE_PRESET: [MessageHandler(Filters.text & ~Filters.command, remove_preset)],
            STATE_GET_UPDATE_URL: [MessageHandler(Filters.text & ~Filters.command, get_update_url)],
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300
    )
    kkfofa_conv = ConversationHandler(
        entry_points=[ CommandHandler("kkfofa", kkfofa_entry), CallbackQueryHandler(kkfofa_entry, pattern=r"^run_preset_") ],
        states={
            STATE_ASK_CONTINENT: [CallbackQueryHandler(ask_continent_callback, pattern=r"^continent_")],
            STATE_CONTINENT_CHOICE: [CallbackQueryHandler(continent_choice_callback, pattern=r"^continent_")],
            STATE_CACHE_CHOICE: [CallbackQueryHandler(cache_choice_callback, pattern=r"^cache_")],
            STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300
    )
    import_conv = ConversationHandler(entry_points=[CommandHandler("import", import_command)], states={STATE_GET_IMPORT_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_import_query)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    stats_conv = ConversationHandler(entry_points=[CommandHandler("stats", stats_command)], states={STATE_GET_STATS_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_fofa_stats_query)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300)
    
    batchfind_conv = ConversationHandler(
        entry_points=[CommandHandler("batchfind", batchfind_command)],
        states={
            STATE_GET_BATCH_FILE: [MessageHandler(Filters.document.mime_type("text/plain"), get_batch_file_handler)],
            STATE_SELECT_BATCH_FEATURES: [CallbackQueryHandler(select_batch_features_callback, pattern=r"^batchfeature_")]
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300
    )
    restore_conv = ConversationHandler(
        entry_points=[CommandHandler("restore", restore_config_command)],
        states={
            STATE_GET_RESTORE_FILE: [MessageHandler(Filters.document, receive_config_file)]
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300
    )

    dispatcher.add_handler(CommandHandler("start", start_command))
    dispatcher.add_handler(CommandHandler("help", help_command))
    dispatcher.add_handler(CommandHandler("host", host_command))
    dispatcher.add_handler(CommandHandler("stop", stop_all_tasks))
    dispatcher.add_handler(CommandHandler("backup", backup_config_command))
    dispatcher.add_handler(CommandHandler("history", history_command))
    dispatcher.add_handler(CommandHandler("getlog", get_log_command))
    dispatcher.add_handler(CommandHandler("shutdown", shutdown_command))
    dispatcher.add_handler(CommandHandler("update", update_script_command))
    dispatcher.add_handler(CallbackQueryHandler(liveness_check_callback, pattern=r'^liveness_'))
    dispatcher.add_handler(CallbackQueryHandler(subnet_scan_callback, pattern=r'^subnet_'))
    
    dispatcher.add_handler(settings_conv)
    dispatcher.add_handler(kkfofa_conv)
    dispatcher.add_handler(import_conv)
    dispatcher.add_handler(stats_conv)
    dispatcher.add_handler(batchfind_conv)
    dispatcher.add_handler(restore_conv)

    logger.info(f"ğŸš€ ç»ˆæç‰ˆæœºå™¨äººå·²å¯åŠ¨ (v8.6 - å…¼å®¹æ€§ä¸æŠ¥å‘Šä¼˜åŒ–)...")
    updater.start_polling()
    updater.idle()

if __name__ == "__main__":
    main()
