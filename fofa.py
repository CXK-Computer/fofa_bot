#
# fofa_final_complete_v5.py (æœ€ç»ˆå®Œæ•´ç‰ˆ for python-telegram-bot v13.x)
#
# æ–°å¢: 1. å¤§æ´²é€‰æ‹©åŠŸèƒ½: /kkfofa åå¯äº¤äº’å¼åœ°å°†æŸ¥è¯¢èŒƒå›´é™å®šåœ¨ç‰¹å®šå¤§æ´²ã€‚
# æ–°å¢: 2. /update å‘½ä»¤, å¯ä»æŒ‡å®šURLåœ¨çº¿æ›´æ–°è„šæœ¬å¹¶è‡ªåŠ¨é‡å¯ã€‚
# æ–°å¢: 3. /settings èœå•ä¸­å¢åŠ  "è„šæœ¬æ›´æ–°" é€‰é¡¹æ¥ç®¡ç†æ›´æ–°URLã€‚
# ä¿®å¤: 1. `RetryAfter` å¼‚å¸¸å¯¼è‡´æ·±åº¦è¿½æº¯ä»»åŠ¡å´©æºƒçš„é—®é¢˜ã€‚
# ä¿®å¤: 2. å¤§è§„æ¨¡å­ç½‘æ‰«ææ—¶å› ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰ç›®æ ‡å¯¼è‡´çš„å†…å­˜å’Œæ€§èƒ½é—®é¢˜ã€‚
#
import os
import sys
import json
import logging
import base64
import time
import re
import requests
import signal
import socket
import hashlib
from functools import wraps
from datetime import datetime, timedelta
from dateutil import tz
from concurrent.futures import ThreadPoolExecutor, as_completed

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand, ParseMode
from telegram.ext import (
    Updater,
    CommandHandler,
    CallbackContext,
    ConversationHandler,
    MessageHandler,
    CallbackQueryHandler,
    Filters,
)
from telegram.error import BadRequest, RetryAfter

# --- å…¨å±€å˜é‡å’Œå¸¸é‡ ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
LOG_FILE = 'fofa_bot.log'
MAX_HISTORY_SIZE = 50
CACHE_EXPIRATION_SECONDS = 24 * 60 * 60  # 24 hours
FOFA_SEARCH_URL = "https://fofa.info/api/v1/search/all"
FOFA_INFO_URL = "https://fofa.info/api/v1/info/my"
FOFA_STATS_URL = "https://fofa.info/api/v1/search/stats"
FOFA_HOST_BASE_URL = "https://fofa.info/api/v1/host/"
FOFA_STATS_FIELDS = "protocol,domain,port,title,os,server,country,asn,org,asset_type,fid,icp"
SCAN_TIMEOUT = 3
SCAN_CONCURRENCY = 100

# <--- æ–°å¢: å¤§æ´²ä¸å›½å®¶ä»£ç æ˜ å°„ ---
CONTINENT_COUNTRIES = {
    "Asia": ["AF", "AM", "AZ", "BH", "BD", "BT", "BN", "KH", "CN", "CY", "GE", "HK", "IN", "ID", "IR", "IQ", "IL", "JP", "JO", "KZ", "KW", "KG", "LA", "LB", "MO", "MY", "MV", "MN", "MM", "NP", "KP", "OM", "PK", "PS", "PH", "QA", "SA", "SG", "KR", "LK", "SY", "TW", "TJ", "TH", "TL", "TR", "TM", "AE", "UZ", "VN", "YE"],
    "Europe": ["AL", "AD", "AT", "BY", "BE", "BA", "BG", "HR", "CZ", "DK", "EE", "FO", "FI", "FR", "DE", "GI", "GR", "HU", "IS", "IE", "IT", "LV", "LI", "LT", "LU", "MK", "MT", "MD", "MC", "ME", "NL", "NO", "PL", "PT", "RO", "RU", "SM", "RS", "SK", "SI", "ES", "SE", "CH", "UA", "GB", "VA"],
    "NorthAmerica": ["AG", "BS", "BB", "BZ", "CA", "CR", "CU", "DM", "DO", "SV", "GD", "GT", "HT", "HN", "JM", "MX", "NI", "PA", "KN", "LC", "VC", "TT", "US"],
    "SouthAmerica": ["AR", "BO", "BR", "CL", "CO", "EC", "FK", "GY", "PY", "PE", "SR", "UY", "VE"],
    "Africa": ["DZ", "AO", "BJ", "BW", "BF", "BI", "CM", "CV", "CF", "TD", "KM", "CG", "CD", "CI", "DJ", "EG", "GQ", "ER", "ET", "GA", "GM", "GH", "GN", "GW", "KE", "LS", "LR", "LY", "MG", "MW", "ML", "MR", "MU", "YT", "MA", "MZ", "NA", "NE", "NG", "RE", "RW", "ST", "SN", "SC", "SL", "SO", "ZA", "SS", "SD", "SZ", "TZ", "TG", "TN", "UG", "EH", "ZM", "ZW"],
    "Oceania": ["AS", "AU", "FJ", "GU", "KI", "MH", "FM", "NR", "NZ", "PW", "PG", "WS", "SB", "TO", "TV", "VU"]
}

# --- æ—¥å¿—é…ç½® ---
if os.path.exists(LOG_FILE) and os.path.getsize(LOG_FILE) > (5 * 1024 * 1024):
    try: os.rename(LOG_FILE, LOG_FILE + '.old')
    except OSError as e: print(f"æ— æ³•è½®æ¢æ—¥å¿—æ–‡ä»¶: {e}")
logging.basicConfig(
    level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler(LOG_FILE, encoding='utf-8'), logging.StreamHandler()]
)
logging.getLogger("requests").setLevel(logging.WARNING); logging.getLogger("urllib3").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)


# --- ä¼šè¯çŠ¶æ€å®šä¹‰ ---
(
    STATE_SETTINGS_MAIN, STATE_SETTINGS_ACTION, STATE_GET_KEY, STATE_REMOVE_API, STATE_GET_PROXY,
    STATE_KKFOFA_MODE, STATE_CACHE_CHOICE, STATE_GET_IMPORT_QUERY, STATE_GET_STATS_QUERY,
    STATE_PRESET_MENU, STATE_GET_PRESET_NAME, STATE_GET_PRESET_QUERY, STATE_REMOVE_PRESET,
    STATE_GET_UPDATE_URL,
    STATE_ASK_CONTINENT, STATE_CONTINENT_CHOICE # <--- æ–°å¢çŠ¶æ€
) = range(16)

# --- é…ç½®ç®¡ç† & ç¼“å­˜ ---
def load_json_file(filename, default_content):
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4); return default_content
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            config = json.load(f)
            for key, value in default_content.items(): config.setdefault(key, value)
            return config
    except (json.JSONDecodeError, IOError):
        logger.error(f"{filename} æŸåï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®é‡å»ºã€‚");
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4); return default_content

def save_json_file(filename, data):
    with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=4, ensure_ascii=False)

DEFAULT_CONFIG = { "bot_token": "YOUR_BOT_TOKEN_HERE", "apis": [], "admins": [], "proxy": "", "full_mode": False, "public_mode": False, "presets": [], "update_url": "" }
CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
HISTORY = load_json_file(HISTORY_FILE, {"queries": []})

def save_config(): save_json_file(CONFIG_FILE, CONFIG)
def save_history(): save_json_file(HISTORY_FILE, HISTORY)
def add_or_update_query(query_text, cache_data=None):
    existing_query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if existing_query:
        HISTORY['queries'].remove(existing_query); existing_query['timestamp'] = datetime.now(tz.tzutc()).isoformat()
        if cache_data: existing_query['cache'] = cache_data
        HISTORY['queries'].insert(0, existing_query)
    else:
        new_query = {"query_text": query_text, "timestamp": datetime.now(tz.tzutc()).isoformat(), "cache": cache_data}
        HISTORY['queries'].insert(0, new_query)
    while len(HISTORY['queries']) > MAX_HISTORY_SIZE: HISTORY['queries'].pop()
    save_history()
def find_cached_query(query_text):
    query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if query and query.get('cache'): return query
    return None

# --- è¾…åŠ©å‡½æ•°ä¸è£…é¥°å™¨ ---
def generate_filename_from_query(query_text: str, prefix: str = "fofa") -> str:
    sanitized_query = re.sub(r'[^a-z0-9\-_]+', '_', query_text.lower()).strip('_')
    max_len = 100
    if len(sanitized_query) > max_len: sanitized_query = sanitized_query[:max_len].rsplit('_', 1)[0]
    timestamp = int(time.time()); return f"{prefix}_{sanitized_query}_{timestamp}.txt"
def get_proxies():
    if CONFIG.get("proxy"): return {"http": CONFIG["proxy"], "https": CONFIG["proxy"]}
    return None
def is_admin(user_id: int) -> bool: return user_id in CONFIG.get('admins', [])
def admin_only(func):
    @wraps(func)
    def wrapped(update: Update, context: CallbackContext, *args, **kwargs):
        if not is_admin(update.effective_user.id):
            message_text = "â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤ç®¡ç†æ“ä½œã€‚"
            if update.callback_query: update.callback_query.answer(message_text, show_alert=True)
            elif update.message: update.message.reply_text(message_text)
            return None
        return func(update, context, *args, **kwargs)
    return wrapped
def escape_markdown(text: str) -> str:
    if not isinstance(text, str): text = str(text)
    escape_chars = r'_*`['; return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)

# --- FOFA API æ ¸å¿ƒé€»è¾‘ (æ— å˜åŠ¨) ---
def _make_api_request(url, params, timeout=60, use_b64=True):
    try:
        if use_b64 and 'q' in params: params['qbase64'] = base64.b64encode(params.pop('q').encode('utf-8')).decode('utf-8')
        response = requests.get(url, params=params, timeout=timeout, proxies=get_proxies(), verify=False)
        response.raise_for_status(); data = response.json();
        if data.get("error"): return None, data.get("errmsg", "æœªçŸ¥çš„FOFAé”™è¯¯")
        return data, None
    except requests.exceptions.RequestException as e: return None, f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}"
    except json.JSONDecodeError: return None, "è§£æJSONå“åº”å¤±è´¥"
def verify_fofa_api(key): return _make_api_request(FOFA_INFO_URL, {'key': key}, timeout=15, use_b64=False)
def fetch_fofa_data(key, query, page=1, page_size=10000, fields="host"):
    params = {'key': key, 'q': query, 'size': page_size, 'page': page, 'fields': fields, 'full': CONFIG.get("full_mode", False)}; return _make_api_request(FOFA_SEARCH_URL, params)
def fetch_fofa_stats(key, query):
    params = {'key': key, 'q': query, 'fields': FOFA_STATS_FIELDS}; return _make_api_request(FOFA_STATS_URL, params)
def fetch_fofa_host_info(key, host, detail=False):
    url = FOFA_HOST_BASE_URL + host; params = {'key': key, 'detail': str(detail).lower()}; return _make_api_request(url, params, use_b64=False)
def execute_query_with_fallback(query_func, preferred_key_index=None):
    if not CONFIG['apis']: return None, None, "æ²¡æœ‰é…ç½®ä»»ä½•API Keyã€‚"
    keys_to_try = CONFIG['apis']; start_index = 0
    if preferred_key_index is not None and 1 <= preferred_key_index <= len(keys_to_try): start_index = preferred_key_index - 1
    for i in range(len(keys_to_try)):
        idx = (start_index + i) % len(keys_to_try); key = keys_to_try[idx]; key_num = idx + 1
        data, error = query_func(key)
        if not error: return data, key_num, None
        if "[820031]" in str(error): logger.warning(f"Key [#{key_num}] Fç‚¹ä½™é¢ä¸è¶³..."); continue
        return None, key_num, error
    return None, None, "æ‰€æœ‰Keyå‡å°è¯•å¤±è´¥ã€‚"

# --- /host & /stats å‘½ä»¤å¤„ç† (æ— å˜åŠ¨) ---
def format_host_summary(data):
    lines = [f"ğŸ“‹ *ä¸»æœºèšåˆæ¦‚è§ˆ: `{escape_markdown(data.get('host', 'N/A'))}`*"]
    lines.append(f"*IP:* `{escape_markdown(data.get('ip', 'N/A'))}`"); lines.append(f"*ASN:* `{data.get('asn', 'N/A')}`"); lines.append(f"*ç»„ç»‡:* `{escape_markdown(data.get('org', 'N/A'))}`"); lines.append(f"*å›½å®¶:* `{escape_markdown(data.get('country_name', 'N/A'))}`"); lines.append(f"*æ›´æ–°æ—¶é—´:* `{escape_markdown(data.get('update_time', 'N/A'))}`\n")
    def join_list(items): return ', '.join(map(str, items)) if items else "æ— "
    lines.append(f"*åè®®:* `{escape_markdown(join_list(data.get('protocol')))}`"); lines.append(f"*ç«¯å£:* `{join_list(data.get('port'))}`\n"); lines.append(f"*äº§å“:* `{escape_markdown(join_list(data.get('product')))}`"); lines.append(f"*åˆ†ç±»:* `{escape_markdown(join_list(data.get('category')))}`")
    return "\n".join(lines)
def format_host_details(data):
    lines = [f"ğŸ“‹ *ä¸»æœºç«¯å£è¯¦æƒ…: `{escape_markdown(data.get('host', 'N/A'))}`*"]; lines.append(f"*IP:* `{escape_markdown(data.get('ip', 'N/A'))}`"); lines.append(f"*ASN:* `{data.get('asn', 'N/A'))}`"); lines.append(f"*ç»„ç»‡:* `{escape_markdown(data.get('org', 'N/A'))}`"); lines.append(f"*å›½å®¶:* `{escape_markdown(data.get('country_name', 'N/A'))}`\n")
    ports_data = data.get('ports', [])
    if not ports_data: lines.append("_æœªå‘ç°å¼€æ”¾ç«¯å£çš„è¯¦ç»†ä¿¡æ¯ã€‚_"); return "\n".join(lines)
    for port_info in sorted(ports_data, key=lambda p: p.get('port', 0)):
        port = port_info.get('port'); protocol = port_info.get('protocol', 'æœªçŸ¥'); lines.append(f"--- *ç«¯å£: {port}* ({protocol}) ---")
        products = port_info.get('products')
        if products:
            for product in products: prod_name = escape_markdown(product.get('product', 'æœªçŸ¥äº§å“')); prod_cat = escape_markdown(product.get('category', 'æœªçŸ¥åˆ†ç±»')); lines.append(f"  - {prod_name} (`{prod_cat}`)")
        else: lines.append("  - _æ— è¯¦ç»†äº§å“ä¿¡æ¯_")
    return "\n".join(lines)
@admin_only
def host_command(update: Update, context: CallbackContext) -> None:
    if not context.args: update.message.reply_text("ç”¨æ³•: `/host <ip_or_domain> [detail]`\n\nç¤ºä¾‹:\n`/host 1.1.1.1`\n`/host example.com detail`", parse_mode=ParseMode.MARKDOWN); return
    host = context.args[0]; detail = len(context.args) > 1 and context.args[1].lower() == 'detail'
    processing_message = update.message.reply_text(f"æ­£åœ¨æŸ¥è¯¢ä¸»æœº `{host}` çš„èšåˆä¿¡æ¯...")
    data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_host_info(key, host, detail))
    if error: processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{error}`", parse_mode=ParseMode.MARKDOWN); return
    if detail: formatted_text = format_host_details(data)
    else: formatted_text = format_host_summary(data)
    processing_message.edit_text(formatted_text, parse_mode=ParseMode.MARKDOWN)
@admin_only
def get_fofa_stats_query(update: Update, context: CallbackContext) -> int:
    query_text = update.message.text; processing_message = update.message.reply_text("æ­£åœ¨æŸ¥è¯¢ FOFA èšåˆç»Ÿè®¡, è¯·ç¨å€™...")
    data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_stats(key, query_text))
    if error: processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{error}`", parse_mode=ParseMode.MARKDOWN); return ConversationHandler.END
    stats_data = data; aggs = stats_data.get("aggs", {})
    try: total_size_formatted = f"{stats_data.get('size', 0):,}"
    except (ValueError, TypeError): total_size_formatted = str(stats_data.get('size', 'N/A'))
    message_lines = [ f"*ğŸ“Š FOFA èšåˆç»Ÿè®¡ä¿¡æ¯*", f"*æŸ¥è¯¢:* `{escape_markdown(query_text)}`", f"*æ€»æ•°:* *{total_size_formatted}*", f"*æœ€åæ›´æ–°:* `{stats_data.get('lastupdatetime', 'N/A')}`", "" ]
    display_map = { "ğŸŒ Top 5 å›½å®¶/åœ°åŒº": "countries", "ğŸ¢ Top 5 ç»„ç»‡ (ORG)": "org", "ğŸ“› Top 5 ASN": "asn", "ğŸ–¥ï¸ Top 5 æœåŠ¡/ç»„ä»¶": "server", "ğŸ”Œ Top 5 åè®®": "protocol", "âš™ï¸ Top 5 æ“ä½œç³»ç»Ÿ": "os", "ğŸšª Top 5 ç«¯å£": "port", }
    for title, key in display_map.items():
        items = aggs.get(key)
        if items:
            message_lines.append(f"*{title}:*")
            for item in items[:5]:
                try: name = escape_markdown(item.get('name', 'N/A')); count_formatted = f"{item.get('count', 0):,}"
                except (ValueError, TypeError): name = str(item.get('name', 'N/A')); count_formatted = str(item.get('count', 0))
                message_lines.append(f"  - `{name}`: *{count_formatted}*")
            message_lines.append("")
    processing_message.edit_text("\n".join(message_lines), parse_mode=ParseMode.MARKDOWN); return ConversationHandler.END
@admin_only
def stats_command(update: Update, context: CallbackContext) -> int:
    update.message.reply_text("è¯·è¾“å…¥ä½ æƒ³è¦è¿›è¡Œèšåˆç»Ÿè®¡çš„ FOFA è¯­æ³•ã€‚\nä¾‹å¦‚: `app=\"nginx\"`\n\néšæ—¶å¯ä»¥å‘é€ /cancel æ¥å–æ¶ˆã€‚", parse_mode=ParseMode.MARKDOWN); return STATE_GET_STATS_QUERY

# --- åå°ä»»åŠ¡ä¸æ‰«æé€»è¾‘ (å·²åŒ…å«ä¹‹å‰çš„ä¿®å¤) ---
def offer_post_download_actions(context: CallbackContext, chat_id, query_text):
    query_hash = hashlib.md5(query_text.encode()).hexdigest()
    context.bot_data[query_hash] = query_text
    keyboard = [[ InlineKeyboardButton("âš¡ï¸ å­˜æ´»æ£€æµ‹", callback_data=f'liveness_{query_hash}'), InlineKeyboardButton("ğŸŒ å­ç½‘æ‰«æ(/24)", callback_data=f'subnet_{query_hash}') ]]
    context.bot.send_message(chat_id, "ä¸‹è½½å®Œæˆï¼Œéœ€è¦å¯¹ç»“æœè¿›è¡ŒäºŒæ¬¡æ‰«æå—ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard))
def download_and_process_file(context: CallbackContext, query_hash, prefix, processor_func, final_message_func):
    bot = context.bot; job_context = context.job.context; chat_id, msg = job_context['chat_id'], job_context['msg']
    original_query = context.bot_data.get(query_hash)
    if not original_query: msg.edit_text("âŒ æ‰«æä»»åŠ¡å·²è¿‡æœŸæˆ–æ— æ³•æ‰¾åˆ°åŸå§‹æŸ¥è¯¢ã€‚"); return
    cached_item = find_cached_query(original_query)
    if not cached_item: msg.edit_text("âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶çš„ç¼“å­˜è®°å½•ã€‚"); return
    msg.edit_text("1/3: æ­£åœ¨ä»TelegramæœåŠ¡å™¨ä¸‹è½½ç»“æœæ–‡ä»¶...")
    temp_path = f"temp_{cached_item['cache']['file_name']}"
    try: file = bot.get_file(cached_item['cache']['file_id']); file.download(custom_path=temp_path)
    except Exception as e: msg.edit_text(f"âŒ ä¸‹è½½ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    try: results = processor_func(temp_path, msg)
    finally:
        if os.path.exists(temp_path): os.remove(temp_path)
    if not results: msg.edit_text("ğŸ¤·â€â™€ï¸ æ‰«æå®Œæˆï¼Œä½†æœªå‘ç°ä»»ä½•å­˜æ´»çš„ç›®æ ‡ã€‚"); return
    msg.edit_text("3/3: æ­£åœ¨æ‰“åŒ…å¹¶å‘é€æ–°ç»“æœ...")
    output_filename = generate_filename_from_query(original_query, prefix=prefix)
    with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(results))))
    final_caption = final_message_func(len(results))
    with open(output_filename, 'rb') as doc: bot.send_document(chat_id, document=doc, caption=final_caption, parse_mode=ParseMode.MARKDOWN)
    os.remove(output_filename); msg.delete()
def process_liveness_check(file_path, msg):
    with open(file_path, 'r', encoding='utf-8') as f: targets = [line.strip() for line in f if line.strip()]
    live_results = set(); total = len(targets)
    msg.edit_text(f"2/3: å·²åŠ è½½ {total} ä¸ªç›®æ ‡ï¼Œå¼€å§‹å­˜æ´»æ£€æµ‹...")
    def check_port(target):
        try:
            ip, port_str = target.split(':'); port = int(port_str)
            with socket.create_connection((ip, port), timeout=SCAN_TIMEOUT) as sock: live_results.add(target)
        except (ValueError, socket.error): pass
    with ThreadPoolExecutor(max_workers=SCAN_CONCURRENCY) as executor: executor.map(check_port, targets)
    return live_results
def process_subnet_scan(file_path, msg):
    subnets_to_ports = {}
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                ip_str, port_str = line.strip().split(':'); port = int(port_str); subnet = ".".join(ip_str.split('.')[:3]) + ".0/24"
                if subnet not in subnets_to_ports: subnets_to_ports[subnet] = set()
                subnets_to_ports[subnet].add(port)
            except ValueError: continue
    if not subnets_to_ports: return set()
    total_targets = sum(len(ports) * 254 for ports in subnets_to_ports.values())
    if total_targets == 0: return set()
    msg.edit_text(f"2/3: åˆ†æå‡º {len(subnets_to_ports)} ä¸ª/24å­ç½‘ï¼Œå…±è®¡ {total_targets} ä¸ªæ‰«æç›®æ ‡ã€‚å¼€å§‹æ‰«æ...")
    live_results = set(); completed_count = 0; last_update_time = time.time()
    def check_port(ip, port):
        try:
            with socket.create_connection((ip, port), timeout=SCAN_TIMEOUT) as sock: return f"{ip}:{port}"
        except socket.error: return None
    with ThreadPoolExecutor(max_workers=SCAN_CONCURRENCY) as executor:
        futures = []
        for subnet, ports in subnets_to_ports.items():
            base_ip = subnet.split('/')[0].rsplit('.', 1)[0]
            for i in range(1, 255):
                for port in ports: futures.append(executor.submit(check_port, f"{base_ip}.{i}", port))
        for future in as_completed(futures):
            completed_count += 1; result = future.result()
            if result: live_results.add(result)
            current_time = time.time()
            if current_time - last_update_time > 2.5:
                progress = (completed_count / total_targets) * 100
                try:
                    msg.edit_text(f"2/3: æ‰«æè¿›åº¦: {progress:.1f}% ({completed_count}/{total_targets})\nå·²å‘ç°: {len(live_results)} ä¸ª")
                    last_update_time = current_time
                except (BadRequest, RetryAfter): pass
    return live_results
def run_liveness_check_job(context: CallbackContext):
    download_and_process_file(context, context.job.context['query_hash'], prefix="live", processor_func=process_liveness_check, final_message_func=lambda count: f"âœ… **å­˜æ´»æ£€æµ‹å®Œæˆ!**\n\nå…±å‘ç° *{count}* ä¸ªå­˜æ´»ç›®æ ‡ã€‚")
def run_subnet_scan_job(context: CallbackContext):
    download_and_process_file(context, context.job.context['query_hash'], prefix="subnet_scan", processor_func=process_subnet_scan, final_message_func=lambda count: f"âœ… **å­ç½‘æ‰«æå®Œæˆ!**\n\nåœ¨æ–°IPä¸­é¢å¤–å‘ç° *{count}* ä¸ªå­˜æ´»ç›®æ ‡ã€‚")
def start_job(update: Update, context: CallbackContext, job_name_prefix, callback_func, query_hash):
    chat_id = update.effective_chat.id; msg = update.effective_message.reply_text("â³ ä»»åŠ¡å·²æäº¤ï¼Œå‡†å¤‡å¼€å§‹...")
    job_context = {'chat_id': chat_id, 'msg': msg, 'query_hash': query_hash}
    context.job_queue.run_once(callback_func, 1, context=job_context, name=f"{job_name_prefix}_{chat_id}")
@admin_only
def liveness_check_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); query_hash = query.data.split('_', 1)[1]; start_job(update, context, "liveness", run_liveness_check_job, query_hash)
@admin_only
def subnet_scan_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); query_hash = query.data.split('_', 1)[1]; start_job(update, context, "subnet", run_subnet_scan_job, query_hash)
def start_download_job(context: CallbackContext, callback_func, job_data):
    chat_id = job_data['chat_id']; job_name = f"download_job_{chat_id}"
    for job in context.job_queue.get_jobs_by_name(job_name): job.schedule_removal()
    context.bot_data.pop(f'stop_job_{chat_id}', None)
    context.job_queue.run_once(callback_func, 1, context=job_data, name=job_name)
def run_full_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, query_text, total_size = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size']
    output_filename = generate_filename_from_query(query_text); unique_results, stop_flag = set(), f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡..."); pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(unique_results)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except (BadRequest, RetryAfter): pass
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page, 10000, "host"))
        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        results = data.get('results', []);
        if not results: break
        unique_results.update(res for res in results if ':' in res)
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(unique_results))
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚æ­£åœ¨å‘é€...")
        with open(output_filename, 'rb') as doc: sent_message = bot.send_document(chat_id, document=doc, filename=output_filename)
        os.remove(output_filename)
        cache_data = {'file_id': sent_message.document.file_id, 'file_name': output_filename, 'result_count': len(unique_results)}
        add_or_update_query(query_text, cache_data); offer_post_download_actions(context, chat_id, query_text)
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)
def run_traceback_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; output_filename = generate_filename_from_query(base_query)
    unique_results, page_count, last_page_date, termination_reason, stop_flag, last_update_time = set(), 0, None, "", f'stop_job_{chat_id}', 0
    msg = bot.send_message(chat_id, "â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query
    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, current_query, 1, 10000, "host,lastupdatetime"))
        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break
        original_count = len(unique_results); unique_results.update([r[0] for r in results if r and r[0] and ':' in r[0]]); newly_added_count = len(unique_results) - original_count
        current_time = time.time()
        if current_time - last_update_time > 2:
            try:
                msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
                last_update_time = current_time
            except RetryAfter as e:
                logger.warning(f"Telegram flood control triggered. Waiting for {e.retry_after} seconds.")
                time.sleep(e.retry_after)
            except BadRequest: pass
        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][1]: continue
            try:
                timestamp_str = results[i][1]; current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                last_page_date = current_date_obj; current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'; valid_anchor_found = True
                break
            except (ValueError, TypeError): continue
        if not valid_anchor_found: termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; break
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(unique_results))))
        msg.edit_text(f"âœ… æ·±åº¦è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨å‘é€æ–‡ä»¶...")
        with open(output_filename, 'rb') as doc: sent_message = bot.send_document(chat_id, document=doc, filename=output_filename)
        os.remove(output_filename)
        cache_data = {'file_id': sent_message.document.file_id, 'file_name': output_filename, 'result_count': len(unique_results)}
        add_or_update_query(base_query, cache_data); offer_post_download_actions(context, chat_id, base_query)
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)
def run_incremental_update_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; msg = bot.send_message(chat_id, "--- å¢é‡æ›´æ–°å¯åŠ¨ ---")
    msg.edit_text("1/5: æ­£åœ¨è·å–æ—§ç¼“å­˜..."); cached_item = find_cached_query(base_query)
    if not cached_item: msg.edit_text("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç¼“å­˜é¡¹ã€‚"); return
    old_file_path = f"old_{cached_item['cache']['file_name']}"; old_results = set()
    try:
        file = bot.get_file(cached_item['cache']['file_id']); file.download(old_file_path)
        with open(old_file_path, 'r', encoding='utf-8') as f: old_results = set(line.strip() for line in f if line.strip() and ':' in line)
    except BadRequest: msg.edit_text("âŒ **é”™è¯¯ï¼šç¼“å­˜æ–‡ä»¶å·²æ— æ³•ä¸‹è½½**\nè¯·é€‰æ‹© **ğŸ” å…¨æ–°æœç´¢**ã€‚", parse_mode=ParseMode.MARKDOWN); return
    except Exception as e: msg.edit_text(f"âŒ è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    msg.edit_text("2/5: æ­£åœ¨ç¡®å®šæ›´æ–°èµ·å§‹ç‚¹..."); data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, base_query, fields="lastupdatetime"))
    if error or not data.get('results'): msg.edit_text(f"âŒ æ— æ³•è·å–æœ€æ–°è®°å½•æ—¶é—´æˆ³: {error or 'æ— ç»“æœ'}"); os.remove(old_file_path); return
    ts_str = data['results'][0][0] if isinstance(data['results'][0], list) else data['results'][0]; cutoff_date = ts_str.split(' ')[0]
    incremental_query = f'({base_query}) && after="{cutoff_date}"'
    msg.edit_text(f"3/5: æ­£åœ¨ä¾¦å¯Ÿè‡ª {cutoff_date} ä»¥æ¥çš„æ–°æ•°æ®..."); data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page_size=1))
    if error: msg.edit_text(f"âŒ ä¾¦å¯ŸæŸ¥è¯¢å¤±è´¥: {error}"); os.remove(old_file_path); return
    total_new_size = data.get('size', 0)
    if total_new_size == 0: msg.edit_text("âœ… æœªå‘ç°æ–°æ•°æ®ã€‚ç¼“å­˜å·²æ˜¯æœ€æ–°ã€‚"); os.remove(old_file_path); return
    new_results, stop_flag = set(), f'stop_job_{chat_id}'; pages_to_fetch = (total_new_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ å¢é‡æ›´æ–°å·²æ‰‹åŠ¨åœæ­¢ã€‚"); os.remove(old_file_path); return
        msg.edit_text(f"3/5: æ­£åœ¨ä¸‹è½½æ–°æ•°æ®... ( Page {page}/{pages_to_fetch} )")
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page=page, page_size=10000))
        if error: msg.edit_text(f"âŒ ä¸‹è½½æ–°æ•°æ®å¤±è´¥: {error}"); os.remove(old_file_path); return
        if data.get('results'): new_results.update(res for res in data.get('results', []) if ':' in res)
    msg.edit_text(f"4/5: æ­£åœ¨åˆå¹¶æ•°æ®... (å‘ç° {len(new_results)} æ¡æ–°æ•°æ®)"); combined_results = sorted(list(new_results.union(old_results))); output_filename = generate_filename_from_query(base_query)
    with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(combined_results))
    msg.edit_text(f"5/5: å‘é€æ›´æ–°åçš„æ–‡ä»¶... (å…± {len(combined_results)} æ¡)")
    with open(output_filename, 'rb') as doc: sent_message = bot.send_document(chat_id, document=doc, filename=output_filename)
    cache_data = {'file_id': sent_message.document.file_id, 'file_name': output_filename, 'result_count': len(combined_results)}
    add_or_update_query(base_query, cache_data); os.remove(old_file_path); os.remove(output_filename)
    msg.delete(); bot.send_message(chat_id, f"âœ… å¢é‡æ›´æ–°å®Œæˆï¼"); offer_post_download_actions(context, chat_id, base_query)

# --- æ ¸å¿ƒå‘½ä»¤å¤„ç† ---
def start_command(update: Update, context: CallbackContext):
    update.message.reply_text('ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Fofa æŸ¥è¯¢æœºå™¨äººï¼è¯·ä½¿ç”¨ /help æŸ¥çœ‹å‘½ä»¤æ‰‹å†Œã€‚')
    if not CONFIG['admins']: first_admin_id = update.effective_user.id; CONFIG.setdefault('admins', []).append(first_admin_id); save_config(); update.message.reply_text(f"â„¹ï¸ å·²è‡ªåŠ¨å°†æ‚¨ (ID: `{first_admin_id}`) æ·»åŠ ä¸ºç¬¬ä¸€ä¸ªç®¡ç†å‘˜ã€‚")
def help_command(update: Update, context: CallbackContext):
    help_text = ( "ğŸ“– *Fofa æœºå™¨äººæŒ‡ä»¤æ‰‹å†Œ*\n\n"
                  "*ğŸ” èµ„äº§æŸ¥è¯¢*\n`/kkfofa [key] <query>` - FOFAæœç´¢\n_ä¸å¸¦å‚æ•°åˆ™æ˜¾ç¤ºé¢„è®¾èœå•_\n\n"
                  "*ğŸ“¦ ä¸»æœºèšåˆ*\n`/host <ip|domain> [detail]`\n_è·å–å•ä¸ªä¸»æœºçš„èšåˆä¿¡æ¯_\n\n"
                  "*ğŸ“Š èšåˆç»Ÿè®¡*\n`/stats <query>` - è·å–å…¨å±€èšåˆç»Ÿè®¡\n\n"
                  "*âš™ï¸ ç®¡ç†ä¸è®¾ç½®*\n`/settings` - è¿›å…¥äº¤äº’å¼è®¾ç½®èœå•\n\n"
                  "*ğŸ’¾ é«˜çº§åŠŸèƒ½*\n"
                  "`/backup` / `/restore` - å¤‡ä»½/æ¢å¤\n"
                  "`/history` - æŸ¥è¯¢å†å²\n"
                  "`/import` - å¯¼å…¥æ—§ç»“æœ\n\n"
                  "*ğŸ’» ç³»ç»Ÿç®¡ç†*\n"
                  "`/update` - åœ¨çº¿æ›´æ–°è„šæœ¬\n"
                  "`/getlog` - è·å–æ—¥å¿—\n"
                  "`/shutdown` - å®‰å…¨å…³é—­æœºå™¨äºº\n\n"
                  "*ğŸ›‘ ä»»åŠ¡æ§åˆ¶*\n`/stop` - ç´§æ€¥åœæ­¢ä¸‹è½½ä»»åŠ¡\n`/cancel` - å–æ¶ˆå½“å‰æ“ä½œ" )
    update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

# --- /kkfofa æŸ¥è¯¢æµç¨‹ (å«å¤§æ´²é€‰æ‹©) ---
def start_new_search(update: Update, context: CallbackContext, message_to_edit=None):
    query_text = context.user_data['query']; key_index = context.user_data.get('key_index'); add_or_update_query(query_text)
    msg = message_to_edit if message_to_edit else update.effective_message.reply_text("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    if message_to_edit: msg.edit_text("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    data, used_key_index, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page_size=1, fields="host"), key_index)
    if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
    total_size = data.get('size', 0)
    if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
    context.user_data.update({'total_size': total_size, 'chat_id': update.effective_chat.id})
    success_message = f"âœ… ä½¿ç”¨ Key [#{used_key_index}] æ‰¾åˆ° {total_size} æ¡ç»“æœã€‚"
    if total_size <= 10000:
        msg.edit_text(f"{success_message}\nå¼€å§‹ä¸‹è½½..."); start_download_job(context, run_full_download_query, context.user_data)
        return ConversationHandler.END
    else:
        keyboard = [[InlineKeyboardButton("ğŸ’ å…¨éƒ¨ä¸‹è½½ (å‰1ä¸‡)", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯ä¸‹è½½", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
        msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard)); return STATE_KKFOFA_MODE

def proceed_with_query(update: Update, context: CallbackContext, message_to_edit):
    query_text = context.user_data['query']
    cached_item = find_cached_query(query_text)
    if cached_item:
        dt_utc = datetime.fromisoformat(cached_item['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        message_text = (f"âœ… *å‘ç°ç¼“å­˜*\n\næŸ¥è¯¢: `{escape_markdown(query_text)}`\nç¼“å­˜äº: *{time_str}*\n\n")
        keyboard = []; is_expired = (datetime.now(tz.tzutc()) - dt_utc).total_seconds() > CACHE_EXPIRATION_SECONDS
        if is_expired: message_text += "âš ï¸ *æ­¤ç¼“å­˜å·²è¿‡æœŸï¼Œæ— æ³•å¢é‡æ›´æ–°ã€‚*"; keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½æ—§ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        else: message_text += "è¯·é€‰æ‹©æ“ä½œï¼š"; keyboard.append([InlineKeyboardButton("ğŸ”„ å¢é‡æ›´æ–°", callback_data='cache_incremental')]); keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        keyboard.append([InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='cache_cancel')])
        message_to_edit.edit_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
        return STATE_CACHE_CHOICE
    return start_new_search(update, context, message_to_edit=message_to_edit)

def kkfofa_entry(update: Update, context: CallbackContext):
    if update.callback_query:
        try:
            query = update.callback_query; query.answer(); preset_index = int(query.data.replace("run_preset_", "")); preset = CONFIG["presets"][preset_index]
            context.user_data.update({'query': preset['query'], 'key_index': None, 'chat_id': update.effective_chat.id})
            return start_new_search(update, context, message_to_edit=query.message)
        except (ValueError, IndexError): query.edit_message_text("âŒ é¢„è®¾æŸ¥è¯¢å¤±è´¥ã€‚"); return ConversationHandler.END
    if not context.args:
        presets = CONFIG.get("presets", [])
        if not presets: update.message.reply_text("æ¬¢è¿ä½¿ç”¨FOFAæŸ¥è¯¢æœºå™¨äººã€‚\n\nâ¡ï¸ ç›´æ¥è¾“å…¥æŸ¥è¯¢è¯­æ³•: `/kkfofa domain=\"example.com\"`\nâ„¹ï¸ å½“å‰æ²¡æœ‰å¯ç”¨çš„é¢„è®¾æŸ¥è¯¢ã€‚ç®¡ç†å‘˜å¯é€šè¿‡ /settings æ·»åŠ ã€‚"); return ConversationHandler.END
        keyboard = [[InlineKeyboardButton(p['name'], callback_data=f"run_preset_{i}")] for i, p in enumerate(presets)]; update.message.reply_text("ğŸ‘‡ è¯·é€‰æ‹©ä¸€ä¸ªé¢„è®¾æŸ¥è¯¢:", reply_markup=InlineKeyboardMarkup(keyboard)); return ConversationHandler.END
    
    key_index, query_text = None, " ".join(context.args)
    if context.args[0].isdigit():
        try:
            num = int(context.args[0])
            if 1 <= num <= len(CONFIG['apis']): key_index = num; query_text = " ".join(context.args[1:])
        except ValueError: pass
    
    context.user_data['original_query'] = query_text
    context.user_data['key_index'] = key_index
    
    keyboard = [[
        InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"),
        InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")
    ]]
    update.message.reply_text(
        f"æŸ¥è¯¢: `{escape_markdown(query_text)}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ",
        reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN
    )
    return STATE_ASK_CONTINENT

def ask_continent_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer()
    choice = query.data.split('_')[1]

    if choice == 'skip':
        context.user_data['query'] = context.user_data['original_query']
        query.edit_message_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown(context.user_data['query'])}`", parse_mode=ParseMode.MARKDOWN)
        return proceed_with_query(update, context, message_to_edit=query.message)
    elif choice == 'select':
        keyboard = [
            [InlineKeyboardButton("ğŸŒ äºšæ´²", callback_data="continent_Asia"), InlineKeyboardButton("ğŸŒ æ¬§æ´²", callback_data="continent_Europe")],
            [InlineKeyboardButton("ğŸŒ åŒ—ç¾æ´²", callback_data="continent_NorthAmerica"), InlineKeyboardButton("ğŸŒ å—ç¾æ´²", callback_data="continent_SouthAmerica")],
            [InlineKeyboardButton("ğŸŒ éæ´²", callback_data="continent_Africa"), InlineKeyboardButton("ğŸŒ å¤§æ´‹æ´²", callback_data="continent_Oceania")],
            [InlineKeyboardButton("â†©ï¸ è·³è¿‡", callback_data="continent_skip")]
        ]
        query.edit_message_text("è¯·é€‰æ‹©ä¸€ä¸ªå¤§æ´²:", reply_markup=InlineKeyboardMarkup(keyboard))
        return STATE_CONTINENT_CHOICE

def continent_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer()
    continent = query.data.split('_', 1)[1]
    original_query = context.user_data['original_query']

    if continent == 'skip':
        context.user_data['query'] = original_query
        query.edit_message_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown(original_query)}`", parse_mode=ParseMode.MARKDOWN)
        return proceed_with_query(update, context, message_to_edit=query.message)

    country_list = CONTINENT_COUNTRIES.get(continent)
    if not country_list:
        query.edit_message_text("âŒ é”™è¯¯ï¼šæ— æ•ˆçš„å¤§æ´²é€‰é¡¹ã€‚"); return ConversationHandler.END

    country_fofa_string = " || ".join([f'country="{code}"' for code in country_list])
    final_query = f"({original_query}) && ({country_fofa_string})"
    context.user_data['query'] = final_query
    
    query.edit_message_text(f"æŸ¥è¯¢å·²æ„å»º:\n`{escape_markdown(final_query)}`\n\næ­£åœ¨å¤„ç†...", parse_mode=ParseMode.MARKDOWN)
    return proceed_with_query(update, context, message_to_edit=query.message)

def cache_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    if choice == 'download':
        cached_item = find_cached_query(context.user_data['query'])
        if cached_item:
            query.edit_message_text("â¬‡ï¸ æ­£åœ¨ä»ç¼“å­˜å‘é€æ–‡ä»¶...");
            try: context.bot.send_document(chat_id=update.effective_chat.id, document=cached_item['cache']['file_id']); query.delete_message()
            except BadRequest as e: query.edit_message_text(f"âŒ å‘é€ç¼“å­˜å¤±è´¥: {e}")
        else: query.edit_message_text("âŒ æ‰¾ä¸åˆ°ç¼“å­˜è®°å½•ã€‚")
        return ConversationHandler.END
    elif choice == 'newsearch': return start_new_search(update, context, message_to_edit=query.message)
    elif choice == 'incremental': query.edit_message_text("â³ å‡†å¤‡å¢é‡æ›´æ–°..."); start_download_job(context, run_incremental_update_query, context.user_data); query.delete_message(); return ConversationHandler.END
    elif choice == 'cancel': query.edit_message_text("æ“ä½œå·²å–æ¶ˆã€‚"); return ConversationHandler.END
def query_mode_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); mode = query.data.split('_')[1]
    if mode == 'full': query.edit_message_text(f"â³ å¼€å§‹å…¨é‡ä¸‹è½½..."); start_download_job(context, run_full_download_query, context.user_data); query.delete_message()
    elif mode == 'traceback': query.edit_message_text(f"â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½..."); start_download_job(context, run_traceback_download_query, context.user_data); query.delete_message()
    elif mode == 'cancel': query.edit_message_text("æ“ä½œå·²å–æ¶ˆã€‚")
    return ConversationHandler.END

# --- å…¶ä»–ç®¡ç†å‘½ä»¤ (æ— å˜åŠ¨) ---
@admin_only
def stop_all_tasks(update: Update, context: CallbackContext): context.bot_data[f'stop_job_{update.effective_chat.id}'] = True; update.message.reply_text("âœ… å·²å‘é€åœæ­¢ä¿¡å·ã€‚")
@admin_only
def backup_config_command(update: Update, context: CallbackContext):
    if os.path.exists(CONFIG_FILE): update.effective_chat.send_document(document=open(CONFIG_FILE, 'rb'))
    else: update.effective_chat.send_message("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ã€‚")
@admin_only
def restore_config_command(update: Update, context: CallbackContext): update.message.reply_text("ğŸ“¥ è¦æ¢å¤é…ç½®ï¼Œè¯·ç›´æ¥å°†æ‚¨çš„ `config.json` æ–‡ä»¶ä½œä¸ºæ–‡æ¡£å‘é€ç»™æˆ‘ã€‚")
@admin_only
def receive_config_file(update: Update, context: CallbackContext):
    global CONFIG;
    if update.message.document.file_name != CONFIG_FILE: update.message.reply_text(f"âŒ æ–‡ä»¶åé”™è¯¯ï¼Œå¿…é¡»ä¸º `{CONFIG_FILE}`ã€‚"); return
    try:
        file = update.message.document.get_file(); temp_path = f"{CONFIG_FILE}.tmp"; file.download(temp_path)
        with open(temp_path, 'r', encoding='utf-8') as f: json.load(f)
        os.replace(temp_path, CONFIG_FILE); CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG); update.message.reply_text("âœ… é…ç½®å·²æˆåŠŸæ¢å¤ï¼æœºå™¨äººåŠŸèƒ½å¯èƒ½éœ€è¦é‡å¯åå®Œå…¨ç”Ÿæ•ˆã€‚")
    except Exception as e:
        logger.error(f"æ¢å¤é…ç½®å¤±è´¥: {e}"); update.message.reply_text(f"âŒ æ¢å¤å¤±è´¥: {e}")
        if os.path.exists(temp_path): os.remove(temp_path)
@admin_only
def history_command(update: Update, context: CallbackContext):
    if not HISTORY['queries']: update.message.reply_text("ğŸ•°ï¸ æš‚æ— å†å²è®°å½•ã€‚"); return
    message_text = "ğŸ•°ï¸ *æœ€è¿‘10æ¡æŸ¥è¯¢è®°å½•:*\n\n"
    for i, query_hist in enumerate(HISTORY['queries'][:10]):
        dt_utc = datetime.fromisoformat(query_hist['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M'); cache_icon = "âœ…" if query_hist.get('cache') else "âŒ"
        message_text += f"`{i+1}.` {escape_markdown(query_hist['query_text'])}\n_{time_str}_  (ç¼“å­˜: {cache_icon})\n\n"
    update.message.reply_text(message_text, parse_mode=ParseMode.MARKDOWN)
@admin_only
def import_command(update: Update, context: CallbackContext):
    if not update.message.reply_to_message or not update.message.reply_to_message.document: update.message.reply_text("âŒ *ç”¨æ³•é”™è¯¯*\nè¯·*å›å¤ (Reply)*ä¸€ä¸ªæ‚¨æƒ³å¯¼å…¥çš„`.txt`æ–‡ä»¶ï¼Œå†è¾“å…¥æ­¤å‘½ä»¤ã€‚", parse_mode=ParseMode.MARKDOWN); return
    context.user_data['import_doc'] = update.message.reply_to_message.document; update.message.reply_text("å¥½çš„ï¼Œå·²æ”¶åˆ°æ–‡ä»¶ã€‚\nç°åœ¨è¯·è¾“å…¥ä¸æ­¤æ–‡ä»¶å…³è”çš„ *FOFA æŸ¥è¯¢è¯­å¥*ï¼š", parse_mode=ParseMode.MARKDOWN); return STATE_GET_IMPORT_QUERY
def get_import_query(update: Update, context: CallbackContext):
    doc = context.user_data.get('import_doc'); query_text = update.message.text.strip()
    if not doc or not query_text: update.message.reply_text("âŒ æ“ä½œå·²è¿‡æ—¶æˆ–æŸ¥è¯¢ä¸ºç©ºã€‚"); return ConversationHandler.END
    cache_data = {'file_id': doc.file_id, 'file_name': doc.file_name, 'result_count': -1}; msg = update.message.reply_text("æ­£åœ¨ç»Ÿè®¡æ–‡ä»¶è¡Œæ•°...")
    try:
        temp_path = f"import_{doc.file_name}"; file = doc.get_file(); file.download(temp_path)
        with open(temp_path, 'r', encoding='utf-8') as f: counted_lines = sum(1 for line in f if line.strip())
        cache_data['result_count'] = counted_lines; os.remove(temp_path); msg.edit_text(f"âœ… *å¯¼å…¥æˆåŠŸï¼*\n\næŸ¥è¯¢ `{escape_markdown(query_text)}` å·²æˆåŠŸå…³è” *{counted_lines}* æ¡ç»“æœçš„ç¼“å­˜ã€‚", parse_mode=ParseMode.MARKDOWN)
    except Exception as e: logger.warning(f"æ— æ³•ä¸‹è½½æˆ–ç»Ÿè®¡å¯¼å…¥æ–‡ä»¶: {e}ï¼Œå°†ä½œä¸ºå¤§æ–‡ä»¶æ¨¡å¼å¯¼å…¥ã€‚"); msg.edit_text(f"âœ… *å¯¼å…¥æˆåŠŸ (å¤§æ–‡ä»¶æ¨¡å¼)ï¼*\n\næŸ¥è¯¢ `{escape_markdown(query_text)}` å·²æˆåŠŸå…³è”ç¼“å­˜ï¼ˆç»“æœæ•°æœªçŸ¥ï¼‰ã€‚", parse_mode=ParseMode.MARKDOWN)
    add_or_update_query(query_text, cache_data); context.user_data.clear(); return ConversationHandler.END
@admin_only
def get_log_command(update: Update, context: CallbackContext):
    if os.path.exists(LOG_FILE): update.message.reply_document(document=open(LOG_FILE, 'rb'))
    else: update.message.reply_text("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚")
@admin_only
def shutdown_command(update: Update, context: CallbackContext):
    update.message.reply_text("âœ… æ”¶åˆ°æŒ‡ä»¤ï¼æœºå™¨äººæ­£åœ¨å¹³ç¨³å…³é—­..."); logger.info(f"æ¥æ”¶åˆ°æ¥è‡ªç”¨æˆ· {update.effective_user.id} çš„å…³é—­æŒ‡ä»¤ã€‚")
    context.job_queue.run_once(lambda _: os.kill(os.getpid(), signal.SIGINT), 1)
@admin_only
def update_script_command(update: Update, context: CallbackContext, from_menu=False):
    url = CONFIG.get("update_url")
    if not url:
        msg_target = update.callback_query.message if from_menu else update.message
        msg_target.reply_text("âŒ æœªåœ¨é…ç½®ä¸­è®¾ç½®æ›´æ–°URLã€‚\nè¯·åœ¨ /settings -> è„šæœ¬æ›´æ–° ä¸­è®¾ç½®ã€‚")
        return
    msg = update.callback_query.message if from_menu else update.message.reply_text("â³ æ­£åœ¨ä»é…ç½®çš„URLæ£€æŸ¥æ›´æ–°...")
    if from_menu: msg.edit_text("â³ æ­£åœ¨ä»é…ç½®çš„URLæ£€æŸ¥æ›´æ–°...")
    try:
        response = requests.get(url, timeout=30, proxies=get_proxies()); response.raise_for_status()
        new_script_content = response.text
    except requests.exceptions.RequestException as e: msg.edit_text(f"âŒ ä¸‹è½½æ›´æ–°å¤±è´¥: {e}"); return
    if 'if __name__ == "__main__":' not in new_script_content or 'Updater(token=bot_token' not in new_script_content:
        msg.edit_text("âŒ ä¸‹è½½çš„æ–‡ä»¶ä¼¼ä¹ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æœºå™¨äººè„šæœ¬ï¼Œå·²ä¸­æ­¢æ›´æ–°ã€‚"); return
    script_path = os.path.abspath(sys.argv[0]); temp_path = script_path + ".new"
    try:
        with open(temp_path, 'w', encoding='utf-8') as f: f.write(new_script_content)
    except IOError as e: msg.edit_text(f"âŒ æ— æ³•å†™å…¥ä¸´æ—¶æ–‡ä»¶: {e}"); return
    try: os.replace(temp_path, script_path)
    except OSError as e:
        msg.edit_text(f"âŒ æ›¿æ¢è„šæœ¬æ–‡ä»¶å¤±è´¥: {e}")
        if os.path.exists(temp_path): os.remove(temp_path)
        return
    msg.edit_text("âœ… æ›´æ–°æˆåŠŸï¼æœºå™¨äººå°†åœ¨2ç§’åé‡å¯ä»¥åº”ç”¨æ–°ç‰ˆæœ¬...")
    logger.info(f"è„šæœ¬å·²ç”±ç”¨æˆ· {update.effective_user.id} æ›´æ–°ã€‚æ­£åœ¨é‡å¯...")
    def restart(context: CallbackContext): os.execv(sys.executable, [sys.executable] + sys.argv)
    context.job_queue.run_once(restart, 2)

# --- è®¾ç½®èœå• (Settings Conversation) (æ— å˜åŠ¨) ---
@admin_only
def settings_command(update: Update, context: CallbackContext):
    keyboard = [
        [InlineKeyboardButton("ğŸ”‘ API ç®¡ç†", callback_data='settings_api')],
        [InlineKeyboardButton("âœ¨ é¢„è®¾ç®¡ç†", callback_data='settings_preset')],
        [InlineKeyboardButton("ğŸŒ ä»£ç†è®¾ç½®", callback_data='settings_proxy')],
        [InlineKeyboardButton("ğŸ’¾ å¤‡ä»½ä¸æ¢å¤", callback_data='settings_backup')],
        [InlineKeyboardButton("ğŸ”„ è„šæœ¬æ›´æ–°", callback_data='settings_update')],
        [InlineKeyboardButton("âŒ å…³é—­èœå•", callback_data='settings_close')]
    ]
    message_text = "âš™ï¸ *è®¾ç½®èœå•*"; reply_markup = InlineKeyboardMarkup(keyboard)
    if update.callback_query: update.callback_query.edit_message_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    else: update.message.reply_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_MAIN
def settings_callback_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); menu = query.data.split('_', 1)[1]
    if menu == 'api': return show_api_menu(update, context)
    if menu == 'proxy': return show_proxy_menu(update, context)
    if menu == 'backup': return show_backup_restore_menu(update, context)
    if menu == 'preset': return show_preset_menu(update, context)
    if menu == 'update': return show_update_menu(update, context)
    if menu == 'close': query.edit_message_text("èœå•å·²å…³é—­."); return ConversationHandler.END
    return STATE_SETTINGS_ACTION
def show_api_menu(update: Update, context: CallbackContext):
    msg = update.callback_query.message
    msg.edit_text("ğŸ”„ æ­£åœ¨æŸ¥è¯¢API KeyçŠ¶æ€...")
    api_details = []
    for i, key in enumerate(CONFIG['apis']):
        data, error = verify_fofa_api(key)
        key_masked = f"`...{key[-4:]}`"
        if error: status = f"âŒ *æ— æ•ˆ*: {error}"
        else:
            username = escape_markdown(data.get('username', 'N/A')); vip_level = data.get('vip_level', 0)
            vip_status = f"ğŸ‘‘ VIP L{vip_level}" if data.get('is_vip') else "ğŸ‘¤ æ™®é€š"
            f_points = data.get('fofa_point', 0); free_points = data.get('remain_free_point', 0)
            status = f"{vip_status} ({username}) | Fç‚¹: *{f_points}*, å…è´¹ç‚¹: *{free_points}*"
        api_details.append(f"`#{i+1}` {key_masked}\n  {status}")
    api_message = "\n\n".join(api_details) if api_details else "_æ— _"
    keyboard = [[InlineKeyboardButton(f"æŸ¥è¯¢èŒƒå›´: {'âœ… å®Œæ•´å†å²' if CONFIG.get('full_mode') else 'â³ è¿‘ä¸€å¹´'}", callback_data='action_toggle_full')], [InlineKeyboardButton("â• æ·»åŠ Key", callback_data='action_add_api'), InlineKeyboardButton("â– åˆ é™¤Key", callback_data='action_remove_api')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back_main')]]
    msg.edit_text(f"ğŸ”‘ *API ç®¡ç†*\n\n{api_message}", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_ACTION
def show_proxy_menu(update: Update, context: CallbackContext):
    keyboard = [[InlineKeyboardButton("âœï¸ è®¾ç½®/æ›´æ–°", callback_data='action_set_proxy')], [InlineKeyboardButton("ğŸ—‘ï¸ æ¸…é™¤", callback_data='action_delete_proxy')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back_main')]]
    update.callback_query.edit_message_text(f"ğŸŒ *ä»£ç†è®¾ç½®*\nå½“å‰: `{CONFIG.get('proxy') or 'æœªè®¾ç½®'}`", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN); return STATE_SETTINGS_ACTION
def show_backup_restore_menu(update: Update, context: CallbackContext):
    message_text = ("ğŸ’¾ *å¤‡ä»½ä¸æ¢å¤*\n\nğŸ“¤ *å¤‡ä»½*\nç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œæˆ–ä½¿ç”¨ /backup å‘½ä»¤ã€‚\n\nğŸ“¥ *æ¢å¤*\nç›´æ¥å‘æœºå™¨äºº*å‘é€* `config.json` æ–‡ä»¶å³å¯ã€‚"); keyboard = [[InlineKeyboardButton("ğŸ“¤ ç«‹å³å¤‡ä»½", callback_data='action_backup_now')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back_main')]]
    update.callback_query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN); return STATE_SETTINGS_ACTION
def show_update_menu(update: Update, context: CallbackContext):
    current_url = CONFIG.get("update_url") or "æœªè®¾ç½®"
    message_text = f"ğŸ”„ *è„šæœ¬æ›´æ–°*\n\næ­¤åŠŸèƒ½å…è®¸æœºå™¨äººä»æŒ‡å®šçš„URLä¸‹è½½æœ€æ–°è„šæœ¬å¹¶è‡ªåŠ¨é‡å¯ã€‚\n\n*å½“å‰æ›´æ–°æº URL:*\n`{escape_markdown(current_url)}`"
    keyboard = [
        [InlineKeyboardButton("âœï¸ è®¾ç½®/æ›´æ–° URL", callback_data='action_set_update_url')],
        [InlineKeyboardButton("ğŸš€ ç«‹å³æ›´æ–°", callback_data='action_run_update')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back_main')]
    ]
    update.callback_query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_ACTION
def settings_action_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back_main': return settings_command(update, context)
    elif action == 'toggle_full': CONFIG["full_mode"] = not CONFIG.get("full_mode", False); save_config(); return show_api_menu(update, context)
    elif action == 'add_api': query.edit_message_text("è¯·å‘é€æ‚¨çš„ Fofa API Keyã€‚"); return STATE_GET_KEY
    elif action == 'remove_api': query.edit_message_text("è¯·è¾“å…¥è¦åˆ é™¤çš„API Keyç¼–å·(#)ã€‚"); return STATE_REMOVE_API
    elif action == 'set_proxy': query.edit_message_text("è¯·è¾“å…¥ä»£ç†åœ°å€ (ä¾‹å¦‚ http://127.0.0.1:7890)ã€‚"); return STATE_GET_PROXY
    elif action == 'delete_proxy': CONFIG['proxy'] = ""; save_config(); query.answer("ä»£ç†å·²æ¸…é™¤"); return show_proxy_menu(update, context)
    elif action == 'backup_now': backup_config_command(update, context); return STATE_SETTINGS_ACTION
    elif action == 'set_update_url': query.edit_message_text("è¯·å‘é€æ–°çš„è„šæœ¬æ›´æ–°URL (å¿…é¡»æ˜¯å¯ç›´æ¥è®¿é—®çš„ raw æ–‡ä»¶é“¾æ¥)ã€‚"); return STATE_GET_UPDATE_URL
    elif action == 'run_update': update_script_command(query, context, from_menu=True); return ConversationHandler.END
    return STATE_SETTINGS_ACTION
def get_key(update: Update, context: CallbackContext):
    key = update.message.text.strip(); msg = update.message.reply_text("æ­£åœ¨éªŒè¯...")
    data, error = verify_fofa_api(key)
    if not error: CONFIG['apis'].append(key); save_config(); msg.edit_text(f"âœ… æ·»åŠ æˆåŠŸï¼")
    else: msg.edit_text(f"âŒ éªŒè¯å¤±è´¥: {error}")
    return settings_command(update, context)
def get_proxy(update: Update, context: CallbackContext):
    CONFIG['proxy'] = update.message.text.strip(); save_config(); update.message.reply_text(f"âœ… ä»£ç†å·²æ›´æ–°ã€‚"); return settings_command(update, context)
def remove_api(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['apis']): CONFIG['apis'].pop(index); save_config(); update.message.reply_text(f"âœ… Keyå·²åˆ é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆç¼–å·ã€‚")
    except (ValueError, IndexError): update.message.reply_text("âŒ è¯·è¾“å…¥æ•°å­—ã€‚")
    return settings_command(update, context)
def get_update_url(update: Update, context: CallbackContext):
    url = update.message.text.strip()
    if url.startswith("http://") or url.startswith("https://"):
        CONFIG['update_url'] = url; save_config(); update.message.reply_text("âœ… æ›´æ–°URLå·²è®¾ç½®ã€‚")
    else: update.message.reply_text("âŒ URLæ ¼å¼æ— æ•ˆï¼Œè¯·è¾“å…¥ä»¥ http:// æˆ– https:// å¼€å¤´çš„é“¾æ¥ã€‚")
    return settings_command(update, context)
def show_preset_menu(update: Update, context: CallbackContext):
    preset_list = "\n".join([f"`#{i+1}`: `{p['name']}`" for i, p in enumerate(CONFIG['presets'])]) or "_æ— _"
    text = f"âœ¨ *é¢„è®¾ç®¡ç†*\n\n{preset_list}"; kbd = [[InlineKeyboardButton("â• æ·»åŠ ", callback_data='preset_add'), InlineKeyboardButton("â– ç§»é™¤", callback_data='preset_remove')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='preset_back')]]
    update.callback_query.edit_message_text(text, reply_markup=InlineKeyboardMarkup(kbd), parse_mode=ParseMode.MARKDOWN); return STATE_PRESET_MENU
def preset_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back': return settings_command(update, context)
    if action == 'add': query.edit_message_text("è¯·è¾“å…¥é¢„è®¾çš„åç§° (ä¾‹å¦‚: æµ·åº·å¨è§†æ‘„åƒå¤´):"); return STATE_GET_PRESET_NAME
    if action == 'remove': query.edit_message_text("è¯·è¾“å…¥è¦ç§»é™¤çš„é¢„è®¾çš„ç¼–å·(#):"); return STATE_REMOVE_PRESET
    return STATE_PRESET_MENU
def get_preset_name(update: Update, context: CallbackContext):
    context.user_data['preset_name'] = update.message.text.strip(); update.message.reply_text(f"åç§°: `{context.user_data['preset_name']}`\n\nç°åœ¨è¯·è¾“å…¥å®Œæ•´çš„FOFAæŸ¥è¯¢è¯­æ³•:"); return STATE_GET_PRESET_QUERY
def get_preset_query(update: Update, context: CallbackContext):
    new_preset = {"name": context.user_data['preset_name'], "query": update.message.text.strip()}; CONFIG['presets'].append(new_preset); save_config()
    update.message.reply_text("âœ… é¢„è®¾æ·»åŠ æˆåŠŸï¼"); context.user_data.clear(); return settings_command(update, context)
def remove_preset(update: Update, context: CallbackContext):
    try:
        idx = int(update.message.text.strip()) - 1
        if 0 <= idx < len(CONFIG['presets']): CONFIG['presets'].pop(idx); save_config(); update.message.reply_text("âœ… é¢„è®¾å·²ç§»é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def cancel(update: Update, context: CallbackContext):
    if update.callback_query: update.callback_query.edit_message_text('æ“ä½œå·²å–æ¶ˆã€‚')
    elif update.message: update.message.reply_text('æ“ä½œå·²å–æ¶ˆã€‚')
    context.user_data.clear(); return ConversationHandler.END

# --- ä¸»å‡½æ•°ä¸è°ƒåº¦å™¨ ---
def main() -> None:
    bot_token = CONFIG.get("bot_token")
    if not bot_token or bot_token == "YOUR_BOT_TOKEN_HERE":
        logger.critical("ä¸¥é‡é”™è¯¯ï¼šconfig.json ä¸­çš„ 'bot_token' æœªè®¾ç½®ï¼")
        if not os.path.exists(CONFIG_FILE): save_config()
        return

    updater = Updater(token=bot_token, use_context=True)
    dispatcher = updater.dispatcher
    commands = [
        BotCommand("start", "ğŸš€ å¯åŠ¨ä¸å¸®åŠ©"), BotCommand("help", "â“ å‘½ä»¤æ‰‹å†Œ"),
        BotCommand("kkfofa", "ğŸ” èµ„äº§æœç´¢/é¢„è®¾"), BotCommand("host", "ğŸ“¦ ä¸»æœºèšåˆä¿¡æ¯"),
        BotCommand("stats", "ğŸ“Š å…¨å±€èšåˆç»Ÿè®¡"), BotCommand("settings", "âš™ï¸ è®¾ç½®èœå•"),
        BotCommand("history", "ğŸ•°ï¸ æŸ¥è¯¢å†å²"), BotCommand("import", "ğŸ–‡ï¸ å¯¼å…¥æ—§ç¼“å­˜"),
        BotCommand("backup", "ğŸ“¤ å¤‡ä»½é…ç½®"), BotCommand("restore", "ğŸ“¥ æ¢å¤é…ç½®"),
        BotCommand("update", "ğŸ”„ åœ¨çº¿æ›´æ–°è„šæœ¬"),
        BotCommand("getlog", "ğŸ“„ è·å–æ—¥å¿—"), BotCommand("shutdown", "ğŸ”Œ å…³é—­æœºå™¨äºº"),
        BotCommand("stop", "ğŸ›‘ åœæ­¢ä»»åŠ¡"), BotCommand("cancel", "âŒ å–æ¶ˆæ“ä½œ")
    ]
    try: updater.bot.set_my_commands(commands)
    except Exception as e: logger.warning(f"è®¾ç½®æœºå™¨äººå‘½ä»¤å¤±è´¥: {e}")

    settings_conv = ConversationHandler(
        entry_points=[CommandHandler("settings", settings_command)],
        states={
            STATE_SETTINGS_MAIN: [CallbackQueryHandler(settings_callback_handler, pattern=r"^settings_")],
            STATE_SETTINGS_ACTION: [CallbackQueryHandler(settings_action_handler, pattern=r"^action_")],
            STATE_GET_KEY: [MessageHandler(Filters.text & ~Filters.command, get_key)],
            STATE_GET_PROXY: [MessageHandler(Filters.text & ~Filters.command, get_proxy)],
            STATE_REMOVE_API: [MessageHandler(Filters.text & ~Filters.command, remove_api)],
            STATE_PRESET_MENU: [CallbackQueryHandler(preset_menu_callback, pattern=r"^preset_")],
            STATE_GET_PRESET_NAME: [MessageHandler(Filters.text & ~Filters.command, get_preset_name)],
            STATE_GET_PRESET_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_preset_query)],
            STATE_REMOVE_PRESET: [MessageHandler(Filters.text & ~Filters.command, remove_preset)],
            STATE_GET_UPDATE_URL: [MessageHandler(Filters.text & ~Filters.command, get_update_url)],
        },
        fallbacks=[CommandHandler("cancel", cancel)]
    )
    
    # <--- ä¿®æ”¹: kkfofa_conv å¢åŠ äº†æ–°çš„çŠ¶æ€å’Œå¤„ç†å™¨ ---
    kkfofa_conv = ConversationHandler(
        entry_points=[ CommandHandler("kkfofa", kkfofa_entry), CallbackQueryHandler(kkfofa_entry, pattern=r"^run_preset_") ],
        states={
            STATE_ASK_CONTINENT: [CallbackQueryHandler(ask_continent_callback, pattern=r"^continent_")],
            STATE_CONTINENT_CHOICE: [CallbackQueryHandler(continent_choice_callback, pattern=r"^continent_")],
            STATE_CACHE_CHOICE: [CallbackQueryHandler(cache_choice_callback, pattern=r"^cache_")],
            STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
        },
        fallbacks=[CommandHandler("cancel", cancel)]
    )

    import_conv = ConversationHandler(entry_points=[CommandHandler("import", import_command)], states={STATE_GET_IMPORT_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_import_query)]}, fallbacks=[CommandHandler("cancel", cancel)])
    stats_conv = ConversationHandler(entry_points=[CommandHandler("stats", stats_command)], states={STATE_GET_STATS_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_fofa_stats_query)]}, fallbacks=[CommandHandler("cancel", cancel)])
    
    dispatcher.add_handler(CommandHandler("start", start_command))
    dispatcher.add_handler(CommandHandler("help", help_command))
    dispatcher.add_handler(CommandHandler("host", host_command))
    dispatcher.add_handler(CommandHandler("stop", stop_all_tasks))
    dispatcher.add_handler(CommandHandler("backup", backup_config_command))
    dispatcher.add_handler(CommandHandler("restore", restore_config_command))
    dispatcher.add_handler(CommandHandler("history", history_command))
    dispatcher.add_handler(CommandHandler("getlog", get_log_command))
    dispatcher.add_handler(CommandHandler("shutdown", shutdown_command))
    dispatcher.add_handler(CommandHandler("update", update_script_command))
    dispatcher.add_handler(settings_conv); dispatcher.add_handler(kkfofa_conv); dispatcher.add_handler(import_conv); dispatcher.add_handler(stats_conv)
    dispatcher.add_handler(MessageHandler(Filters.document.mime_type("application/json"), receive_config_file))
    dispatcher.add_handler(CallbackQueryHandler(liveness_check_callback, pattern=r"^liveness_"))
    dispatcher.add_handler(CallbackQueryHandler(subnet_scan_callback, pattern=r"^subnet_"))
    
    logger.info("ğŸš€ ç»ˆæç‰ˆæœºå™¨äººå·²å¯åŠ¨ (v5 - å«å¤§æ´²é€‰æ‹©)...")
    updater.start_polling()
    updater.idle()
    logger.info("æœºå™¨äººå·²å…³é—­ã€‚")

if __name__ == "__main__":
    main()
