# fofa_bot_v9.8.py (ä¿®å¤ä¼šå‘˜ç­‰çº§åˆ¤æ–­é€»è¾‘ & æ¶ˆæ¯æ ¼å¼)
#
# v9.8 æ ¸å¿ƒæ›´æ–°:
# 1. Bugä¿®å¤: é‡æ„äº†API Keyç­‰çº§çš„åˆ¤æ–­é€»è¾‘ï¼Œä¼˜å…ˆæ£€æŸ¥ is_vip å­—æ®µï¼Œå¹¶ä¿®æ­£äº† vip_level çš„æ˜ å°„ï¼Œè§£å†³äº† [820001] æƒé™é”™è¯¯ã€‚
# 2. Bugä¿®å¤: ç§»é™¤äº†å¯¹APIé”™è¯¯ä¿¡æ¯ä¸å¿…è¦çš„è½¬ä¹‰ï¼Œè§£å†³äº†éƒ¨åˆ†æ¶ˆæ¯ä¸­å‡ºç°å¤šä½™ "/" çš„é—®é¢˜ã€‚
# 3. ä¿ç•™äº†v9.7æ‰€æœ‰åŠŸèƒ½ã€‚
#
# è¿è¡Œå‰è¯·ç¡®ä¿å·²å®‰è£…ä¾èµ–:
# pip install pandas openpyxl pysocks "requests[socks]" tqdm "python-telegram-bot[persistence]"
import os
import sys
import json
import logging
import base64
import time
import re
import requests
import signal
import socket
import hashlib
import shutil
import random
import csv
import asyncio
import pandas as pd
from functools import wraps
from datetime import datetime, timedelta
from dateutil import tz
from urllib.parse import urlparse

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand, ParseMode
from telegram.ext import (
    Updater,
    CommandHandler,
    CallbackContext,
    ConversationHandler,
    MessageHandler,
    CallbackQueryHandler,
    Filters,
    PicklePersistence,
)
from telegram.error import BadRequest, RetryAfter

# --- å…¨å±€å˜é‡å’Œå¸¸é‡ ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
LOG_FILE = 'fofa_bot.log'
FOFA_CACHE_DIR = 'fofa_file'
PERSISTENCE_FILE = 'bot_persistence'
ANONYMOUS_KEYS_FILE = 'fofa_anonymous.json'
MAX_HISTORY_SIZE = 50
CACHE_EXPIRATION_SECONDS = 24 * 60 * 60
MAX_BATCH_TARGETS = 10000
FOFA_SEARCH_URL = "https://fofa.info/api/v1/search/all"
FOFA_INFO_URL = "https://fofa.info/api/v1/info/my"
FOFA_STATS_URL = "https://fofa.info/api/v1/search/stats"

# --- FOFA å­—æ®µå®šä¹‰ ---
# /stats æ¥å£å¯ç”¨çš„å…è´¹å­—æ®µ
FOFA_STATS_FIELDS = "protocol,domain,port,title,os,server,country,asn,org,asset_type,fid,icp"

# /search/all æ¥å£å­—æ®µæŒ‰ä¼šå‘˜ç­‰çº§åˆ’åˆ†
FREE_FIELDS = ["ip", "port", "protocol", "country", "country_name", "region", "city", "longitude", "latitude", "asn", "org", "host", "domain", "os", "server", "icp", "title", "jarm", "header", "banner", "cert", "base_protocol", "link", "cert.issuer.org", "cert.issuer.cn", "cert.subject.org", "cert.subject.cn", "tls.ja3s", "tls.version", "cert.sn", "cert.not_before", "cert.not_after", "cert.domain"]
PERSONAL_FIELDS = FREE_FIELDS + ["header_hash", "banner_hash", "banner_fid"]
BUSINESS_FIELDS = PERSONAL_FIELDS + ["cname", "lastupdatetime", "product", "product_category", "version", "icon_hash", "cert.is_valid", "cname_domain", "body", "cert.is_match", "cert.is_equal"]
ENTERPRISE_FIELDS = BUSINESS_FIELDS + ["icon", "fid", "structinfo"]

FIELD_CATEGORIES = {
    "å…è´¹å­—æ®µ": FREE_FIELDS,
    "ä¸ªäººä¼šå‘˜å­—æ®µ": list(set(PERSONAL_FIELDS) - set(FREE_FIELDS)),
    "å•†ä¸šç‰ˆæœ¬å­—æ®µ": list(set(BUSINESS_FIELDS) - set(PERSONAL_FIELDS)),
    "ä¼ä¸šç‰ˆæœ¬å­—æ®µ": list(set(ENTERPRISE_FIELDS) - set(BUSINESS_FIELDS)),
}

KEY_LEVELS = {} # å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨API Keyçš„ç­‰çº§

# --- æ—¥å¿—é…ç½® ---
if os.path.exists(LOG_FILE) and os.path.getsize(LOG_FILE) > (5 * 1024 * 1024):
    try: os.rename(LOG_FILE, LOG_FILE + '.old')
    except OSError as e: print(f"æ— æ³•è½®æ¢æ—¥å¿—æ–‡ä»¶: {e}")
logging.basicConfig(
    level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler(LOG_FILE, encoding='utf-8'), logging.StreamHandler()]
)
logging.getLogger("requests").setLevel(logging.WARNING); logging.getLogger("urllib3").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# --- ä¼šè¯çŠ¶æ€å®šä¹‰ ---
(
    STATE_SETTINGS_MAIN, STATE_SETTINGS_ACTION, STATE_GET_KEY, STATE_REMOVE_API,
    STATE_KKFOFA_MODE, STATE_CACHE_CHOICE, STATE_GET_IMPORT_QUERY, STATE_GET_STATS_QUERY,
    STATE_PRESET_MENU, STATE_GET_PRESET_NAME, STATE_GET_PRESET_QUERY, STATE_REMOVE_PRESET,
    STATE_GET_UPDATE_URL, STATE_ASK_CONTINENT, STATE_CONTINENT_CHOICE,
    STATE_GET_BATCH_FILE, STATE_SELECT_BATCH_FEATURES, STATE_GET_RESTORE_FILE,
    STATE_PROXYPOOL_MENU, STATE_GET_PROXY_ADD, STATE_GET_PROXY_REMOVE,
    STATE_GET_TRACEBACK_LIMIT, STATE_GET_SCAN_CONCURRENCY, STATE_GET_SCAN_TIMEOUT,
    STATE_UPLOAD_API_MENU, STATE_GET_UPLOAD_URL, STATE_GET_UPLOAD_TOKEN,
    STATE_GET_GUEST_KEY, STATE_BATCH_GET_QUERY, STATE_BATCH_SELECT_FIELDS
) = range(30)

# --- é…ç½®ç®¡ç† & ç¼“å­˜ ---
def load_json_file(filename, default_content):
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4); return default_content
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            config = json.load(f)
            for key, value in default_content.items(): config.setdefault(key, value)
            return config
    except (json.JSONDecodeError, IOError):
        logger.error(f"{filename} æŸåï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®é‡å»ºã€‚");
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4); return default_content

def save_json_file(filename, data):
    with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=4, ensure_ascii=False)

DEFAULT_CONFIG = { "bot_token": "YOUR_BOT_TOKEN_HERE", "apis": [], "admins": [], "proxy": "", "proxies": [], "full_mode": False, "public_mode": False, "presets": [], "update_url": "", "upload_api_url": "", "upload_api_token": "" }
CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
HISTORY = load_json_file(HISTORY_FILE, {"queries": []})
ANONYMOUS_KEYS = load_json_file(ANONYMOUS_KEYS_FILE, {})

def save_config(): save_json_file(CONFIG_FILE, CONFIG)
def save_anonymous_keys(): save_json_file(ANONYMOUS_KEYS_FILE, ANONYMOUS_KEYS)

def add_or_update_query(query_text, cache_data=None):
    existing_query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if existing_query:
        HISTORY['queries'].remove(existing_query); existing_query['timestamp'] = datetime.now(tz.tzutc()).isoformat()
        if cache_data: existing_query['cache'] = cache_data
        HISTORY['queries'].insert(0, existing_query)
    else:
        new_query = {"query_text": query_text, "timestamp": datetime.now(tz.tzutc()).isoformat(), "cache": cache_data}
        HISTORY['queries'].insert(0, new_query)
    while len(HISTORY['queries']) > MAX_HISTORY_SIZE: HISTORY['queries'].pop()
    save_json_file(HISTORY_FILE, HISTORY)
def find_cached_query(query_text):
    query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if query and query.get('cache'):
        if 'file_path' in query['cache'] and os.path.exists(query['cache']['file_path']):
            return query
    return None

# --- è¾…åŠ©å‡½æ•°ä¸è£…é¥°å™¨ ---
def generate_filename_from_query(query_text: str, prefix: str = "fofa", ext: str = ".txt") -> str:
    sanitized_query = re.sub(r'[^a-z0-9\-_]+', '_', query_text.lower()).strip('_')
    max_len = 100
    if len(sanitized_query) > max_len: sanitized_query = sanitized_query[:max_len].rsplit('_', 1)[0]
    timestamp = int(time.time()); return f"{prefix}_{sanitized_query}_{timestamp}{ext}"
def get_proxies():
    proxies_list = CONFIG.get("proxies", [])
    if not proxies_list:
        single_proxy = CONFIG.get("proxy")
        if single_proxy: return {"http": single_proxy, "https": single_proxy}
        return None
    chosen_proxy = random.choice(proxies_list)
    return {"http": chosen_proxy, "https": chosen_proxy}
def is_admin(user_id: int) -> bool: return user_id in CONFIG.get('admins', [])
def admin_only(func):
    @wraps(func)
    def wrapped(update: Update, context: CallbackContext, *args, **kwargs):
        if not is_admin(update.effective_user.id):
            message_text = "â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤ç®¡ç†æ“ä½œã€‚"
            if update.callback_query: update.callback_query.answer(message_text, show_alert=True)
            elif update.message: update.message.reply_text(message_text)
            return None
        return func(update, context, *args, **kwargs)
    return wrapped
def escape_markdown(text: str) -> str:
    if not isinstance(text, str): text = str(text)
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)
def create_progress_bar(percentage: float, length: int = 10) -> str:
    if percentage < 0: percentage = 0
    if percentage > 100: percentage = 100
    filled_length = int(length * percentage // 100)
    bar = 'â–ˆ' * filled_length + 'â–‘' * (length - filled_length)
    return f"[{bar}] {percentage:.1f}%"

# --- æ–‡ä»¶ä¸Šä¼ è¾…åŠ©å‡½æ•° ---
def upload_and_send_links(context: CallbackContext, chat_id: int, file_path: str):
    api_url = CONFIG.get("upload_api_url")
    api_token = CONFIG.get("upload_api_token")
    if not api_url or not api_token:
        logger.info("æœªé…ç½®ä¸Šä¼ APIçš„URLæˆ–Tokenï¼Œè·³è¿‡æ–‡ä»¶ä¸Šä¼ ã€‚")
        return
    try:
        with open(file_path, 'rb') as f:
            files = {'file': (os.path.basename(file_path), f)}
            headers = {'Authorization': api_token}
            response = requests.post(api_url, headers=headers, files=files, timeout=60, proxies=get_proxies())
            response.raise_for_status()
            result = response.json()

        if result and isinstance(result, list) and 'src' in result[0]:
            file_url_path = result[0]['src']
            parsed_main_url = urlparse(api_url)
            base_url = f"{parsed_main_url.scheme}://{parsed_main_url.netloc}"
            full_url = base_url + file_url_path
            file_name = os.path.basename(file_url_path)
            
            download_commands = (
                f"ğŸ“¥ *æ–‡ä»¶ä¸‹è½½å‘½ä»¤*\n\n"
                f"*cURL:*\n`curl -o \"{file_name}\" \"{full_url}\"`\n\n"
                f"*Wget:*\n`wget --content-disposition \"{full_url}\"`"
            )
            context.bot.send_message(chat_id, download_commands, parse_mode=ParseMode.MARKDOWN)
        else:
            raise ValueError(f"å“åº”æ ¼å¼ä¸æ­£ç¡®: {result}")
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        # v9.8 FIX: Removed unnecessary markdown escape for error message
        context.bot.send_message(chat_id, f"âš ï¸ æ–‡ä»¶ä¸Šä¼ åˆ°å¤–éƒ¨æœåŠ¡å™¨å¤±è´¥: `{str(e)}`", parse_mode=ParseMode.MARKDOWN)

# --- FOFA API æ ¸å¿ƒé€»è¾‘ ---
def _make_api_request(url, params, timeout=60, use_b64=True, retries=10):
    if use_b64 and 'q' in params:
        params['qbase64'] = base64.b64encode(params.pop('q').encode('utf-8')).decode('utf-8')
    last_error = None
    for attempt in range(retries):
        try:
            proxies = get_proxies()
            response = requests.get(url, params=params, timeout=timeout, proxies=proxies, verify=False)
            if response.status_code == 429:
                wait_time = 5 * (attempt + 1)
                logger.warning(f"FOFA API rate limit hit (429). Retrying in {wait_time} seconds... (Attempt {attempt + 1}/{retries})")
                time.sleep(wait_time)
                last_error = f"APIè¯·æ±‚å› é€Ÿç‡é™åˆ¶(429)å¤±è´¥"
                continue
            response.raise_for_status()
            data = response.json()
            if data.get("error"):
                return None, data.get("errmsg", "æœªçŸ¥çš„FOFAé”™è¯¯")
            return data, None
        except requests.exceptions.RequestException as e:
            last_error = f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}"
            logger.error(f"RequestException on attempt {attempt + 1}: {e}")
            time.sleep(5)
        except json.JSONDecodeError as e:
            last_error = f"è§£æJSONå“åº”å¤±è´¥: {e}"
            break
    logger.error(f"API request failed after {retries} retries. Last error: {last_error}")
    return None, last_error if last_error else "APIè¯·æ±‚æœªçŸ¥é”™è¯¯"
def verify_fofa_api(key): return _make_api_request(FOFA_INFO_URL, {'key': key}, timeout=15, use_b64=False, retries=3)
def fetch_fofa_data(key, query, page=1, page_size=10000, fields="host"):
    query_lower = query.lower()
    if 'body=' in query_lower: page_size = min(page_size, 500)
    elif 'cert=' in query_lower: page_size = min(page_size, 2000)
    params = {'key': key, 'q': query, 'size': page_size, 'page': page, 'fields': fields, 'full': CONFIG.get("full_mode", False)}; return _make_api_request(FOFA_SEARCH_URL, params)
def fetch_fofa_stats(key, query):
    params = {'key': key, 'q': query, 'fields': FOFA_STATS_FIELDS}; return _make_api_request(FOFA_STATS_URL, params)

def check_and_classify_keys():
    """å¯åŠ¨æ—¶æ£€æŸ¥å¹¶åˆ†ç±»æ‰€æœ‰ç®¡ç†å‘˜API Key"""
    logger.info("--- å¼€å§‹æ£€æŸ¥å¹¶åˆ†ç±»API Keys ---")
    global KEY_LEVELS
    KEY_LEVELS.clear()
    for key in CONFIG.get('apis', []):
        data, error = verify_fofa_api(key)
        if error:
            logger.warning(f"Key '...{key[-4:]}' æ— æ•ˆ: {error}")
            KEY_LEVELS[key] = -1 # -1 ä»£è¡¨æ— æ•ˆ
            continue
        
        # v9.8 FIX: Corrected VIP level detection logic
        is_vip = data.get('is_vip', False)
        api_level = data.get('vip_level', 0)
        
        level = 0 # Default to Free
        if is_vip:
            if api_level in [1, 2]: # Personal Member (based on user feedback)
                level = 1
            elif api_level == 3: # Business Member (assumption)
                level = 2
            elif api_level >= 4: # Enterprise Member (assumption)
                level = 3
        
        KEY_LEVELS[key] = level
        level_name = {0: "å…è´¹ä¼šå‘˜", 1: "ä¸ªäººä¼šå‘˜", 2: "å•†ä¸šä¼šå‘˜", 3: "ä¼ä¸šä¼šå‘˜"}.get(level, "æœªçŸ¥ç­‰çº§")
        logger.info(f"Key '...{key[-4:]}' ({data.get('username', 'N/A')}) - ç­‰çº§: {level} ({level_name})")
    logger.info("--- API Keys åˆ†ç±»å®Œæˆ ---")

def get_fields_by_level(level):
    if level >= 3: return ENTERPRISE_FIELDS
    if level == 2: return BUSINESS_FIELDS
    if level == 1: return PERSONAL_FIELDS
    return FREE_FIELDS

def execute_query_with_fallback(query_func, preferred_key_index=None):
    if not CONFIG['apis']: return None, None, None, "æ²¡æœ‰é…ç½®ä»»ä½•API Keyã€‚"
    keys_to_try = [k for k in CONFIG['apis'] if KEY_LEVELS.get(k, -1) != -1] # åªå°è¯•æœ‰æ•ˆçš„key
    if not keys_to_try: return None, None, None, "æ‰€æœ‰é…ç½®çš„API Keyéƒ½æ— æ•ˆã€‚"
    
    start_index = 0
    if preferred_key_index is not None and 1 <= preferred_key_index <= len(CONFIG['apis']):
        preferred_key = CONFIG['apis'][preferred_key_index - 1]
        if preferred_key in keys_to_try:
            start_index = keys_to_try.index(preferred_key)

    for i in range(len(keys_to_try)):
        idx = (start_index + i) % len(keys_to_try)
        key = keys_to_try[idx]
        key_num = CONFIG['apis'].index(key) + 1
        key_level = KEY_LEVELS.get(key, 0)
        
        data, error = query_func(key)
        if not error:
            return data, key_num, key_level, None
        if "[820031]" in str(error):
            logger.warning(f"Key [#{key_num}] Fç‚¹ä½™é¢ä¸è¶³...");
            continue
        return None, key_num, key_level, error
    return None, None, None, "æ‰€æœ‰Keyå‡å°è¯•å¤±è´¥ (å¯èƒ½Fç‚¹å‡ä¸è¶³)ã€‚"

# --- å¼‚æ­¥æ‰«æé€»è¾‘ (æ— å˜åŠ¨) ---
async def async_check_port(host, port, timeout):
    try:
        fut = asyncio.open_connection(host, port)
        _, writer = await asyncio.wait_for(fut, timeout=timeout)
        writer.close(); await writer.wait_closed()
        return f"{host}:{port}"
    except (asyncio.TimeoutError, ConnectionRefusedError, OSError, socket.gaierror): return None
    except Exception: return None

async def async_scanner_orchestrator(targets, concurrency, timeout, mode='tcping'):
    try:
        from tqdm.asyncio import tqdm as asyncio_tqdm
    except ImportError:
        logger.warning("tqdm æœªå®‰è£…ï¼Œæ§åˆ¶å°å°†ä¸æ˜¾ç¤ºè¿›åº¦æ¡ã€‚è¯·è¿è¡Œ: pip install tqdm")
        async def dummy_gather(*args, **kwargs):
            return await asyncio.gather(*args)
        asyncio_tqdm_gather = dummy_gather
    else:
        asyncio_tqdm_gather = asyncio_tqdm.gather
        
    semaphore = asyncio.Semaphore(concurrency)
    scan_targets = []
    
    if mode == 'tcping':
        for t in targets:
            try:
                host, port_str = t.split(':', 1)
                scan_targets.append((host, int(port_str)))
            except (ValueError, IndexError): continue
    elif mode == 'subnet':
        subnets_to_ports = {}
        for line in targets:
            try:
                ip_str, port_str = line.strip().split(':'); port = int(port_str)
                subnet = ".".join(ip_str.split('.')[:3])
                if subnet not in subnets_to_ports: subnets_to_ports[subnet] = set()
                subnets_to_ports[subnet].add(port)
            except ValueError: continue
        for subnet, ports in subnets_to_ports.items():
            for i in range(1, 255):
                for port in ports:
                    scan_targets.append((f"{subnet}.{i}", port))

    async def worker(host, port):
        async with semaphore:
            return await async_check_port(host, port, timeout)

    tasks = [worker(host, port) for host, port in scan_targets]
    results = await asyncio_tqdm_gather(*tasks, desc=f"Scanning ({mode})", total=len(tasks), unit="host")
    
    return [res for res in results if res is not None]

def run_async_scan_job(context: CallbackContext):
    job_context = context.job.context
    chat_id, msg, query_hash, mode = job_context['chat_id'], job_context['msg'], job_context['query_hash'], job_context['mode']
    concurrency, timeout = job_context['concurrency'], job_context['timeout']

    original_query = context.bot_data.get(query_hash)
    if not original_query: msg.edit_text("âŒ æ‰«æä»»åŠ¡å·²è¿‡æœŸæˆ–æœºå™¨äººåˆšåˆšé‡å¯ã€‚è¯·é‡æ–°å‘èµ·æŸ¥è¯¢ä»¥å¯ç”¨æ‰«æã€‚"); return
    
    cached_item = find_cached_query(original_query)
    if not cached_item: msg.edit_text("âŒ æ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶çš„æœ¬åœ°ç¼“å­˜è®°å½•ã€‚"); return

    msg.edit_text("1/3: æ­£åœ¨è¯»å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶...")
    try:
        with open(cached_item['cache']['file_path'], 'r', encoding='utf-8') as f:
            targets = [line.strip() for line in f if ':' in line.strip()]
    except Exception as e: msg.edit_text(f"âŒ è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
        
    scan_type_text = "TCPå­˜æ´»æ‰«æ" if mode == 'tcping' else "å­ç½‘æ‰«æ"
    msg.edit_text(f"2/3: å·²åŠ è½½ {len(targets)} ä¸ªç›®æ ‡ï¼Œå¼€å§‹å¼‚æ­¥{scan_type_text} (å¹¶å‘: {concurrency}, è¶…æ—¶: {timeout}s)...")
    
    live_results = asyncio.run(async_scanner_orchestrator(targets, concurrency, timeout, mode))

    if not live_results: msg.edit_text("ğŸ¤·â€â™€ï¸ æ‰«æå®Œæˆï¼Œä½†æœªå‘ç°ä»»ä½•å­˜æ´»çš„ç›®æ ‡ã€‚"); return
    
    msg.edit_text("3/3: æ­£åœ¨æ‰“åŒ…å¹¶å‘é€æ–°ç»“æœ...")
    output_filename = generate_filename_from_query(original_query, prefix=f"{mode}_scan")
    with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(live_results))))
    
    final_caption = f"âœ… **å¼‚æ­¥{scan_type_text}å®Œæˆ!**\n\nå…±å‘ç° *{len(live_results)}* ä¸ªå­˜æ´»ç›®æ ‡ã€‚"
    with open(output_filename, 'rb') as doc:
        context.bot.send_document(chat_id, document=doc, caption=final_caption, parse_mode=ParseMode.MARKDOWN)
    
    upload_and_send_links(context, chat_id, output_filename)
    os.remove(output_filename); msg.delete()

# --- æ‰«ææµç¨‹å…¥å£ (æ— å˜åŠ¨) ---
def offer_post_download_actions(context: CallbackContext, chat_id, query_text):
    query_hash = hashlib.md5(query_text.encode()).hexdigest()
    context.bot_data[query_hash] = query_text
    keyboard = [[
        InlineKeyboardButton("âš¡ï¸ å¼‚æ­¥TCPå­˜æ´»æ‰«æ", callback_data=f'start_scan_tcping_{query_hash}'),
        InlineKeyboardButton("ğŸŒ å¼‚æ­¥å­ç½‘æ‰«æ(/24)", callback_data=f'start_scan_subnet_{query_hash}')
    ]]
    context.bot.send_message(chat_id, "ä¸‹è½½å®Œæˆï¼Œéœ€è¦å¯¹ç»“æœè¿›è¡ŒäºŒæ¬¡æ‰«æå—ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard))

def start_scan_callback(update: Update, context: CallbackContext) -> int:
    query = update.callback_query; query.answer()
    _, mode, query_hash = query.data.split('_', 2)
    
    context.user_data['scan_query_hash'] = query_hash
    context.user_data['scan_mode'] = mode
    
    query.message.edit_text("è¯·è¾“å…¥æ‰«æå¹¶å‘æ•° (å»ºè®® 100-1000):")
    return STATE_GET_SCAN_CONCURRENCY

def get_concurrency_callback(update: Update, context: CallbackContext) -> int:
    try:
        concurrency = int(update.message.text)
        if not 1 <= concurrency <= 5000: raise ValueError
        context.user_data['scan_concurrency'] = concurrency
        update.message.reply_text("è¯·è¾“å…¥è¿æ¥è¶…æ—¶æ—¶é—´ (ç§’, å»ºè®® 1-3):")
        return STATE_GET_SCAN_TIMEOUT
    except ValueError:
        update.message.reply_text("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 1-5000 ä¹‹é—´çš„æ•´æ•°ã€‚")
        return STATE_GET_SCAN_CONCURRENCY

def get_timeout_callback(update: Update, context: CallbackContext) -> int:
    try:
        timeout = float(update.message.text)
        if not 0.1 <= timeout <= 10: raise ValueError
        
        msg = update.message.reply_text("âœ… å‚æ•°è®¾ç½®å®Œæ¯•ï¼Œä»»åŠ¡å·²æäº¤åˆ°åå°ã€‚")
        job_context = {
            'chat_id': update.effective_chat.id, 'msg': msg,
            'query_hash': context.user_data['scan_query_hash'],
            'mode': context.user_data['scan_mode'],
            'concurrency': context.user_data['scan_concurrency'],
            'timeout': timeout
        }
        context.job_queue.run_once(run_async_scan_job, 1, context=job_context, name=f"scan_{update.effective_chat.id}")

        context.user_data.clear()
        return ConversationHandler.END
    except ValueError:
        update.message.reply_text("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥ 0.1-10 ä¹‹é—´çš„æ•°å­—ã€‚")
        return STATE_GET_SCAN_TIMEOUT

# --- åå°ä¸‹è½½ä»»åŠ¡ (æ— å˜åŠ¨) ---
def start_download_job(context: CallbackContext, callback_func, job_data):
    chat_id = job_data['chat_id']; job_name = f"download_job_{chat_id}"
    for job in context.job_queue.get_jobs_by_name(job_name): job.schedule_removal()
    context.bot_data.pop(f'stop_job_{chat_id}', None)
    context.job_queue.run_once(callback_func, 1, context=job_data, name=job_name)
def run_full_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, query_text, total_size = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size']
    output_filename = generate_filename_from_query(query_text); unique_results, stop_flag = set(), f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡..."); pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(unique_results)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except (BadRequest, RetryAfter): pass
        
        # æ ¹æ®æ˜¯è®¿å®¢è¿˜æ˜¯ç®¡ç†å‘˜é€‰æ‹©ä¸åŒçš„æŸ¥è¯¢æ–¹å¼
        guest_key = job_data.get('guest_key')
        if guest_key:
            data, error = fetch_fofa_data(guest_key, query_text, page, 10000, "host")
        else:
            data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page, 10000, "host"))

        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        results = data.get('results', []);
        if not results: break
        unique_results.update(res for res in results if ':' in res)
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(unique_results))
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚æ­£åœ¨å‘é€...")
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        with open(cache_path, 'rb') as doc: bot.send_document(chat_id, document=doc, filename=output_filename)
        upload_and_send_links(context, chat_id, cache_path)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(query_text, cache_data); offer_post_download_actions(context, chat_id, query_text)
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)
def run_traceback_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; limit = job_data.get('limit')
    output_filename = generate_filename_from_query(base_query); unique_results, page_count, last_page_date, termination_reason, stop_flag, last_update_time = set(), 0, None, "", f'stop_job_{chat_id}', 0
    msg = bot.send_message(chat_id, "â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query
    guest_key = job_data.get('guest_key')
    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        
        if guest_key:
            data, error = fetch_fofa_data(guest_key, current_query, 1, 10000, "host,lastupdatetime")
        else:
            data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, current_query, 1, 10000, "host,lastupdatetime"))

        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break
        original_count = len(unique_results); unique_results.update([r[0] for r in results if r and r[0] and ':' in r[0]]); newly_added_count = len(unique_results) - original_count
        if limit and len(unique_results) >= limit: unique_results = set(list(unique_results)[:limit]); termination_reason = f"\n\nâ„¹ï¸ å·²è¾¾åˆ°æ‚¨è®¾ç½®çš„ {limit} æ¡ç»“æœä¸Šé™ã€‚"; break
        current_time = time.time()
        if current_time - last_update_time > 2:
            try: msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
            except (BadRequest, RetryAfter): pass
            last_update_time = current_time
        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][1]: continue
            try:
                timestamp_str = results[i][1]; current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                last_page_date = current_date_obj; current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'; valid_anchor_found = True
                break
            except (ValueError, TypeError): continue
        if not valid_anchor_found: termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; break
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(unique_results))))
        msg.edit_text(f"âœ… æ·±åº¦è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨å‘é€æ–‡ä»¶...")
        cache_path = os.path.join(FOFA_CACHE_DIR, output_filename)
        shutil.move(output_filename, cache_path)
        with open(cache_path, 'rb') as doc: bot.send_document(chat_id, document=doc, filename=output_filename)
        upload_and_send_links(context, chat_id, cache_path)
        cache_data = {'file_path': cache_path, 'result_count': len(unique_results)}
        add_or_update_query(base_query, cache_data); offer_post_download_actions(context, chat_id, base_query)
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)
def run_incremental_update_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']; msg = bot.send_message(chat_id, "--- å¢é‡æ›´æ–°å¯åŠ¨ ---")
    msg.edit_text("1/5: æ­£åœ¨è·å–æ—§ç¼“å­˜..."); cached_item = find_cached_query(base_query)
    if not cached_item: msg.edit_text("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜é¡¹ã€‚"); return
    old_file_path = cached_item['cache']['file_path']; old_results = set()
    try:
        with open(old_file_path, 'r', encoding='utf-8') as f: old_results = set(line.strip() for line in f if line.strip() and ':' in line)
    except Exception as e: msg.edit_text(f"âŒ è¯»å–æœ¬åœ°ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    msg.edit_text("2/5: æ­£åœ¨ç¡®å®šæ›´æ–°èµ·å§‹ç‚¹..."); data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, base_query, fields="lastupdatetime"))
    if error or not data.get('results'): msg.edit_text(f"âŒ æ— æ³•è·å–æœ€æ–°è®°å½•æ—¶é—´æˆ³: {error or 'æ— ç»“æœ'}"); return
    ts_str = data['results'][0][0] if isinstance(data['results'][0], list) else data['results'][0]; cutoff_date = ts_str.split(' ')[0]
    incremental_query = f'({base_query}) && after="{cutoff_date}"'
    msg.edit_text(f"3/5: æ­£åœ¨ä¾¦å¯Ÿè‡ª {cutoff_date} ä»¥æ¥çš„æ–°æ•°æ®..."); data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page_size=1))
    if error: msg.edit_text(f"âŒ ä¾¦å¯ŸæŸ¥è¯¢å¤±è´¥: {error}"); return
    total_new_size = data.get('size', 0)
    if total_new_size == 0: msg.edit_text("âœ… æœªå‘ç°æ–°æ•°æ®ã€‚ç¼“å­˜å·²æ˜¯æœ€æ–°ã€‚"); return
    new_results, stop_flag = set(), f'stop_job_{chat_id}'; pages_to_fetch = (total_new_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ å¢é‡æ›´æ–°å·²æ‰‹åŠ¨åœæ­¢ã€‚"); return
        msg.edit_text(f"3/5: æ­£åœ¨ä¸‹è½½æ–°æ•°æ®... ( Page {page}/{pages_to_fetch} )")
        data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page=page, page_size=10000))
        if error: msg.edit_text(f"âŒ ä¸‹è½½æ–°æ•°æ®å¤±è´¥: {error}"); return
        if data.get('results'): new_results.update(res for res in data.get('results', []) if ':' in res)
    msg.edit_text(f"4/5: æ­£åœ¨åˆå¹¶æ•°æ®... (å‘ç° {len(new_results)} æ¡æ–°æ•°æ®)"); combined_results = sorted(list(new_results.union(old_results)))
    with open(old_file_path, 'w', encoding='utf-8') as f: f.write("\n".join(combined_results))
    msg.edit_text(f"5/5: å‘é€æ›´æ–°åçš„æ–‡ä»¶... (å…± {len(combined_results)} æ¡)")
    with open(old_file_path, 'rb') as doc: bot.send_document(chat_id, document=doc, filename=os.path.basename(old_file_path))
    upload_and_send_links(context, chat_id, old_file_path)
    cache_data = {'file_path': old_file_path, 'result_count': len(combined_results)}
    add_or_update_query(base_query, cache_data)
    msg.delete(); bot.send_message(chat_id, f"âœ… å¢é‡æ›´æ–°å®Œæˆï¼"); offer_post_download_actions(context, chat_id, base_query)
def run_batch_download_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, query_text, total_size, fields = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size'], job_data['fields']
    output_filename = generate_filename_from_query(query_text, prefix="batch_export", ext=".csv"); results_list, stop_flag = [], f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹è‡ªå®šä¹‰å­—æ®µæ‰¹é‡å¯¼å‡ºä»»åŠ¡..."); pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(results_list)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except (BadRequest, RetryAfter): pass
        data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page, 10000, fields))
        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        page_results = data.get('results', [])
        if not page_results: break
        results_list.extend(page_results)
    if results_list:
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(results_list)} æ¡ã€‚æ­£åœ¨ç”ŸæˆCSVæ–‡ä»¶...")
        try:
            with open(output_filename, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f); writer.writerow(fields.split(',')); writer.writerows(results_list)
            with open(output_filename, 'rb') as doc:
                bot.send_document(chat_id, document=doc, filename=output_filename, caption=f"âœ… è‡ªå®šä¹‰å¯¼å‡ºå®Œæˆ\næŸ¥è¯¢: `{escape_markdown(query_text)}`", parse_mode=ParseMode.MARKDOWN)
            upload_and_send_links(context, chat_id, output_filename)
        except Exception as e:
            msg.edit_text(f"âŒ ç”Ÿæˆæˆ–å‘é€CSVæ–‡ä»¶å¤±è´¥: {e}"); logger.error(f"Failed to generate/send CSV for batch command: {e}")
        finally:
            if os.path.exists(output_filename): os.remove(output_filename)
            msg.delete()
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)
def run_batch_traceback_query(context: CallbackContext):
    job_data = context.job.context; bot, chat_id, base_query, fields, limit = context.bot, job_data['chat_id'], job_data['query'], job_data['fields'], job_data.get('limit')
    output_filename = generate_filename_from_query(base_query, prefix="batch_traceback", ext=".csv")
    unique_results, page_count, last_page_date, termination_reason, stop_flag, last_update_time = [], 0, None, "", f'stop_job_{chat_id}', 0
    msg = bot.send_message(chat_id, "â³ å¼€å§‹è‡ªå®šä¹‰å­—æ®µæ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query; seen_hashes = set()
    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, current_query, 1, 10000, fields + ",lastupdatetime"))
        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break
        newly_added_count = 0
        for r in results:
            r_hash = hashlib.md5(str(r).encode()).hexdigest()
            if r_hash not in seen_hashes:
                seen_hashes.add(r_hash); unique_results.append(r[:-1]); newly_added_count += 1 # Exclude lastupdatetime
        if limit and len(unique_results) >= limit: unique_results = unique_results[:limit]; termination_reason = f"\n\nâ„¹ï¸ å·²è¾¾åˆ°æ‚¨è®¾ç½®çš„ {limit} æ¡ç»“æœä¸Šé™ã€‚"; break
        current_time = time.time()
        if current_time - last_update_time > 2:
            try: msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
            except (BadRequest, RetryAfter): pass
            last_update_time = current_time
        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][-1]: continue
            try:
                timestamp_str = results[i][-1]; current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                last_page_date = current_date_obj; current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'; valid_anchor_found = True
                break
            except (ValueError, TypeError): continue
        if not valid_anchor_found: termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œ."; break
    if unique_results:
        msg.edit_text(f"âœ… è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨ç”ŸæˆCSV...")
        try:
            with open(output_filename, 'w', encoding='utf-8-sig', newline='') as f:
                writer = csv.writer(f); writer.writerow(fields.split(',')); writer.writerows(unique_results)
            with open(output_filename, 'rb') as doc:
                bot.send_document(chat_id, document=doc, filename=output_filename)
            upload_and_send_links(context, chat_id, output_filename)
        except Exception as e:
            msg.edit_text(f"âŒ ç”Ÿæˆæˆ–å‘é€CSVæ–‡ä»¶å¤±è´¥: {e}"); logger.error(f"Failed to generate/send CSV for batch traceback: {e}")
        finally:
            if os.path.exists(output_filename): os.remove(output_filename)
            msg.delete()
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)

# --- æ ¸å¿ƒå‘½ä»¤å¤„ç† ---
def start_command(update: Update, context: CallbackContext):
    update.message.reply_text('ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Fofa æŸ¥è¯¢æœºå™¨äºº v9.8ï¼è¯·ä½¿ç”¨ /help æŸ¥çœ‹å‘½ä»¤æ‰‹å†Œã€‚')
    if not CONFIG['admins']: first_admin_id = update.effective_user.id; CONFIG.setdefault('admins', []).append(first_admin_id); save_config(); update.message.reply_text(f"â„¹ï¸ å·²è‡ªåŠ¨å°†æ‚¨ (ID: `{first_admin_id}`) æ·»åŠ ä¸ºç¬¬ä¸€ä¸ªç®¡ç†å‘˜ã€‚")

def help_command(update: Update, context: CallbackContext):
    help_text = ( "ğŸ“– *Fofa æœºå™¨äººæŒ‡ä»¤æ‰‹å†Œ v9.8*\n\n"
                  "*ğŸ” èµ„äº§æŸ¥è¯¢*\n`/kkfofa [key] <query>`\n_FOFAæœç´¢, éç®¡ç†å‘˜é¦–æ¬¡ä½¿ç”¨éœ€æä¾›Key_\n\n"
                  "*ğŸ“¦ ä¸»æœºè¯¦æŸ¥ (æ™ºèƒ½)*\n`/host <ip|domain>`\n_æ ¹æ®Keyç­‰çº§è·å–æœ€å…¨ä¸»æœºä¿¡æ¯ (ç®¡ç†å‘˜)_\n\n"
                  "*ğŸ”¬ ä¸»æœºé€ŸæŸ¥ (å¼€æ”¾)*\n`/lowhost <ip|domain>`\n_è·å–ä¸»æœºåŸºç¡€ä¿¡æ¯ (æ‰€æœ‰ç”¨æˆ·å¯ç”¨)_\n\n"
                  "*ğŸ“Š èšåˆç»Ÿè®¡*\n`/stats <query>`\n_è·å–å…¨å±€èšåˆç»Ÿè®¡ (ç®¡ç†å‘˜)_\n\n"
                  "*ğŸ“‚ æ‰¹é‡æ™ºèƒ½åˆ†æ*\n`/batchfind`\n_ä¸Šä¼ IPåˆ—è¡¨, åˆ†æç‰¹å¾å¹¶ç”ŸæˆExcel (ç®¡ç†å‘˜)_\n\n"
                  "*ğŸ“¤ æ‰¹é‡è‡ªå®šä¹‰å¯¼å‡º (äº¤äº’å¼)*\n`/batch <query>`\n_è¿›å…¥äº¤äº’å¼èœå•é€‰æ‹©å­—æ®µå¯¼å‡º (ç®¡ç†å‘˜)_\n\n"
                  "*âš™ï¸ ç®¡ç†ä¸è®¾ç½®*\n`/settings`\n_è¿›å…¥äº¤äº’å¼è®¾ç½®èœå• (ç®¡ç†å‘˜)_\n\n"
                  "*ğŸ’» ç³»ç»Ÿç®¡ç†*\n"
                  "`/check` - ç³»ç»Ÿè‡ªæ£€\n"
                  "`/update` - åœ¨çº¿æ›´æ–°è„šæœ¬\n"
                  "`/shutdown` - å®‰å…¨å…³é—­/é‡å¯\n\n"
                  "*ğŸ›‘ ä»»åŠ¡æ§åˆ¶*\n`/stop` - ç´§æ€¥åœæ­¢ä¸‹è½½ä»»åŠ¡\n`/cancel` - å–æ¶ˆå½“å‰æ“ä½œ\n\n"
                  "ğŸ’¡ *æœºå™¨äººç°åœ¨èƒ½è‡ªåŠ¨è¯†åˆ«Keyç­‰çº§å¹¶ä¸ºè®¿å®¢æä¾›æœåŠ¡ï¼*" )
    update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

def cancel(update: Update, context: CallbackContext) -> int:
    message = "æ“ä½œå·²å–æ¶ˆã€‚"
    if update.message: update.message.reply_text(message)
    elif update.callback_query: update.callback_query.edit_message_text(message)
    context.user_data.clear()
    return ConversationHandler.END

# --- /kkfofa & è®¿å®¢é€»è¾‘ ---
def kkfofa_entry(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    
    # è®¿å®¢é€»è¾‘
    if not is_admin(user_id):
        guest_key = ANONYMOUS_KEYS.get(str(user_id))
        if not guest_key:
            update.message.reply_text("ğŸ‘‹ æ¬¢è¿ï¼ä½œä¸ºé¦–æ¬¡ä½¿ç”¨çš„è®¿å®¢ï¼Œè¯·è¾“å…¥æ‚¨çš„FOFA API Keyä»¥ç»§ç»­ã€‚æ‚¨çš„Keyåªä¼šè¢«æ‚¨è‡ªå·±ä½¿ç”¨ã€‚")
            # å°†æŸ¥è¯¢å‚æ•°æš‚å­˜ï¼Œä»¥ä¾¿è·å–Keyåç»§ç»­
            if context.args:
                context.user_data['pending_query'] = " ".join(context.args)
            return STATE_GET_GUEST_KEY
        # å¦‚æœè®¿å®¢å·²æœ‰keyï¼Œå°†å…¶å­˜å…¥ä¸Šä¸‹æ–‡ä»¥ä¾¿åç»­ä½¿ç”¨
        context.user_data['guest_key'] = guest_key

    # ç®¡ç†å‘˜å’Œå·²éªŒè¯çš„è®¿å®¢é€»è¾‘
    query_obj = update.callback_query; message_obj = update.message
    if query_obj:
        query_obj.answer()
        try:
            preset_index = int(query_obj.data.replace("run_preset_", "")); preset = CONFIG["presets"][preset_index]
            context.user_data['original_query'] = preset['query']; context.user_data['key_index'] = None
            keyboard = [[InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"), InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")]]
            query_obj.message.edit_text(f"é¢„è®¾æŸ¥è¯¢: `{escape_markdown(preset['query'])}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
            return STATE_ASK_CONTINENT
        except (ValueError, IndexError):
            query_obj.message.edit_text("âŒ é¢„è®¾æŸ¥è¯¢å¤±è´¥ã€‚"); return ConversationHandler.END
    if not context.args:
        presets = CONFIG.get("presets", [])
        if not presets: message_obj.reply_text("æ¬¢è¿ä½¿ç”¨FOFAæŸ¥è¯¢æœºå™¨äººã€‚\n\nâ¡ï¸ ç›´æ¥è¾“å…¥æŸ¥è¯¢è¯­æ³•: `/kkfofa domain=\"example.com\"`\nâ„¹ï¸ å½“å‰æ²¡æœ‰å¯ç”¨çš„é¢„è®¾æŸ¥è¯¢ã€‚ç®¡ç†å‘˜å¯é€šè¿‡ /settings æ·»åŠ ã€‚"); return ConversationHandler.END
        keyboard = []
        for i, p in enumerate(presets):
            query_preview = p['query'][:25] + '...' if len(p['query']) > 25 else p['query']
            keyboard.append([InlineKeyboardButton(f"{p['name']} (`{query_preview}`)", callback_data=f"run_preset_{i}")])
        message_obj.reply_text("ğŸ‘‡ è¯·é€‰æ‹©ä¸€ä¸ªé¢„è®¾æŸ¥è¯¢:", reply_markup=InlineKeyboardMarkup(keyboard)); return ConversationHandler.END
    
    key_index, query_text = None, " ".join(context.args)
    if context.args[0].isdigit() and is_admin(user_id): # åªæœ‰ç®¡ç†å‘˜å¯ä»¥æŒ‡å®škey
        try:
            num = int(context.args[0])
            if 1 <= num <= len(CONFIG['apis']): key_index = num; query_text = " ".join(context.args[1:])
        except ValueError: pass
        
    context.user_data['original_query'] = query_text; context.user_data['key_index'] = key_index
    keyboard = [[InlineKeyboardButton("ğŸŒ æ˜¯çš„, é™å®šå¤§æ´²", callback_data="continent_select"), InlineKeyboardButton("â© ä¸, ç›´æ¥æœç´¢", callback_data="continent_skip")]]
    message_obj.reply_text(f"æŸ¥è¯¢: `{escape_markdown(query_text)}`\n\næ˜¯å¦è¦å°†æ­¤æŸ¥è¯¢é™å®šåœ¨ç‰¹å®šå¤§æ´²èŒƒå›´å†…ï¼Ÿ", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_ASK_CONTINENT

def get_guest_key(update: Update, context: CallbackContext):
    user_id = update.effective_user.id
    guest_key = update.message.text.strip()
    
    msg = update.message.reply_text("â³ æ­£åœ¨éªŒè¯æ‚¨çš„API Key...")
    data, error = verify_fofa_api(guest_key)
    
    if error:
        msg.edit_text(f"âŒ KeyéªŒè¯å¤±è´¥: {error}\nè¯·é‡æ–°è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„Keyï¼Œæˆ–ä½¿ç”¨ /cancel å–æ¶ˆã€‚")
        return STATE_GET_GUEST_KEY
    
    # éªŒè¯æˆåŠŸï¼Œä¿å­˜Key
    ANONYMOUS_KEYS[str(user_id)] = guest_key
    save_anonymous_keys()
    msg.edit_text(f"âœ… KeyéªŒè¯æˆåŠŸ ({data.get('username', 'N/A')})ï¼æ‚¨çš„Keyå·²ä¿å­˜ï¼Œç°åœ¨å¯ä»¥å¼€å§‹æŸ¥è¯¢äº†ã€‚")
    
    # å¦‚æœæœ‰å¾…å¤„ç†çš„æŸ¥è¯¢ï¼Œåˆ™ç»§ç»­
    if 'pending_query' in context.user_data:
        context.args = context.user_data.pop('pending_query').split()
        return kkfofa_entry(update, context)
    
    return ConversationHandler.END

def ask_continent_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    if choice == 'skip':
        context.user_data['query'] = context.user_data['original_query']
        query.message.edit_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown(context.user_data['query'])}`", parse_mode=ParseMode.MARKDOWN)
        return proceed_with_query(update, context, message_to_edit=query.message)
    elif choice == 'select':
        keyboard = [
            [InlineKeyboardButton("ğŸŒ äºšæ´²", callback_data="continent_Asia"), InlineKeyboardButton("ğŸŒ æ¬§æ´²", callback_data="continent_Europe")],
            [InlineKeyboardButton("ğŸŒ åŒ—ç¾æ´²", callback_data="continent_NorthAmerica"), InlineKeyboardButton("ğŸŒ å—ç¾æ´²", callback_data="continent_SouthAmerica")],
            [InlineKeyboardButton("ğŸŒ éæ´²", callback_data="continent_Africa"), InlineKeyboardButton("ğŸŒ å¤§æ´‹æ´²", callback_data="continent_Oceania")],
            [InlineKeyboardButton("â†©ï¸ è·³è¿‡", callback_data="continent_skip")]]
        query.message.edit_text("è¯·é€‰æ‹©ä¸€ä¸ªå¤§æ´²:", reply_markup=InlineKeyboardMarkup(keyboard)); return STATE_CONTINENT_CHOICE
def continent_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); continent = query.data.split('_', 1)[1]; original_query = context.user_data['original_query']
    if continent == 'skip':
        context.user_data['query'] = original_query
        query.message.edit_text(f"å¥½çš„ï¼Œå°†ç›´æ¥æœç´¢: `{escape_markdown(original_query)}`", parse_mode=ParseMode.MARKDOWN)
        return proceed_with_query(update, context, message_to_edit=query.message)
    country_list = CONTINENT_COUNTRIES.get(continent)
    if not country_list: query.message.edit_text("âŒ é”™è¯¯ï¼šæ— æ•ˆçš„å¤§æ´²é€‰é¡¹ã€‚"); return ConversationHandler.END
    country_fofa_string = " || ".join([f'country="{code}"' for code in country_list]); final_query = f"({original_query}) && ({country_fofa_string})"
    context.user_data['query'] = final_query
    query.message.edit_text(f"æŸ¥è¯¢å·²æ„å»º:\n`{escape_markdown(final_query)}`\n\næ­£åœ¨å¤„ç†...", parse_mode=ParseMode.MARKDOWN)
    return proceed_with_query(update, context, message_to_edit=query.message)
def proceed_with_query(update: Update, context: CallbackContext, message_to_edit):
    query_text = context.user_data['query']
    cached_item = find_cached_query(query_text)
    if cached_item:
        dt_utc = datetime.fromisoformat(cached_item['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        message_text = (f"âœ… *å‘ç°ç¼“å­˜*\n\næŸ¥è¯¢: `{escape_markdown(query_text)}`\nç¼“å­˜äº: *{time_str}*\n\n")
        keyboard = []; is_expired = (datetime.now(tz.tzutc()) - dt_utc).total_seconds() > CACHE_EXPIRATION_SECONDS
        if is_expired or not is_admin(update.effective_user.id): # è®¿å®¢ä¸èƒ½å¢é‡æ›´æ–°
             message_text += "âš ï¸ *æ­¤ç¼“å­˜å·²è¿‡æœŸæˆ–æ‚¨æ˜¯è®¿å®¢ï¼Œæ— æ³•å¢é‡æ›´æ–°ã€‚*" if is_expired else ""
             keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½æ—§ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        else: 
            message_text += "è¯·é€‰æ‹©æ“ä½œï¼š"; keyboard.append([InlineKeyboardButton("ğŸ”„ å¢é‡æ›´æ–°", callback_data='cache_incremental')]); keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        keyboard.append([InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='cache_cancel')])
        message_to_edit.edit_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
        return STATE_CACHE_CHOICE
    return start_new_search(update, context, message_to_edit=message_to_edit)
def cache_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); choice = query.data.split('_')[1]
    if choice == 'download':
        cached_item = find_cached_query(context.user_data['query'])
        if cached_item:
            query.message.edit_text("â¬‡ï¸ æ­£åœ¨ä»æœ¬åœ°ç¼“å­˜å‘é€æ–‡ä»¶..."); file_path = cached_item['cache']['file_path']
            try:
                with open(file_path, 'rb') as doc: context.bot.send_document(chat_id=update.effective_chat.id, document=doc, filename=os.path.basename(file_path))
                upload_and_send_links(context, update.effective_chat.id, file_path)
                query.message.delete()
            except Exception as e: query.message.edit_text(f"âŒ å‘é€ç¼“å­˜å¤±è´¥: {e}")
        else: query.message.edit_text("âŒ æ‰¾ä¸åˆ°æœ¬åœ°ç¼“å­˜è®°å½•ã€‚")
        return ConversationHandler.END
    elif choice == 'newsearch': return start_new_search(update, context, message_to_edit=query.message)
    elif choice == 'incremental': query.edit_message_text("â³ å‡†å¤‡å¢é‡æ›´æ–°..."); start_download_job(context, run_incremental_update_query, context.user_data); query.message.delete(); return ConversationHandler.END
    elif choice == 'cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆã€‚"); return ConversationHandler.END
def start_new_search(update: Update, context: CallbackContext, message_to_edit=None):
    query_text = context.user_data['query']; key_index = context.user_data.get('key_index'); add_or_update_query(query_text)
    msg = message_to_edit if message_to_edit else update.effective_message.reply_text("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    if message_to_edit: msg.edit_text("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    
    guest_key = context.user_data.get('guest_key')
    if guest_key:
        data, error = fetch_fofa_data(guest_key, query_text, page_size=1, fields="host")
        used_key_info = "æ‚¨çš„Key"
    else:
        data, used_key_index, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page_size=1, fields="host"), key_index)
        used_key_info = f"Key [#{used_key_index}]"

    if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
    total_size = data.get('size', 0)
    if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
    context.user_data.update({'total_size': total_size, 'chat_id': update.effective_chat.id, 'is_batch_mode': False})
    success_message = f"âœ… ä½¿ç”¨ {used_key_info} æ‰¾åˆ° {total_size} æ¡ç»“æœã€‚"
    if total_size <= 10000:
        msg.edit_text(f"{success_message}\nå¼€å§‹ä¸‹è½½..."); start_download_job(context, run_full_download_query, context.user_data)
        return ConversationHandler.END
    else:
        keyboard = [[InlineKeyboardButton("ğŸ’ å…¨éƒ¨ä¸‹è½½ (å‰1ä¸‡)", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯ä¸‹è½½", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
        msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard)); return STATE_KKFOFA_MODE
def query_mode_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); mode = query.data.split('_')[1]
    if mode == 'cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆ."); return ConversationHandler.END
    if mode == 'traceback':
        keyboard = [[InlineKeyboardButton("â™¾ï¸ å…¨éƒ¨è·å–", callback_data='limit_none')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='limit_cancel')]]
        query.message.edit_text("è¯·è¾“å…¥æ·±åº¦è¿½æº¯è·å–çš„ç»“æœæ•°é‡ä¸Šé™ (ä¾‹å¦‚: 50000)ï¼Œæˆ–é€‰æ‹©å…¨éƒ¨è·å–ã€‚", reply_markup=InlineKeyboardMarkup(keyboard))
        return STATE_GET_TRACEBACK_LIMIT
    job_func = run_batch_download_query if context.user_data.get('is_batch_mode') else run_full_download_query
    if mode == 'full' and job_func:
        query.message.edit_text(f"â³ å¼€å§‹ä¸‹è½½..."); start_download_job(context, job_func, context.user_data); query.message.delete()
    return ConversationHandler.END
def get_traceback_limit(update: Update, context: CallbackContext):
    limit = None
    if update.callback_query:
        query = update.callback_query; query.answer()
        if query.data == 'limit_cancel': query.message.edit_text("æ“ä½œå·²å–æ¶ˆ."); return ConversationHandler.END
    elif update.message:
        try:
            limit = int(update.message.text.strip()); assert limit > 0
        except (ValueError, AssertionError):
            update.message.reply_text("âŒ æ— æ•ˆçš„æ•°å­—ï¼Œè¯·è¾“å…¥ä¸€ä¸ªæ­£æ•´æ•°ã€‚"); return STATE_GET_TRACEBACK_LIMIT
    context.user_data['limit'] = limit
    job_func = run_batch_traceback_query if context.user_data.get('is_batch_mode') else run_traceback_download_query
    msg_target = update.callback_query.message if update.callback_query else update.message
    msg_target.reply_text(f"â³ å¼€å§‹æ·±åº¦è¿½æº¯ (ä¸Šé™: {limit or 'æ— '})...")
    start_download_job(context, job_func, context.user_data)
    if update.callback_query: msg_target.delete()
    return ConversationHandler.END

# --- /host å’Œ /lowhost å‘½ä»¤ ---
def _create_dict_from_fofa_result(result_list, fields_list):
    return {fields_list[i]: result_list[i] for i in range(len(fields_list))}

def get_common_host_info(results, fields_list):
    if not results: return {}
    first_entry = _create_dict_from_fofa_result(results[0], fields_list)
    info = {
        "IP": first_entry.get('ip', 'N/A'),
        "åœ°ç†ä½ç½®": f"{first_entry.get('country_name', '')} {first_entry.get('region', '')} {first_entry.get('city', '')}".strip(),
        "ASN": f"{first_entry.get('asn', 'N/A')} ({first_entry.get('org', 'N/A')})",
        "æ“ä½œç³»ç»Ÿ": first_entry.get('os', 'N/A'),
    }
    port_index = fields_list.index('port') if 'port' in fields_list else -1
    if port_index != -1:
        all_ports = sorted(list(set(res[port_index] for res in results if len(res) > port_index)))
        info["å¼€æ”¾ç«¯å£"] = all_ports
    return info

def create_host_summary(host_arg, results, fields_list):
    info = get_common_host_info(results, fields_list)
    summary = [f"ğŸ“Œ *ä¸»æœºæ¦‚è§ˆ: `{host_arg}`*"]
    for key, value in info.items():
        if value and value != 'N/A':
            if isinstance(value, list):
                summary.append(f"*{key}:* `{', '.join(map(str, value))}`")
            else:
                summary.append(f"*{key}:* `{value}`")
    summary.append("\nğŸ“„ *è¯¦ç»†æŠ¥å‘Šå·²ä½œä¸ºæ–‡ä»¶å‘é€ã€‚*")
    return "\n".join(summary)

def format_full_host_report(host_arg, results, fields_list):
    info = get_common_host_info(results, fields_list)
    report = [f"ğŸ“Œ *ä¸»æœºèšåˆæŠ¥å‘Š: `{host_arg}`*\n"]
    for key, value in info.items():
        if value and value != 'N/A':
            if isinstance(value, list):
                report.append(f"*{key}:* `{', '.join(map(str, value))}`")
            else:
                report.append(f"*{key}:* `{value}`")

    report.append("\n--- *æœåŠ¡è¯¦æƒ…* ---\n")
    for res_list in results:
        d = _create_dict_from_fofa_result(res_list, fields_list)
        port_info = [f"ğŸŒ *Port `{d.get('port')}` ({d.get('protocol', 'N/A')})*"]
        if d.get('title'): port_info.append(f"  - *æ ‡é¢˜:* `{d.get('title')}`")
        if d.get('server'): port_info.append(f"  - *æœåŠ¡:* `{d.get('server')}`")
        if d.get('icp'): port_info.append(f"  - *ICP:* `{d.get('icp')}`")
        if d.get('jarm'): port_info.append(f"  - *JARM:* `{d.get('jarm')}`")
        
        cert_str = d.get('cert', '{}')
        try:
            cert_info = json.loads(cert_str) if isinstance(cert_str, str) and cert_str.startswith('{') else {}
            if cert_info.get('issuer', {}).get('CN'): port_info.append(f"  - *è¯ä¹¦é¢å‘è€…:* `{cert_info['issuer']['CN']}`")
            if cert_info.get('subject', {}).get('CN'): port_info.append(f"  - *è¯ä¹¦ä½¿ç”¨è€…:* `{cert_info['subject']['CN']}`")
        except json.JSONDecodeError:
            pass

        if d.get('header'): port_info.append(f"  - *Header:* ```\n{d.get('header')}\n```")
        if d.get('banner'): port_info.append(f"  - *Banner:* ```\n{d.get('banner')}\n```")
        report.append("\n".join(port_info))
    return "\n".join(report)

def host_command_logic(update: Update, context: CallbackContext, use_max_fields: bool):
    if not context.args:
        command_name = "/host" if use_max_fields else "/lowhost"
        update.message.reply_text(f"ç”¨æ³•: `{command_name} <ip_or_domain>`\n\nç¤ºä¾‹:\n`{command_name} 1.1.1.1`", parse_mode=ParseMode.MARKDOWN)
        return
    
    host_arg = context.args[0]
    processing_message = update.message.reply_text(f"â³ æ­£åœ¨æŸ¥è¯¢ä¸»æœº `{escape_markdown(host_arg)}`...")
    
    query = f'ip="{host_arg}"' if re.match(r"^\d{1,3}(\.\d{1,3}){3}$", host_arg) else f'domain="{host_arg}"'
    
    if use_max_fields:
        # æ™ºèƒ½é€‰æ‹©å­—æ®µ
        data, _, key_level, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query, page_size=1, fields="host"))
        if error:
            # v9.8 FIX: Removed unnecessary markdown escape for error message
            processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{error}`", parse_mode=ParseMode.MARKDOWN)
            return
        fields_list = get_fields_by_level(key_level)
        fields_str = ",".join(fields_list)
        data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query, page_size=100, fields=fields_str))
    else:
        # /lowhost, ä½¿ç”¨å…è´¹å­—æ®µ
        fields_list = FREE_FIELDS
        fields_str = ",".join(fields_list)
        data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query, page_size=100, fields=fields_str))

    if error:
        # v9.8 FIX: Removed unnecessary markdown escape for error message
        processing_message.edit_text(f"æŸ¥è¯¢å¤±è´¥ ğŸ˜\n*åŸå› :* `{error}`", parse_mode=ParseMode.MARKDOWN)
        return
    
    results = data.get('results', [])
    if not results:
        processing_message.edit_text(f"ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°å…³äº `{escape_markdown(host_arg)}` çš„ä»»ä½•ä¿¡æ¯ã€‚")
        return

    full_report = format_full_host_report(host_arg, results, fields_list)
    
    if len(full_report) > 3800:
        summary_report = create_host_summary(host_arg, results, fields_list)
        processing_message.edit_text(summary_report, parse_mode=ParseMode.MARKDOWN, disable_web_page_preview=True)
        report_filename = f"host_details_{host_arg.replace('.', '_')}.txt"
        try:
            plain_text_report = re.sub(r'([*_`\[\]])', '', full_report)
            with open(report_filename, 'w', encoding='utf-8') as f: f.write(plain_text_report)
            with open(report_filename, 'rb') as doc: context.bot.send_document(chat_id=update.effective_chat.id, document=doc, caption="ğŸ“„ å®Œæ•´çš„è¯¦ç»†æŠ¥å‘Šå·²é™„ä¸Šã€‚")
            upload_and_send_links(context, update.effective_chat.id, report_filename)
        finally:
            if os.path.exists(report_filename): os.remove(report_filename)
    else:
        processing_message.edit_text(full_report, parse_mode=ParseMode.MARKDOWN, disable_web_page_preview=True)

@admin_only
def host_command(update: Update, context: CallbackContext):
    host_command_logic(update, context, use_max_fields=True)

def lowhost_command(update: Update, context: CallbackContext):
    host_command_logic(update, context, use_max_fields=False)

# --- /stats å‘½ä»¤ (æ— å˜åŠ¨) ---
@admin_only
def stats_command(update: Update, context: CallbackContext):
    if not context.args:
        update.message.reply_text("è¯·è¾“å…¥è¦è¿›è¡Œèšåˆç»Ÿè®¡çš„FOFAæŸ¥è¯¢è¯­æ³•:")
        return STATE_GET_STATS_QUERY
    return get_fofa_stats_query(update, context)
def get_fofa_stats_query(update: Update, context: CallbackContext):
    query_text = " ".join(context.args) if context.args else update.message.text
    msg = update.message.reply_text(f"â³ æ­£åœ¨å¯¹ `{escape_markdown(query_text)}` è¿›è¡Œèšåˆç»Ÿè®¡...")
    data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_stats(key, query_text))
    if error: msg.edit_text(f"âŒ ç»Ÿè®¡å¤±è´¥: {error}"); return ConversationHandler.END
    report = [f"ğŸ“Š *èšåˆç»Ÿè®¡æŠ¥å‘Š for `{escape_markdown(query_text)}`*\n"]
    for field, aggs in data.items():
        if aggs:
            report.append(f"--- *{field.capitalize()}* ---")
            for item in aggs[:10]: # Top 10
                report.append(f"`{item['name']}`: {item['count']}")
            report.append("")
    msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN)
    return ConversationHandler.END

# --- /batchfind å‘½ä»¤ (æ— å˜åŠ¨) ---
BATCH_FEATURES = { "protocol": "åè®®", "domain": "åŸŸå", "os": "æ“ä½œç³»ç»Ÿ", "server": "æœåŠ¡/ç»„ä»¶", "icp": "ICPå¤‡æ¡ˆå·", "title": "æ ‡é¢˜", "jarm": "JARMæŒ‡çº¹", "cert.issuer.org": "è¯ä¹¦é¢å‘ç»„ç»‡", "cert.issuer.cn": "è¯ä¹¦é¢å‘CN", "cert.subject.org": "è¯ä¹¦ä¸»ä½“ç»„ç»‡", "cert.subject.cn": "è¯ä¹¦ä¸»ä½“CN" }
@admin_only
def batchfind_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·ä¸Šä¼ ä¸€ä¸ªåŒ…å« IP:Port åˆ—è¡¨çš„ .txt æ–‡ä»¶ã€‚")
    return STATE_GET_BATCH_FILE
def get_batch_file_handler(update: Update, context: CallbackContext):
    doc = update.message.document
    file = doc.get_file()
    file_path = os.path.join(FOFA_CACHE_DIR, doc.file_name)
    file.download(custom_path=file_path)
    context.user_data['batch_file_path'] = file_path
    context.user_data['selected_features'] = set()
    keyboard = []
    features_list = list(BATCH_FEATURES.items())
    for i in range(0, len(features_list), 2):
        row = [InlineKeyboardButton(f"â˜ {features_list[i][1]}", callback_data=f"batchfeature_{features_list[i][0]}")]
        if i + 1 < len(features_list):
            row.append(InlineKeyboardButton(f"â˜ {features_list[i+1][1]}", callback_data=f"batchfeature_{features_list[i+1][0]}"))
        keyboard.append(row)
    keyboard.append([InlineKeyboardButton("âœ… å…¨éƒ¨é€‰æ‹©", callback_data="batchfeature_all"), InlineKeyboardButton("â¡ï¸ å¼€å§‹åˆ†æ", callback_data="batchfeature_done")])
    update.message.reply_text("è¯·é€‰æ‹©æ‚¨éœ€è¦åˆ†æçš„ç‰¹å¾:", reply_markup=InlineKeyboardMarkup(keyboard))
    return STATE_SELECT_BATCH_FEATURES
def select_batch_features_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); feature = query.data.split('_', 1)[1]
    selected = context.user_data['selected_features']
    if feature == 'done':
        if not selected: query.answer("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾ï¼", show_alert=True); return STATE_SELECT_BATCH_FEATURES
        query.message.edit_text("âœ… ç‰¹å¾é€‰æ‹©å®Œæ¯•ï¼Œä»»åŠ¡å·²æäº¤åˆ°åå°åˆ†æã€‚")
        job_context = {'chat_id': query.message.chat_id, 'file_path': context.user_data['batch_file_path'], 'features': list(selected)}
        context.job_queue.run_once(run_batch_find_job, 1, context=job_context, name=f"batchfind_{query.message.chat_id}")
        return ConversationHandler.END
    if feature == 'all':
        if len(selected) == len(BATCH_FEATURES): selected.clear()
        else: selected.update(BATCH_FEATURES.keys())
    elif feature in selected: selected.remove(feature)
    else: selected.add(feature)
    keyboard = []
    features_list = list(BATCH_FEATURES.items())
    for i in range(0, len(features_list), 2):
        row = []
        key1 = features_list[i][0]; row.append(InlineKeyboardButton(f"{'â˜‘' if key1 in selected else 'â˜'} {features_list[i][1]}", callback_data=f"batchfeature_{key1}"))
        if i + 1 < len(features_list):
            key2 = features_list[i+1][0]; row.append(InlineKeyboardButton(f"{'â˜‘' if key2 in selected else 'â˜'} {features_list[i+1][1]}", callback_data=f"batchfeature_{key2}"))
        keyboard.append(row)
    all_text = "âœ… å–æ¶ˆå…¨é€‰" if len(selected) == len(BATCH_FEATURES) else "âœ… å…¨éƒ¨é€‰æ‹©"
    keyboard.append([InlineKeyboardButton(all_text, callback_data="batchfeature_all"), InlineKeyboardButton("â¡ï¸ å¼€å§‹åˆ†æ", callback_data="batchfeature_done")])
    query.message.edit_reply_markup(reply_markup=InlineKeyboardMarkup(keyboard))
    return STATE_SELECT_BATCH_FEATURES
def run_batch_find_job(context: CallbackContext):
    job_data = context.job.context; chat_id, file_path, features = job_data['chat_id'], job_data['file_path'], job_data['features']
    bot = context.bot; msg = bot.send_message(chat_id, "â³ å¼€å§‹æ‰¹é‡åˆ†æä»»åŠ¡...")
    try:
        with open(file_path, 'r', encoding='utf-8') as f: targets = [line.strip() for line in f if line.strip()]
    except Exception as e: msg.edit_text(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}"); return
    if not targets: msg.edit_text("âŒ æ–‡ä»¶ä¸ºç©ºã€‚"); return
    
    total_targets = len(targets); processed_count = 0; detailed_results_for_excel = []
    for target in targets:
        processed_count += 1
        if processed_count % 10 == 0:
            try: msg.edit_text(f"åˆ†æè¿›åº¦: {create_progress_bar(processed_count/total_targets*100)} ({processed_count}/{total_targets})")
            except (BadRequest, RetryAfter): pass
        query = f'ip="{target}"' if ':' not in target else f'host="{target}"'
        data, _, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query, page_size=1, fields=",".join(features)))
        if not error and data.get('results'):
            result = data['results'][0]
            row_data = {'Target': target}
            row_data.update({BATCH_FEATURES.get(f, f): result[i] for i, f in enumerate(features)})
            detailed_results_for_excel.append(row_data)
    
    if detailed_results_for_excel:
        try:
            df = pd.DataFrame(detailed_results_for_excel)
            excel_filename = generate_filename_from_query(os.path.basename(file_path), prefix="analysis", ext=".xlsx")
            df.to_excel(excel_filename, index=False, engine='openpyxl')
            msg.edit_text("âœ… åˆ†æå®Œæˆï¼æ­£åœ¨å‘é€ExcelæŠ¥å‘Š...")
            with open(excel_filename, 'rb') as doc:
                bot.send_document(chat_id=chat_id, document=doc, caption="ğŸ“„ è¯¦ç»†ç‰¹å¾åˆ†æExcelæŠ¥å‘Š")
            upload_and_send_links(context, chat_id, excel_filename)
            os.remove(excel_filename)
        except Exception as e: msg.edit_text(f"âŒ ç”ŸæˆExcelå¤±è´¥: {e}")
    else: msg.edit_text("ğŸ¤·â€â™€ï¸ åˆ†æå®Œæˆï¼Œä½†æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„FOFAæ•°æ®ã€‚")
    if os.path.exists(file_path): os.remove(file_path)

# --- /batch (äº¤äº’å¼) ---
def build_batch_fields_keyboard(user_data):
    selected_fields = user_data.get('selected_fields', set())
    page = user_data.get('page', 0)
    
    flat_fields = []
    for category, fields in FIELD_CATEGORIES.items():
        for field in fields:
            flat_fields.append((field, category))
            
    items_per_page = 12
    start_index = page * items_per_page
    end_index = start_index + items_per_page
    page_items = flat_fields[start_index:end_index]
    
    keyboard = []
    for i in range(0, len(page_items), 2):
        row = []
        field1, cat1 = page_items[i]
        prefix1 = "â˜‘ï¸" if field1 in selected_fields else "â˜"
        row.append(InlineKeyboardButton(f"{prefix1} {field1}", callback_data=f"batchfield_toggle_{field1}"))
        if i + 1 < len(page_items):
            field2, cat2 = page_items[i+1]
            prefix2 = "â˜‘ï¸" if field2 in selected_fields else "â˜"
            row.append(InlineKeyboardButton(f"{prefix2} {field2}", callback_data=f"batchfield_toggle_{field2}"))
        keyboard.append(row)
        
    nav_row = []
    if page > 0:
        nav_row.append(InlineKeyboardButton("â¬…ï¸ ä¸Šä¸€é¡µ", callback_data="batchfield_prev"))
    if end_index < len(flat_fields):
        nav_row.append(InlineKeyboardButton("ä¸‹ä¸€é¡µ â¡ï¸", callback_data="batchfield_next"))
    keyboard.append(nav_row)
    keyboard.append([InlineKeyboardButton("âœ… å®Œæˆé€‰æ‹©å¹¶å¼€å§‹", callback_data="batchfield_done")])
    
    return InlineKeyboardMarkup(keyboard)

@admin_only
def batch_command(update: Update, context: CallbackContext):
    if not context.args:
        update.message.reply_text("ç”¨æ³•: `/batch <fofa_query>`")
        return ConversationHandler.END
    
    query_text = " ".join(context.args)
    context.user_data['query'] = query_text
    context.user_data['selected_fields'] = set(FREE_FIELDS[:5]) # é»˜è®¤é€‰æ‹©å‰5ä¸ªå…è´¹å­—æ®µ
    context.user_data['page'] = 0
    
    keyboard = build_batch_fields_keyboard(context.user_data)
    update.message.reply_text(f"æŸ¥è¯¢: `{query_text}`\nè¯·é€‰æ‹©è¦å¯¼å‡ºçš„å­—æ®µ:", reply_markup=keyboard, parse_mode=ParseMode.MARKDOWN)
    return STATE_BATCH_SELECT_FIELDS

def batch_select_fields_callback(update: Update, context: CallbackContext):
    query = update.callback_query
    query.answer()
    
    action = query.data.split('_', 1)[1]
    
    if action == "next":
        context.user_data['page'] += 1
    elif action == "prev":
        context.user_data['page'] -= 1
    elif action.startswith("toggle_"):
        field = action.replace("toggle_", "")
        if field in context.user_data['selected_fields']:
            context.user_data['selected_fields'].remove(field)
        else:
            context.user_data['selected_fields'].add(field)
    elif action == "done":
        selected_fields = context.user_data.get('selected_fields')
        if not selected_fields:
            query.answer("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå­—æ®µï¼", show_alert=True)
            return STATE_BATCH_SELECT_FIELDS
        
        query_text = context.user_data['query']
        fields_str = ",".join(list(selected_fields))
        
        msg = query.message.edit_text("æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢ä»¥é¢„ä¼°æ•°æ®é‡...")
        data, used_key_index, key_level, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page_size=1, fields="host"))
        if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
        
        total_size = data.get('size', 0)
        if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
        
        # æ£€æŸ¥æ‰€é€‰å­—æ®µæ˜¯å¦è¶…å‡ºKeyçš„æƒé™
        allowed_fields = get_fields_by_level(key_level)
        unauthorized_fields = [f for f in selected_fields if f not in allowed_fields]
        if unauthorized_fields:
            msg.edit_text(f"âš ï¸ è­¦å‘Š: æ‚¨é€‰æ‹©çš„å­—æ®µ `{', '.join(unauthorized_fields)}` è¶…å‡ºå½“å‰å¯ç”¨æœ€é«˜çº§Key (ç­‰çº§{key_level}) çš„æƒé™ã€‚è¯·é‡æ–°é€‰æ‹©æˆ–å‡çº§Keyã€‚")
            return ConversationHandler.END

        context.user_data.update({'chat_id': update.effective_chat.id, 'fields': fields_str, 'total_size': total_size, 'is_batch_mode': True })
        success_message = f"âœ… ä½¿ç”¨ Key [#{used_key_index}] (ç­‰çº§{key_level}) æ‰¾åˆ° {total_size} æ¡ç»“æœã€‚"
        
        if total_size <= 10000:
            msg.edit_text(f"{success_message}\nå¼€å§‹è‡ªå®šä¹‰å­—æ®µæ‰¹é‡å¯¼å‡º..."); start_download_job(context, run_batch_download_query, context.user_data)
            return ConversationHandler.END
        else:
            keyboard = [[InlineKeyboardButton("ğŸ’ å¯¼å‡ºå‰1ä¸‡æ¡", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯å¯¼å‡º", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
            msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©å¯¼å‡ºæ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard)); return STATE_KKFOFA_MODE
            
    keyboard = build_batch_fields_keyboard(context.user_data)
    query.message.edit_reply_markup(reply_markup=keyboard)
    return STATE_BATCH_SELECT_FIELDS

# --- å…¶ä»–ç®¡ç†å‘½ä»¤ (æ— å˜åŠ¨) ---
@admin_only
def check_command(update: Update, context: CallbackContext):
    msg = update.message.reply_text("â³ æ­£åœ¨æ‰§è¡Œç³»ç»Ÿè‡ªæ£€...")
    report = ["*ğŸ“‹ ç³»ç»Ÿè‡ªæ£€æŠ¥å‘Š*"]
    try:
        global CONFIG; CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
        report.append("âœ… *é…ç½®æ–‡ä»¶*: `config.json` åŠ è½½æ­£å¸¸")
    except Exception as e:
        report.append(f"âŒ *é…ç½®æ–‡ä»¶*: åŠ è½½å¤±è´¥ - {escape_markdown(str(e))}")
        msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN); return
    report.append("\n*ğŸ”‘ API Keys:*")
    if not CONFIG.get('apis'): report.append("  - âš ï¸ æœªé…ç½®ä»»ä½• API Key")
    else:
        for i, key in enumerate(CONFIG['apis']):
            level = KEY_LEVELS.get(key, -1)
            level_name = {-1: "âŒ æ— æ•ˆ", 0: "âœ… å…è´¹", 1: "âœ… ä¸ªäºº", 2: "âœ… å•†ä¸š", 3: "âœ… ä¼ä¸š"}.get(level, "æœªçŸ¥")
            report.append(f"  `#{i+1}` (`...{key[-4:]}`): {level_name}")
            
    report.append("\n*ğŸŒ ä»£ç†:*")
    proxies_to_check = CONFIG.get("proxies", [])
    if not proxies_to_check and CONFIG.get("proxy"): proxies_to_check.append(CONFIG.get("proxy"))
    if not proxies_to_check: report.append("  - â„¹ï¸ æœªé…ç½®ä»£ç†")
    else:
        for p in proxies_to_check:
            try:
                requests.get("https://fofa.info", proxies={"http": p, "https": p}, timeout=10, verify=False)
                report.append(f"  - `{escape_markdown(p)}`: âœ… è¿æ¥æˆåŠŸ")
            except Exception as e: report.append(f"  - `{escape_markdown(p)}`: âŒ è¿æ¥å¤±è´¥ - `{escape_markdown(str(e))}`")
    msg.edit_text("\n".join(report), parse_mode=ParseMode.MARKDOWN)
@admin_only
def stop_all_tasks(update: Update, context: CallbackContext):
    chat_id = update.effective_chat.id
    context.bot_data[f'stop_job_{chat_id}'] = True
    update.message.reply_text("ğŸ›‘ å·²å‘é€åœæ­¢ä¿¡å·ï¼Œå½“å‰ä¸‹è½½ä»»åŠ¡å°†åœ¨å®Œæˆæœ¬é¡µååœæ­¢ã€‚")
@admin_only
def backup_config_command(update: Update, context: CallbackContext):
    if os.path.exists(CONFIG_FILE):
        update.effective_chat.send_document(document=open(CONFIG_FILE, 'rb'))
        upload_and_send_links(context, update.effective_chat.id, CONFIG_FILE)
    else: update.effective_chat.send_message("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ã€‚")
@admin_only
def restore_config_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·å‘é€æ‚¨çš„ `config.json` å¤‡ä»½æ–‡ä»¶ã€‚")
    return STATE_GET_RESTORE_FILE
def receive_config_file(update: Update, context: CallbackContext):
    doc = update.message.document
    if doc.file_name != 'config.json':
        update.message.reply_text("âŒ æ–‡ä»¶åé”™è¯¯ï¼Œè¯·ç¡®ä¿æ‚¨ä¸Šä¼ çš„æ˜¯ `config.json`ã€‚")
        return ConversationHandler.END
    file = doc.get_file()
    file.download(custom_path=CONFIG_FILE)
    global CONFIG; CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)
    update.message.reply_text("âœ… é…ç½®æ–‡ä»¶å·²æ¢å¤ã€‚æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ä»¥åº”ç”¨æ›´æ”¹ã€‚")
    shutdown_command(update, context, restart=True)
    return ConversationHandler.END
@admin_only
def history_command(update: Update, context: CallbackContext):
    if not HISTORY['queries']: update.message.reply_text("æŸ¥è¯¢å†å²ä¸ºç©ºã€‚"); return
    history_text = "*ğŸ•°ï¸ æœ€è¿‘æŸ¥è¯¢å†å²*\n\n"
    for i, item in enumerate(HISTORY['queries'][:15]):
        dt_utc = datetime.fromisoformat(item['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        history_text += f"`{i+1}.` `{escape_markdown(item['query_text'])}`\n   _{time_str}_\n"
    update.message.reply_text(history_text, parse_mode=ParseMode.MARKDOWN)
@admin_only
def import_command(update: Update, context: CallbackContext):
    update.message.reply_text("è¯·å‘é€æ‚¨è¦å¯¼å…¥çš„æ—§ç¼“å­˜æ–‡ä»¶ (txtæ ¼å¼)ã€‚")
    return STATE_GET_IMPORT_QUERY
def get_import_query(update: Update, context: CallbackContext):
    doc = update.message.document
    if not doc.file_name.endswith('.txt'): update.message.reply_text("âŒ è¯·ä¸Šä¼  .txt æ–‡ä»¶ã€‚"); return ConversationHandler.END
    file = doc.get_file()
    temp_path = os.path.join(FOFA_CACHE_DIR, f"import_{doc.file_id}.txt")
    file.download(custom_path=temp_path)
    try:
        with open(temp_path, 'r', encoding='utf-8') as f: result_count = sum(1 for _ in f)
    except Exception as e: update.message.reply_text(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}"); os.remove(temp_path); return ConversationHandler.END
    query_text = update.message.text
    if not query_text: update.message.reply_text("è¯·è¾“å…¥ä¸æ­¤æ–‡ä»¶å…³è”çš„åŸå§‹FOFAæŸ¥è¯¢è¯­æ³•:"); return STATE_GET_IMPORT_QUERY
    
    final_filename = generate_filename_from_query(query_text)
    final_path = os.path.join(FOFA_CACHE_DIR, final_filename)
    shutil.move(temp_path, final_path)
    
    cache_data = {'file_path': final_path, 'result_count': result_count}
    add_or_update_query(query_text, cache_data)
    update.message.reply_text(f"âœ… æˆåŠŸå¯¼å…¥ç¼“å­˜ï¼\næŸ¥è¯¢: `{escape_markdown(query_text)}`\nå…± {result_count} æ¡è®°å½•ã€‚")
    return ConversationHandler.END
@admin_only
def get_log_command(update: Update, context: CallbackContext):
    if os.path.exists(LOG_FILE):
        update.message.reply_document(document=open(LOG_FILE, 'rb'))
        upload_and_send_links(context, update.effective_chat.id, LOG_FILE)
    else: update.message.reply_text("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚")
@admin_only
def shutdown_command(update: Update, context: CallbackContext, restart=False):
    message = "ğŸ¤– æœºå™¨äººæ­£åœ¨é‡å¯..." if restart else "ğŸ¤– æœºå™¨äººæ­£åœ¨å…³é—­..."
    update.message.reply_text(message)
    logger.info(f"Shutdown/Restart initiated by user {update.effective_user.id}")
    
    updater = context.bot_data.get('updater')
    if not updater:
        logger.error("Could not find updater object in bot_data for shutdown!")
        update.message.reply_text("âŒ å†…éƒ¨é”™è¯¯: æ— æ³•æ‰¾åˆ°æ ¸å¿ƒç»„ä»¶ï¼Œæ— æ³•å…³é—­ã€‚")
        return

    context.job_queue.stop()
    updater.stop()
    
    if restart:
        try:
            os.execv(sys.executable, [sys.executable] + sys.argv)
        except Exception as e:
            logger.error(f"é‡å¯å¤±è´¥: {e}")
            update.message.reply_text(f"âŒ é‡å¯å¤±è´¥: {e}")
@admin_only
def update_script_command(update: Update, context: CallbackContext):
    update_url = CONFIG.get("update_url")
    if not update_url:
        update.message.reply_text("âŒ æœªåœ¨è®¾ç½®ä¸­é…ç½®æ›´æ–°URLã€‚è¯·ä½¿ç”¨ /settings -> è„šæœ¬æ›´æ–° -> è®¾ç½®URLã€‚")
        return
    msg = update.message.reply_text("â³ æ­£åœ¨ä»è¿œç¨‹URLä¸‹è½½æ–°è„šæœ¬...")
    try:
        response = requests.get(update_url, timeout=30, proxies=get_proxies())
        response.raise_for_status()
        script_content = response.text
        with open(__file__, 'w', encoding='utf-8') as f:
            f.write(script_content)
        msg.edit_text("âœ… è„šæœ¬æ›´æ–°æˆåŠŸï¼æœºå™¨äººå°†è‡ªåŠ¨é‡å¯ä»¥åº”ç”¨æ–°ç‰ˆæœ¬ã€‚")
        shutdown_command(update, context, restart=True)
    except Exception as e:
        msg.edit_text(f"âŒ æ›´æ–°å¤±è´¥: {e}")

# --- è®¾ç½®èœå• (æ— å˜åŠ¨) ---
@admin_only
def settings_command(update: Update, context: CallbackContext):
    keyboard = [
        [InlineKeyboardButton("ğŸ”‘ API ç®¡ç†", callback_data='settings_api'), InlineKeyboardButton("âœ¨ é¢„è®¾ç®¡ç†", callback_data='settings_preset')],
        [InlineKeyboardButton("ğŸŒ ä»£ç†æ± ç®¡ç†", callback_data='settings_proxypool'), InlineKeyboardButton("ğŸ“¤ ä¸Šä¼ æ¥å£è®¾ç½®", callback_data='settings_upload')],
        [InlineKeyboardButton("ğŸ’¾ å¤‡ä»½ä¸æ¢å¤", callback_data='settings_backup'), InlineKeyboardButton("ğŸ”„ è„šæœ¬æ›´æ–°", callback_data='settings_update')],
        [InlineKeyboardButton("âŒ å…³é—­èœå•", callback_data='settings_close')]
    ]
    message_text = "âš™ï¸ *è®¾ç½®èœå•*"; reply_markup = InlineKeyboardMarkup(keyboard)
    if update.callback_query: update.callback_query.message.edit_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    else: update.message.reply_text(message_text, reply_markup=reply_markup, parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_MAIN
def settings_callback_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); menu = query.data.split('_', 1)[1]
    if menu == 'api': return show_api_menu(update, context, force_check=False)
    if menu == 'proxypool': return show_proxypool_menu(update, context)
    if menu == 'backup': return show_backup_restore_menu(update, context)
    if menu == 'preset': return show_preset_menu(update, context)
    if menu == 'update': return show_update_menu(update, context)
    if menu == 'upload': return show_upload_api_menu(update, context)
    if menu == 'close': query.message.edit_text("èœå•å·²å…³é—­."); return ConversationHandler.END
    return STATE_SETTINGS_ACTION
def settings_action_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'add_api': query.message.edit_text("è¯·è¾“å…¥æ–°çš„FOFA API Key:"); return STATE_GET_KEY
    if action == 'remove_api': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„API Keyçš„ç¼–å·:"); return STATE_REMOVE_API
    if action == 'check_api': return show_api_menu(update, context, force_check=True)
    if action == 'back': return settings_command(update, context)
def show_api_menu(update: Update, context: CallbackContext, force_check=False):
    query = update.callback_query
    if force_check: 
        query.message.edit_text("â³ æ­£åœ¨é‡æ–°æ£€æŸ¥æ‰€æœ‰API KeyçŠ¶æ€...")
        check_and_classify_keys() # å¼ºåˆ¶æ£€æŸ¥æ—¶é‡æ–°åˆ†ç±»
    api_list_text = ["*ğŸ”‘ å½“å‰ API Keys:*"]
    if not CONFIG['apis']: api_list_text.append("  - _ç©º_")
    else:
        for i, key in enumerate(CONFIG['apis']):
            level = KEY_LEVELS.get(key, -1)
            level_name = {-1: "âŒ æ— æ•ˆ", 0: "âœ… å…è´¹", 1: "âœ… ä¸ªäºº", 2: "âœ… å•†ä¸š", 3: "âœ… ä¼ä¸š"}.get(level, "æœªçŸ¥")
            api_list_text.append(f"  `#{i+1}` `...{key[-4:]}` - {level_name}")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='action_add_api'), InlineKeyboardButton("â– ç§»é™¤", callback_data='action_remove_api')],
        [InlineKeyboardButton("ğŸ”„ çŠ¶æ€æ£€æŸ¥", callback_data='action_check_api'), InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='action_back')]
    ]
    query.message.edit_text("\n".join(api_list_text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_ACTION
def get_key(update: Update, context: CallbackContext):
    new_key = update.message.text.strip()
    if new_key not in CONFIG['apis']: 
        CONFIG['apis'].append(new_key); save_config()
        check_and_classify_keys() # æ·»åŠ åç«‹å³åˆ†ç±»
        update.message.reply_text("âœ… API Key å·²æ·»åŠ ã€‚")
    else: update.message.reply_text("âš ï¸ æ­¤ Key å·²å­˜åœ¨ã€‚")
    return settings_command(update, context)
def remove_api(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['apis']):
            removed_key = CONFIG['apis'].pop(index); save_config()
            check_and_classify_keys() # ç§»é™¤åé‡æ–°åˆ†ç±»
            update.message.reply_text(f"âœ… å·²ç§»é™¤ Key `...{removed_key[-4:]}`ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def show_preset_menu(update: Update, context: CallbackContext):
    query = update.callback_query; presets = CONFIG.get("presets", [])
    text = ["*âœ¨ é¢„è®¾æŸ¥è¯¢ç®¡ç†*"]
    if not presets: text.append("  - _ç©º_")
    else:
        for i, p in enumerate(presets): text.append(f"`{i+1}.` *{p['name']}*: `{p['query']}`")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='preset_add'), InlineKeyboardButton("â– ç§»é™¤", callback_data='preset_remove')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='preset_back')]
    ]
    query.message.edit_text("\n".join(text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_PRESET_MENU
def preset_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_')[1]
    if action == 'add': query.message.edit_text("è¯·è¾“å…¥é¢„è®¾çš„åç§°:"); return STATE_GET_PRESET_NAME
    if action == 'remove': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„é¢„è®¾çš„ç¼–å·:"); return STATE_REMOVE_PRESET
    if action == 'back': return settings_command(update, context)
def get_preset_name(update: Update, context: CallbackContext):
    context.user_data['preset_name'] = update.message.text.strip()
    update.message.reply_text("è¯·è¾“å…¥æ­¤é¢„è®¾çš„FOFAæŸ¥è¯¢è¯­æ³•:")
    return STATE_GET_PRESET_QUERY
def get_preset_query(update: Update, context: CallbackContext):
    preset_query = update.message.text.strip(); preset_name = context.user_data['preset_name']
    CONFIG.setdefault("presets", []).append({"name": preset_name, "query": preset_query}); save_config()
    update.message.reply_text("âœ… é¢„è®¾å·²æ·»åŠ ã€‚")
    return settings_command(update, context)
def remove_preset(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['presets']):
            CONFIG['presets'].pop(index); save_config()
            update.message.reply_text("âœ… é¢„è®¾å·²ç§»é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def show_update_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    url = CONFIG.get("update_url") or "æœªè®¾ç½®"
    text = f"ğŸ”„ *è„šæœ¬æ›´æ–°è®¾ç½®*\n\nå½“å‰æ›´æ–°URL: `{escape_markdown(url)}`"
    keyboard = [[InlineKeyboardButton("âœï¸ è®¾ç½®URL", callback_data='update_set_url'), InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='update_back')]]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_ACTION
def get_update_url(update: Update, context: CallbackContext):
    url = update.message.text.strip()
    if url.lower().startswith('http'): CONFIG['update_url'] = url; save_config(); update.message.reply_text("âœ… æ›´æ–°URLå·²è®¾ç½®ã€‚")
    else: update.message.reply_text("âŒ æ— æ•ˆçš„URLæ ¼å¼ã€‚")
    return settings_command(update, context)
def show_backup_restore_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    text = "ğŸ’¾ *å¤‡ä»½ä¸æ¢å¤*\n\n- *å¤‡ä»½*: å‘é€å½“å‰çš„ `config.json` æ–‡ä»¶ç»™æ‚¨ã€‚\n- *æ¢å¤*: æ‚¨éœ€è¦å‘æœºå™¨äººå‘é€ä¸€ä¸ª `config.json` æ–‡ä»¶æ¥è¦†ç›–å½“å‰é…ç½®ã€‚"
    keyboard = [[InlineKeyboardButton("ğŸ“¤ å¤‡ä»½", callback_data='backup_now'), InlineKeyboardButton("ğŸ“¥ æ¢å¤", callback_data='restore_now')], [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='backup_back')]]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_ACTION
def show_proxypool_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    proxies = CONFIG.get("proxies", [])
    text = ["*ğŸŒ ä»£ç†æ± ç®¡ç†*"]
    if not proxies: text.append("  - _ç©º_")
    else:
        for i, p in enumerate(proxies): text.append(f"`{i+1}.` `{p}`")
    keyboard = [
        [InlineKeyboardButton("â• æ·»åŠ ", callback_data='proxypool_add'), InlineKeyboardButton("â– ç§»é™¤", callback_data='proxypool_remove')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='proxypool_back')]
    ]
    query.message.edit_text("\n".join(text), reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_PROXYPOOL_MENU
def proxypool_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_')[1]
    if action == 'add': query.message.edit_text("è¯·è¾“å…¥è¦æ·»åŠ çš„ä»£ç† (æ ¼å¼: `http://user:pass@host:port`):"); return STATE_GET_PROXY_ADD
    if action == 'remove': query.message.edit_text("è¯·è¾“å…¥è¦ç§»é™¤çš„ä»£ç†çš„ç¼–å·:"); return STATE_GET_PROXY_REMOVE
    if action == 'back': return settings_command(update, context)
def get_proxy_to_add(update: Update, context: CallbackContext):
    proxy = update.message.text.strip()
    if proxy not in CONFIG['proxies']: CONFIG['proxies'].append(proxy); save_config(); update.message.reply_text("âœ… ä»£ç†å·²æ·»åŠ ã€‚")
    else: update.message.reply_text("âš ï¸ æ­¤ä»£ç†å·²å­˜åœ¨ã€‚")
    return settings_command(update, context)
def get_proxy_to_remove(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text.strip()) - 1
        if 0 <= index < len(CONFIG['proxies']):
            CONFIG['proxies'].pop(index); save_config()
            update.message.reply_text("âœ… ä»£ç†å·²ç§»é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆçš„ç¼–å·ã€‚")
    except ValueError: update.message.reply_text("âŒ è¯·è¾“å…¥ä¸€ä¸ªæœ‰æ•ˆçš„æ•°å­—ç¼–å·ã€‚")
    return settings_command(update, context)
def show_upload_api_menu(update: Update, context: CallbackContext):
    query = update.callback_query
    url = CONFIG.get("upload_api_url") or "æœªè®¾ç½®"
    token_status = "å·²è®¾ç½®" if CONFIG.get("upload_api_token") else "æœªè®¾ç½®"
    text = (f"ğŸ“¤ *ä¸Šä¼ æ¥å£è®¾ç½®*\n\n"
            f"æ­¤åŠŸèƒ½å¯å°†æœºå™¨äººç”Ÿæˆçš„æ‰€æœ‰æ–‡ä»¶è‡ªåŠ¨ä¸Šä¼ åˆ°æ‚¨æŒ‡å®šçš„æœåŠ¡å™¨ï¼Œå¹¶è¿”å›ä¸‹è½½å‘½ä»¤ã€‚\n\n"
            f"*API URL:* `{escape_markdown(url)}`\n"
            f"*API Token:* `{token_status}`")
    kbd = [
        [InlineKeyboardButton("âœï¸ è®¾ç½® URL", callback_data='upload_set_url'), InlineKeyboardButton("ğŸ”‘ è®¾ç½® Token", callback_data='upload_set_token')],
        [InlineKeyboardButton("ğŸ”™ è¿”å›", callback_data='upload_back')]
    ]
    query.message.edit_text(text, reply_markup=InlineKeyboardMarkup(kbd), parse_mode=ParseMode.MARKDOWN)
    return STATE_UPLOAD_API_MENU
def upload_api_menu_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back': return settings_command(update, context)
    if action == 'set_url': query.message.edit_text("è¯·è¾“å…¥æ‚¨çš„ä¸Šä¼ æ¥å£ URL:"); return STATE_GET_UPLOAD_URL
    if action == 'set_token': query.message.edit_text("è¯·è¾“å…¥æ‚¨çš„ä¸Šä¼ æ¥å£ Token:"); return STATE_GET_UPLOAD_TOKEN
    return STATE_UPLOAD_API_MENU
def get_upload_url(update: Update, context: CallbackContext):
    url = update.message.text.strip()
    if url.lower().startswith('http'):
        CONFIG['upload_api_url'] = url; save_config()
        update.message.reply_text("âœ… ä¸Šä¼  URL å·²æ›´æ–°ã€‚")
    else: update.message.reply_text("âŒ æ— æ•ˆçš„ URL æ ¼å¼ã€‚")
    return settings_command(update, context)
def get_upload_token(update: Update, context: CallbackContext):
    token = update.message.text.strip()
    CONFIG['upload_api_token'] = token; save_config()
    update.message.reply_text("âœ… ä¸Šä¼  Token å·²æ›´æ–°ã€‚")
    return settings_command(update, context)

# --- ä¸»å‡½æ•°ä¸è°ƒåº¦å™¨ ---
def main() -> None:
    global CONFIG
    os.makedirs(FOFA_CACHE_DIR, exist_ok=True)
    if not os.path.exists(CONFIG_FILE) or CONFIG.get("bot_token") == "YOUR_BOT_TOKEN_HERE":
        print("--- é¦–æ¬¡è¿è¡Œæˆ–é…ç½®ä¸å®Œæ•´ï¼Œè¿›å…¥äº¤äº’å¼è®¾ç½® ---")
        bot_token = input("è¯·è¾“å…¥æ‚¨çš„ Telegram Bot Token: ").strip()
        admin_id = input("è¯·è¾“å…¥æ‚¨çš„ Telegram User ID (ä½œä¸ºç¬¬ä¸€ä¸ªç®¡ç†å‘˜): ").strip()
        if not bot_token or not admin_id.isdigit(): print("é”™è¯¯ï¼šBot Token å’Œ Admin ID ä¸èƒ½ä¸ºç©ºä¸”IDå¿…é¡»æ˜¯æ•°å­—ã€‚è¯·é‡æ–°è¿è¡Œè„šæœ¬ã€‚"); sys.exit(1)
        CONFIG["bot_token"] = bot_token; CONFIG["admins"] = [int(admin_id)]
        fofa_keys = []; print("è¯·è¾“å…¥æ‚¨çš„ FOFA API Key (è¾“å…¥ç©ºè¡Œç»“æŸ):")
        while True:
            key = input(f"  - Key #{len(fofa_keys) + 1}: ").strip()
            if not key: break
            fofa_keys.append(key)
        CONFIG["apis"] = fofa_keys
        save_config(); print("âœ… é…ç½®å·²ä¿å­˜åˆ° config.jsonã€‚æ­£åœ¨å¯åŠ¨æœºå™¨äºº...")
        CONFIG = load_json_file(CONFIG_FILE, DEFAULT_CONFIG)

    bot_token = CONFIG.get("bot_token")
    if not bot_token or bot_token == "YOUR_BOT_TOKEN_HERE": logger.critical("é”™è¯¯: 'bot_token' æœªåœ¨ config.json ä¸­è®¾ç½®!"); return
    
    check_and_classify_keys() # å¯åŠ¨æ—¶åˆ†ç±»Key
    
    persistence = PicklePersistence(filename=PERSISTENCE_FILE)
    updater = Updater(token=bot_token, use_context=True, persistence=persistence)
    dispatcher = updater.dispatcher
    dispatcher.bot_data['updater'] = updater
    
    commands = [
        BotCommand("start", "ğŸš€ å¯åŠ¨æœºå™¨äºº"), BotCommand("help", "â“ å‘½ä»¤æ‰‹å†Œ"),
        BotCommand("kkfofa", "ğŸ” èµ„äº§æœç´¢/é¢„è®¾"), BotCommand("host", "ğŸ“¦ ä¸»æœºè¯¦æŸ¥ (æ™ºèƒ½)"),
        BotCommand("lowhost", "ğŸ”¬ ä¸»æœºé€ŸæŸ¥ (å¼€æ”¾)"), BotCommand("stats", "ğŸ“Š å…¨å±€èšåˆç»Ÿè®¡"),
        BotCommand("batchfind", "ğŸ“‚ æ‰¹é‡æ™ºèƒ½åˆ†æ (Excel)"), BotCommand("batch", "ğŸ“¤ æ‰¹é‡è‡ªå®šä¹‰å¯¼å‡º (äº¤äº’å¼)"),
        BotCommand("check", "ğŸ©º ç³»ç»Ÿè‡ªæ£€"), BotCommand("settings", "âš™ï¸ è®¾ç½®èœå•"),
        BotCommand("history", "ğŸ•°ï¸ æŸ¥è¯¢å†å²"), BotCommand("import", "ğŸ–‡ï¸ å¯¼å…¥æ—§ç¼“å­˜"),
        BotCommand("backup", "ğŸ“¤ å¤‡ä»½é…ç½®"), BotCommand("restore", "ğŸ“¥ æ¢å¤é…ç½®"),
        BotCommand("update", "ğŸ”„ åœ¨çº¿æ›´æ–°è„šæœ¬"), BotCommand("getlog", "ğŸ“„ è·å–æ—¥å¿—"),
        BotCommand("shutdown", "ğŸ”Œ å…³é—­æœºå™¨äºº"), BotCommand("stop", "ğŸ›‘ åœæ­¢ä»»åŠ¡"),
        BotCommand("cancel", "âŒ å–æ¶ˆæ“ä½œ")
    ]
    try: updater.bot.set_my_commands(commands)
    except Exception as e: logger.warning(f"è®¾ç½®æœºå™¨äººå‘½ä»¤å¤±è´¥: {e}")

    settings_conv = ConversationHandler(
        entry_points=[CommandHandler("settings", settings_command)],
        states={
            STATE_SETTINGS_MAIN: [CallbackQueryHandler(settings_callback_handler, pattern=r"^settings_")],
            STATE_SETTINGS_ACTION: [
                CallbackQueryHandler(settings_action_handler, pattern=r"^action_"),
                CallbackQueryHandler(show_update_menu, pattern=r"^settings_update"),
                CallbackQueryHandler(show_backup_restore_menu, pattern=r"^settings_backup"),
                CallbackQueryHandler(lambda u,c: backup_config_command(u.callback_query, c), pattern=r"^backup_now"),
                CallbackQueryHandler(lambda u,c: restore_config_command(u.callback_query.message, c), pattern=r"^restore_now"),
                CallbackQueryHandler(get_update_url, pattern=r"^update_set_url"),
                CallbackQueryHandler(settings_command, pattern=r"^(update_back|backup_back)"),
            ],
            STATE_GET_KEY: [MessageHandler(Filters.text & ~Filters.command, get_key)],
            STATE_REMOVE_API: [MessageHandler(Filters.text & ~Filters.command, remove_api)],
            STATE_PRESET_MENU: [CallbackQueryHandler(preset_menu_callback, pattern=r"^preset_")],
            STATE_GET_PRESET_NAME: [MessageHandler(Filters.text & ~Filters.command, get_preset_name)],
            STATE_GET_PRESET_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_preset_query)],
            STATE_REMOVE_PRESET: [MessageHandler(Filters.text & ~Filters.command, remove_preset)],
            STATE_GET_UPDATE_URL: [MessageHandler(Filters.text & ~Filters.command, get_update_url)],
            STATE_PROXYPOOL_MENU: [CallbackQueryHandler(proxypool_menu_callback, pattern=r"^proxypool_")],
            STATE_GET_PROXY_ADD: [MessageHandler(Filters.text & ~Filters.command, get_proxy_to_add)],
            STATE_GET_PROXY_REMOVE: [MessageHandler(Filters.text & ~Filters.command, get_proxy_to_remove)],
            STATE_UPLOAD_API_MENU: [CallbackQueryHandler(upload_api_menu_callback, pattern=r"^upload_")],
            STATE_GET_UPLOAD_URL: [MessageHandler(Filters.text & ~Filters.command, get_upload_url)],
            STATE_GET_UPLOAD_TOKEN: [MessageHandler(Filters.text & ~Filters.command, get_upload_token)],
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300,
        persistent=True, name="settings_conv"
    )
    kkfofa_conv = ConversationHandler(
        entry_points=[ CommandHandler("kkfofa", kkfofa_entry), CallbackQueryHandler(kkfofa_entry, pattern=r"^run_preset_") ],
        states={
            STATE_GET_GUEST_KEY: [MessageHandler(Filters.text & ~Filters.command, get_guest_key)],
            STATE_ASK_CONTINENT: [CallbackQueryHandler(ask_continent_callback, pattern=r"^continent_")], 
            STATE_CONTINENT_CHOICE: [CallbackQueryHandler(continent_choice_callback, pattern=r"^continent_")], 
            STATE_CACHE_CHOICE: [CallbackQueryHandler(cache_choice_callback, pattern=r"^cache_")],
            STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
            STATE_GET_TRACEBACK_LIMIT: [MessageHandler(Filters.text & ~Filters.command, get_traceback_limit), CallbackQueryHandler(get_traceback_limit, pattern=r"^limit_")]
        },
        fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300,
        persistent=True, name="kkfofa_conv"
    )
    batch_conv = ConversationHandler(
        entry_points=[CommandHandler("batch", batch_command)], 
        states={
            STATE_BATCH_SELECT_FIELDS: [CallbackQueryHandler(batch_select_fields_callback, pattern=r"^batchfield_")],
            STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
            STATE_GET_TRACEBACK_LIMIT: [MessageHandler(Filters.text & ~Filters.command, get_traceback_limit), CallbackQueryHandler(get_traceback_limit, pattern=r"^limit_")]
        },
        fallbacks=[CommandHandler('cancel', cancel)], conversation_timeout=600,
        persistent=True, name="batch_conv"
    )
    import_conv = ConversationHandler(entry_points=[CommandHandler("import", import_command)], states={STATE_GET_IMPORT_QUERY: [MessageHandler(Filters.document.mime_type("text/plain"), get_import_query)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300, persistent=True, name="import_conv")
    stats_conv = ConversationHandler(entry_points=[CommandHandler("stats", stats_command)], states={STATE_GET_STATS_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_fofa_stats_query)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300, persistent=True, name="stats_conv")
    batchfind_conv = ConversationHandler(entry_points=[CommandHandler("batchfind", batchfind_command)], states={STATE_GET_BATCH_FILE: [MessageHandler(Filters.document.mime_type("text/plain"), get_batch_file_handler)], STATE_SELECT_BATCH_FEATURES: [CallbackQueryHandler(select_batch_features_callback, pattern=r"^batchfeature_")]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300, persistent=True, name="batchfind_conv")
    restore_conv = ConversationHandler(entry_points=[CommandHandler("restore", restore_config_command)], states={STATE_GET_RESTORE_FILE: [MessageHandler(Filters.document, receive_config_file)]}, fallbacks=[CommandHandler("cancel", cancel)], conversation_timeout=300, persistent=True, name="restore_conv")
    scan_conv = ConversationHandler(entry_points=[CallbackQueryHandler(start_scan_callback, pattern=r'^start_scan_')], states={STATE_GET_SCAN_CONCURRENCY: [MessageHandler(Filters.text & ~Filters.command, get_concurrency_callback)], STATE_GET_SCAN_TIMEOUT: [MessageHandler(Filters.text & ~Filters.command, get_timeout_callback)]}, fallbacks=[CommandHandler('cancel', cancel)], conversation_timeout=120, persistent=True, name="scan_conv")

    dispatcher.add_handler(CommandHandler("start", start_command)); dispatcher.add_handler(CommandHandler("help", help_command)); dispatcher.add_handler(CommandHandler("host", host_command)); dispatcher.add_handler(CommandHandler("lowhost", lowhost_command)); dispatcher.add_handler(CommandHandler("check", check_command)); dispatcher.add_handler(CommandHandler("stop", stop_all_tasks)); dispatcher.add_handler(CommandHandler("backup", backup_config_command)); dispatcher.add_handler(CommandHandler("history", history_command)); dispatcher.add_handler(CommandHandler("getlog", get_log_command)); dispatcher.add_handler(CommandHandler("shutdown", shutdown_command)); dispatcher.add_handler(CommandHandler("update", update_script_command));
    dispatcher.add_handler(settings_conv); dispatcher.add_handler(kkfofa_conv); dispatcher.add_handler(batch_conv); dispatcher.add_handler(import_conv); dispatcher.add_handler(stats_conv); dispatcher.add_handler(batchfind_conv); dispatcher.add_handler(restore_conv); dispatcher.add_handler(scan_conv)

    logger.info(f"ğŸš€ Fofa Bot v9.8 (ä¼šå‘˜é€»è¾‘ä¿®å¤ç‰ˆ) å·²å¯åŠ¨...")
    updater.start_polling()
    updater.idle()

if __name__ == "__main__":
    main()
