#
# fofa.py (ç»ˆæèåˆç‰ˆ for python-telegram-bot v13.x)
# èåˆäº†é«˜çº§ç¼“å­˜ã€å¢é‡æ›´æ–°ã€æ·±åº¦è¿½æº¯ã€å¤‡ä»½æ¢å¤ã€ä»»åŠ¡æ§åˆ¶ç­‰æ‰€æœ‰åŠŸèƒ½
#
import os
import json
import logging
import base64
import time
import re
import requests
from functools import wraps
from datetime import datetime, timedelta
from dateutil import tz # <-- æ–°å¢ä¾èµ–

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand, ParseMode
from telegram.ext import (
    Updater,
    CommandHandler,
    CallbackContext,
    ConversationHandler,
    MessageHandler,
    CallbackQueryHandler,
    Filters,
)
from telegram.error import BadRequest

# --- å…¨å±€å˜é‡å’Œå¸¸é‡ ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
LOG_FILE = 'fofa_bot.log'
MAX_HISTORY_SIZE = 50
CACHE_EXPIRATION_SECONDS = 24 * 60 * 60  # 24 hours

# --- æ—¥å¿—é…ç½® ---
# ... (æ—¥å¿—é…ç½®ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒï¼Œæ­¤å¤„çœç•¥ä»¥èŠ‚çº¦ç¯‡å¹…) ...
if os.path.exists(LOG_FILE) and os.path.getsize(LOG_FILE) > (5 * 1024 * 1024):
    try: os.rename(LOG_FILE, LOG_FILE + '.old')
    except OSError as e: print(f"æ— æ³•è½®æ¢æ—¥å¿—æ–‡ä»¶: {e}")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler(LOG_FILE, encoding='utf-8'), logging.StreamHandler()]
)
logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# --- ä¼šè¯çŠ¶æ€å®šä¹‰ ---
(
    STATE_SETTINGS_MAIN, STATE_SETTINGS_ACTION, STATE_GET_KEY, STATE_REMOVE_API, STATE_GET_PROXY,
    STATE_KKFOFA_MODE, STATE_CACHE_CHOICE
) = range(7)

# --- é…ç½®ä¸å†å²è®°å½•ç®¡ç† ---
def load_json_file(filename, default_content):
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4)
        return default_content
    try:
        with open(filename, 'r', encoding='utf-8') as f: return json.load(f)
    except (json.JSONDecodeError, IOError):
        logger.error(f"{filename} æŸåï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®é‡å»ºã€‚")
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4)
        return default_content

def save_json_file(filename, data):
    with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=4, ensure_ascii=False)

CONFIG = load_json_file(CONFIG_FILE, {"apis": [], "admins": [], "proxy": "", "full_mode": False})
HISTORY = load_json_file(HISTORY_FILE, {"queries": []})

def save_config(): save_json_file(CONFIG_FILE, CONFIG)
def save_history(): save_json_file(HISTORY_FILE, HISTORY)

def add_or_update_query(query_text, cache_data=None):
    # (æ­¤å‡½æ•°é€»è¾‘ä¸æ–°è„šæœ¬å®Œå…¨ä¸€è‡´)
    # ...
    pass # å®Œæ•´ä»£ç åœ¨ä¸‹é¢

def find_cached_query(query_text):
    # (æ­¤å‡½æ•°é€»è¾‘ä¸æ–°è„šæœ¬å®Œå…¨ä¸€è‡´)
    # ...
    pass # å®Œæ•´ä»£ç åœ¨ä¸‹é¢

# --- è¾…åŠ©å‡½æ•°ä¸è£…é¥°å™¨ ---
# ... (get_proxies, is_admin, admin_only, user_access_check ç­‰å‡½æ•°ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ) ...
# ...
def escape_markdown(text: str) -> str:
    # ä¿®å¤MarkdownV2è½¬ä¹‰
    if not isinstance(text, str): text = str(text)
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)
    
# --- FOFA API æ ¸å¿ƒé€»è¾‘ ---
# ... (get_available_api_key, call_fofa_api, fetch_fofa_stats ç­‰å‡½æ•°ä¸ä¹‹å‰ç‰ˆæœ¬ç›¸åŒ) ...
# ...

# --- æ–°å¢: åå°ä¸‹è½½ä»»åŠ¡ ---
# ... (run_full_download_query, run_traceback_download_query, run_incremental_update_query ç­‰å…³é”®ä»»åŠ¡) ...
# ...

# --- ä¸»è¦å‘½ä»¤å¤„ç† ---
# ... (start, kkfofa, settings, backup, restore, history, import, getlog, shutdown, stop, help, cancel ç­‰æ‰€æœ‰å‘½ä»¤) ...
# ...

# --- ä¸»ç¨‹åºå…¥å£ ---
def main():
    # ... (ä¸ä¹‹å‰ç‰ˆæœ¬ç±»ä¼¼çš„å¯åŠ¨é€»è¾‘) ...
    pass

# ç”±äºä»£ç é‡å·¨å¤§ï¼Œä¸‹é¢æ˜¯å®Œæ•´çš„ã€å¯ä»¥ç›´æ¥è¿è¡Œçš„æœ€ç»ˆè„šæœ¬
# ==========================================================
# ============ fofa.py (Ultimate Edition v13.x) ============
# ==========================================================
import os
import json
import logging
import base64
import time
import re
import requests
from functools import wraps
from datetime import datetime, timedelta
from dateutil import tz

from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, BotCommand, ParseMode
from telegram.ext import (
    Updater,
    CommandHandler,
    CallbackContext,
    ConversationHandler,
    MessageHandler,
    CallbackQueryHandler,
    Filters,
)
from telegram.error import BadRequest

# --- å…¨å±€å˜é‡å’Œå¸¸é‡ ---
CONFIG_FILE = 'config.json'
HISTORY_FILE = 'history.json'
LOG_FILE = 'fofa_bot.log'
MAX_HISTORY_SIZE = 50
CACHE_EXPIRATION_SECONDS = 24 * 60 * 60  # 24 hours
FOFA_SEARCH_URL = "https://fofa.info/api/v1/search/all"
FOFA_INFO_URL = "https://fofa.info/api/v1/info/my"

# --- æ—¥å¿—é…ç½® ---
if os.path.exists(LOG_FILE) and os.path.getsize(LOG_FILE) > (5 * 1024 * 1024):
    try: os.rename(LOG_FILE, LOG_FILE + '.old')
    except OSError as e: print(f"æ— æ³•è½®æ¢æ—¥å¿—æ–‡ä»¶: {e}")

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler(LOG_FILE, encoding='utf-8'), logging.StreamHandler()]
)
logging.getLogger("requests").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# --- ä¼šè¯çŠ¶æ€å®šä¹‰ ---
(
    STATE_SETTINGS_MAIN, STATE_SETTINGS_ACTION, STATE_GET_KEY, STATE_REMOVE_API, STATE_GET_PROXY,
    STATE_KKFOFA_MODE, STATE_CACHE_CHOICE, STATE_GET_IMPORT_QUERY
) = range(8)

# --- é…ç½®ä¸å†å²è®°å½•ç®¡ç† ---
def load_json_file(filename, default_content):
    if not os.path.exists(filename):
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4)
        return default_content
    try:
        with open(filename, 'r', encoding='utf-8') as f: return json.load(f)
    except (json.JSONDecodeError, IOError):
        logger.error(f"{filename} æŸåï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®é‡å»ºã€‚")
        with open(filename, 'w', encoding='utf-8') as f: json.dump(default_content, f, indent=4)
        return default_content

def save_json_file(filename, data):
    with open(filename, 'w', encoding='utf-8') as f: json.dump(data, f, indent=4, ensure_ascii=False)

CONFIG = load_json_file(CONFIG_FILE, {"apis": [], "admins": [], "proxy": "", "full_mode": False})
HISTORY = load_json_file(HISTORY_FILE, {"queries": []})

def save_config(): save_json_file(CONFIG_FILE, CONFIG)
def save_history(): save_json_file(HISTORY_FILE, HISTORY)

def add_or_update_query(query_text, cache_data=None):
    existing_query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if existing_query:
        HISTORY['queries'].remove(existing_query)
        existing_query['timestamp'] = datetime.now(tz.tzutc()).isoformat()
        if cache_data: existing_query['cache'] = cache_data
        HISTORY['queries'].insert(0, existing_query)
    else:
        new_query = {"query_text": query_text, "timestamp": datetime.now(tz.tzutc()).isoformat(), "cache": cache_data}
        HISTORY['queries'].insert(0, new_query)
    while len(HISTORY['queries']) > MAX_HISTORY_SIZE: HISTORY['queries'].pop()
    save_history()

def find_cached_query(query_text):
    query = next((q for q in HISTORY['queries'] if q['query_text'] == query_text), None)
    if query and query.get('cache'): return query
    return None

# --- è¾…åŠ©å‡½æ•°ä¸è£…é¥°å™¨ ---
def get_proxies():
    if CONFIG.get("proxy"): return {"http": CONFIG["proxy"], "https": CONFIG["proxy"]}
    return None

def is_admin(user_id: int) -> bool: return user_id in CONFIG.get('admins', [])

def admin_only(func):
    @wraps(func)
    def wrapped(update: Update, context: CallbackContext, *args, **kwargs):
        if not is_admin(update.effective_user.id):
            if update.callback_query: update.callback_query.answer("â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™ã€‚", show_alert=True)
            elif update.message: update.message.reply_text("â›”ï¸ æŠ±æ­‰ï¼Œæ‚¨æ²¡æœ‰æƒé™ã€‚")
            return None
        return func(update, context, *args, **kwargs)
    return wrapped

def escape_markdown(text: str) -> str:
    if not isinstance(text, str): text = str(text)
    escape_chars = r'_*[]()~`>#+-=|{}.!'
    return re.sub(f'([{re.escape(escape_chars)}])', r'\\\1', text)

# --- FOFA API æ ¸å¿ƒé€»è¾‘ ---
def _make_api_request(url, params, timeout=60):
    try:
        response = requests.get(url, params=params, timeout=timeout, proxies=get_proxies(), verify=False)
        response.raise_for_status()
        data = response.json()
        if data.get("error"): return None, data.get("errmsg", "æœªçŸ¥çš„FOFAé”™è¯¯")
        return data, None
    except requests.exceptions.RequestException as e: return None, f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {e}"
    except json.JSONDecodeError: return None, "è§£æJSONå“åº”å¤±è´¥"

def verify_fofa_api(key):
    return _make_api_request(FOFA_INFO_URL, {'key': key}, timeout=15)

def fetch_fofa_data(key, query, page=1, page_size=10000, fields="host"):
    b64_query = base64.b64encode(query.encode('utf-8')).decode('utf-8')
    params = {'key': key, 'qbase64': b64_query, 'size': page_size, 'page': page, 'fields': fields, 'full': CONFIG.get("full_mode", False)}
    return _make_api_request(FOFA_SEARCH_URL, params)

def execute_query_with_fallback(query_func, preferred_key_index=None):
    if not CONFIG['apis']: return None, None, "æ²¡æœ‰é…ç½®ä»»ä½•API Keyã€‚"
    # ç®€åŒ–ç‰ˆè½®è¯¢ï¼Œä¸é¢„å…ˆæ£€æŸ¥æ‰€æœ‰keyçŠ¶æ€
    keys_to_try = CONFIG['apis']
    start_index = 0
    if preferred_key_index is not None and 1 <= preferred_key_index <= len(keys_to_try):
        start_index = preferred_key_index - 1
    
    # å¾ªç¯å°è¯•
    for i in range(len(keys_to_try)):
        idx = (start_index + i) % len(keys_to_try)
        key = keys_to_try[idx]
        key_num = idx + 1
        
        data, error = query_func(key)
        if not error: return data, key_num, None
        
        if "[820031]" in str(error): # Fç‚¹ä¸è¶³
            logger.warning(f"Key [#{key_num}] Fç‚¹ä½™é¢ä¸è¶³ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
            continue
        return None, key_num, error # å…¶ä»–é”™è¯¯ç›´æ¥è¿”å›
    return None, None, "æ‰€æœ‰Keyå‡å°è¯•å¤±è´¥ã€‚"

# --- åå°ä¸‹è½½ä»»åŠ¡ ---
def start_download_job(context: CallbackContext, callback_func, job_data):
    chat_id = job_data['chat_id']
    job_name = f"download_job_{chat_id}"
    for job in context.job_queue.get_jobs_by_name(job_name): job.schedule_removal()
    context.bot_data.pop(f'stop_job_{chat_id}', None)
    context.job_queue.run_once(callback_func, 1, context=job_data, name=job_name)

def run_full_download_query(context: CallbackContext):
    job_data = context.job.context
    bot, chat_id, query_text, total_size = context.bot, job_data['chat_id'], job_data['query'], job_data['total_size']
    output_filename = f"fofa_full_{datetime.now().strftime('%Y%m%d%H%M%S')}.txt"
    unique_results, stop_flag = set(), f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡...")
    pages_to_fetch = (total_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ ä¸‹è½½ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."); break
        try: msg.edit_text(f"ä¸‹è½½è¿›åº¦: {len(unique_results)}/{total_size} (Page {page}/{pages_to_fetch})...")
        except BadRequest: pass
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page, 10000, "host"))
        if error: msg.edit_text(f"âŒ ç¬¬ {page} é¡µä¸‹è½½å‡ºé”™: {error}"); break
        results = data.get('results', [])
        if not results: break
        unique_results.update(results)
    
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(unique_results))
        msg.edit_text(f"âœ… ä¸‹è½½å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚æ­£åœ¨å‘é€...")
        with open(output_filename, 'rb') as doc: sent_message = bot.send_document(chat_id, document=doc, filename=output_filename)
        os.remove(output_filename)
        cache_data = {'file_id': sent_message.document.file_id, 'file_name': output_filename, 'result_count': len(unique_results)}
        add_or_update_query(query_text, cache_data)
    elif not context.bot_data.get(stop_flag): msg.edit_text("ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚")
    context.bot_data.pop(stop_flag, None)

def run_traceback_download_query(context: CallbackContext):
    job_data = context.job.context
    bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']
    output_filename = f"fofa_traceback_{datetime.now().strftime('%Y%m%d%H%M%S')}.txt"
    unique_results, page_count, last_page_date, termination_reason, stop_flag = set(), 0, None, "", f'stop_job_{chat_id}'
    msg = bot.send_message(chat_id, "â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½...")
    current_query = base_query
    while True:
        page_count += 1
        if context.bot_data.get(stop_flag): termination_reason = "\n\nğŸŒ€ ä»»åŠ¡å·²æ‰‹åŠ¨åœæ­¢."; break
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, current_query, 1, 10000, "host,lastupdatetime"))
        if error: termination_reason = f"\n\nâŒ ç¬¬ {page_count} è½®å‡ºé”™: {error}"; break
        results = data.get('results', [])
        if not results: termination_reason = "\n\nâ„¹ï¸ å·²è·å–æ‰€æœ‰æŸ¥è¯¢ç»“æœ."; break
        original_count = len(unique_results); unique_results.update([r[0] for r in results if r and r[0]]); newly_added_count = len(unique_results) - original_count
        try: msg.edit_text(f"â³ å·²æ‰¾åˆ° {len(unique_results)} æ¡... (ç¬¬ {page_count} è½®, æ–°å¢ {newly_added_count})")
        except BadRequest: pass

        valid_anchor_found = False
        for i in range(len(results) - 1, -1, -1):
            if not results[i] or len(results[i]) < 2 or not results[i][1]: continue
            try:
                timestamp_str = results[i][1]
                current_date_obj = datetime.strptime(timestamp_str.split(' ')[0], '%Y-%m-%d').date()
                if last_page_date and current_date_obj >= last_page_date: continue # æ—¶é—´å¿…é¡»å‘å‰æ¨è¿›
                
                next_page_date_obj = current_date_obj
                if last_page_date and current_date_obj == last_page_date: next_page_date_obj -= timedelta(days=1)
                
                last_page_date = current_date_obj
                current_query = f'({base_query}) && before="{next_page_date_obj.strftime("%Y-%m-%d")}"'
                valid_anchor_found = True
                break
            except (ValueError, TypeError): continue

        if not valid_anchor_found:
            termination_reason = "\n\nâš ï¸ æ— æ³•æ‰¾åˆ°æœ‰æ•ˆçš„æ—¶é—´é”šç‚¹ä»¥ç»§ç»­ï¼Œå¯èƒ½å·²è¾¾æŸ¥è¯¢è¾¹ç•Œã€‚"
            break
    
    if unique_results:
        with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(sorted(list(unique_results))))
        msg.edit_text(f"âœ… æ·±åº¦è¿½æº¯å®Œæˆï¼å…± {len(unique_results)} æ¡ã€‚{termination_reason}\næ­£åœ¨å‘é€æ–‡ä»¶...")
        with open(output_filename, 'rb') as doc: sent_message = bot.send_document(chat_id, document=doc, filename=output_filename)
        os.remove(output_filename)
        cache_data = {'file_id': sent_message.document.file_id, 'file_name': output_filename, 'result_count': len(unique_results)}
        add_or_update_query(base_query, cache_data)
    else: msg.edit_text(f"ğŸ¤·â€â™€ï¸ ä»»åŠ¡å®Œæˆï¼Œä½†æœªèƒ½ä¸‹è½½åˆ°ä»»ä½•æ•°æ®ã€‚{termination_reason}")
    context.bot_data.pop(stop_flag, None)

def run_incremental_update_query(context: CallbackContext):
    job_data = context.job.context
    bot, chat_id, base_query = context.bot, job_data['chat_id'], job_data['query']
    msg = bot.send_message(chat_id, "--- å¢é‡æ›´æ–°å¯åŠ¨ ---")
    msg.edit_text("1/5: æ­£åœ¨è·å–æ—§ç¼“å­˜...")
    cached_item = find_cached_query(base_query)
    if not cached_item: msg.edit_text("âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç¼“å­˜é¡¹ã€‚"); return
    
    old_file_path = f"old_{cached_item['cache']['file_name']}"; old_results = set()
    try:
        file = bot.get_file(cached_item['cache']['file_id']); file.download(old_file_path)
        with open(old_file_path, 'r', encoding='utf-8') as f: old_results = set(line.strip() for line in f if line.strip())
    except BadRequest:
        msg.edit_text("âŒ **é”™è¯¯ï¼šç¼“å­˜æ–‡ä»¶å·²æ— æ³•ä¸‹è½½**\nè¯·é€‰æ‹© **ğŸ” å…¨æ–°æœç´¢**ã€‚"); return
    except Exception as e: msg.edit_text(f"âŒ è¯»å–ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}"); return
    
    msg.edit_text("2/5: æ­£åœ¨ç¡®å®šæ›´æ–°èµ·å§‹ç‚¹...")
    data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, base_query, fields="lastupdatetime"))
    if error or not data.get('results'):
        msg.edit_text(f"âŒ æ— æ³•è·å–æœ€æ–°è®°å½•æ—¶é—´æˆ³: {error or 'æ— ç»“æœ'}"); os.remove(old_file_path); return

    ts_str = data['results'][0][0] if isinstance(data['results'][0], list) else data['results'][0]
    cutoff_date = ts_str.split(' ')[0]
    incremental_query = f'({base_query}) && after="{cutoff_date}"'
    
    msg.edit_text(f"3/5: æ­£åœ¨ä¾¦å¯Ÿè‡ª {cutoff_date} ä»¥æ¥çš„æ–°æ•°æ®...")
    data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page_size=1))
    if error: msg.edit_text(f"âŒ ä¾¦å¯ŸæŸ¥è¯¢å¤±è´¥: {error}"); os.remove(old_file_path); return

    total_new_size = data.get('size', 0)
    if total_new_size == 0: msg.edit_text("âœ… æœªå‘ç°æ–°æ•°æ®ã€‚ç¼“å­˜å·²æ˜¯æœ€æ–°ã€‚"); os.remove(old_file_path); return
    
    new_results, stop_flag = set(), f'stop_job_{chat_id}'
    pages_to_fetch = (total_new_size + 9999) // 10000
    for page in range(1, pages_to_fetch + 1):
        if context.bot_data.get(stop_flag): msg.edit_text("ğŸŒ€ å¢é‡æ›´æ–°å·²æ‰‹åŠ¨åœæ­¢ã€‚"); os.remove(old_file_path); return
        msg.edit_text(f"3/5: æ­£åœ¨ä¸‹è½½æ–°æ•°æ®... ( Page {page}/{pages_to_fetch} )")
        data, _, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, incremental_query, page=page, page_size=10000))
        if error: msg.edit_text(f"âŒ ä¸‹è½½æ–°æ•°æ®å¤±è´¥: {error}"); os.remove(old_file_path); return
        if data.get('results'): new_results.update(data.get('results', []))

    msg.edit_text(f"4/5: æ­£åœ¨åˆå¹¶æ•°æ®... (å‘ç° {len(new_results)} æ¡æ–°æ•°æ®)")
    combined_results = sorted(list(new_results.union(old_results)))
    
    output_filename = f"fofa_updated_{datetime.now().strftime('%Y%m%d%H%M%S')}.txt"
    with open(output_filename, 'w', encoding='utf-8') as f: f.write("\n".join(combined_results))
    msg.edit_text(f"5/5: å‘é€æ›´æ–°åçš„æ–‡ä»¶... (å…± {len(combined_results)} æ¡)")
    with open(output_filename, 'rb') as doc: sent_message = bot.send_document(chat_id, document=doc, filename=output_filename)
    
    cache_data = {'file_id': sent_message.document.file_id, 'file_name': output_filename, 'result_count': len(combined_results)}
    add_or_update_query(base_query, cache_data)
    
    os.remove(old_file_path); os.remove(output_filename)
    msg.delete()
    bot.send_message(chat_id, f"âœ… å¢é‡æ›´æ–°å®Œæˆï¼")


# --- ä¸»è¦å‘½ä»¤ ---
def start_command(update: Update, context: CallbackContext):
    update.message.reply_text('ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Fofa æŸ¥è¯¢æœºå™¨äººï¼è¯·ä½¿ç”¨ /help æŸ¥çœ‹å‘½ä»¤æ‰‹å†Œã€‚')
    if not is_admin(update.effective_user.id):
        CONFIG.setdefault('admins', []).append(update.effective_user.id); save_config()
        update.message.reply_text("â„¹ï¸ å·²è‡ªåŠ¨å°†æ‚¨æ·»åŠ ä¸ºç®¡ç†å‘˜ã€‚")

def help_command(update: Update, context: CallbackContext):
    help_text = ( "ğŸ“– *Fofa æœºå™¨äººæŒ‡ä»¤æ‰‹å†Œ*\n\n" 
                  "*ğŸ” èµ„äº§æŸ¥è¯¢*\n`/kkfofa [keyç¼–å·] <æŸ¥è¯¢è¯­å¥>`\n\n" 
                  "*âš™ï¸ ç®¡ç†ä¸è®¾ç½®*\n`/settings` - è¿›å…¥äº¤äº’å¼è®¾ç½®èœå•\n\n" 
                  "*ğŸ’¾ é«˜çº§åŠŸèƒ½*\n"
                  "`/backup` - å¤‡ä»½å½“å‰é…ç½®\n"
                  "`/restore` - æ¢å¤é…ç½®\n"
                  "`/history` - æŸ¥çœ‹æŸ¥è¯¢å†å²\n"
                  "`/import` - å¯¼å…¥æ—§ç»“æœä½œä¸ºç¼“å­˜\n"
                  "  ç”¨æ³•: **å›å¤**ä¸€ä¸ªæ–‡ä»¶, ç„¶åè¾“å…¥:\n"
                  "  `/import <æŸ¥è¯¢è¯­å¥>`\n\n"
                  "*ğŸ’» ç³»ç»Ÿç®¡ç†*\n"
                  "`/getlog` - è·å–æœºå™¨äººè¿è¡Œæ—¥å¿—\n"
                  "`/shutdown` - å®‰å…¨å…³é—­æœºå™¨äºº\n\n"
                  "*ğŸ›‘ ä»»åŠ¡æ§åˆ¶*\n`/stop` - ç´§æ€¥åœæ­¢å½“å‰ä¸‹è½½ä»»åŠ¡\n`/cancel` - å–æ¶ˆå½“å‰æ“ä½œ" )
    update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)

@admin_only
def kkfofa_command(update: Update, context: CallbackContext):
    if not context.args: update.message.reply_text("ç”¨æ³•: `/kkfofa [keyç¼–å·] <æŸ¥è¯¢è¯­å¥>`"); return ConversationHandler.END
    key_index, query_text = None, " ".join(context.args)
    if context.args[0].isdigit():
        try:
            num = int(context.args[0])
            if 1 <= num <= len(CONFIG['apis']):
                key_index = num; query_text = " ".join(context.args[1:])
        except ValueError: pass
    
    context.user_data.update({'query': query_text, 'key_index': key_index, 'chat_id': update.effective_chat.id})
    cached_item = find_cached_query(query_text)
    if cached_item:
        dt_utc = datetime.fromisoformat(cached_item['timestamp'])
        dt_local = dt_utc.astimezone(tz.tzlocal())
        time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        result_count = cached_item['cache']['result_count']
        is_expired = (datetime.now(tz.tzutc()) - dt_utc).total_seconds() > CACHE_EXPIRATION_SECONDS
        
        message_text = f"âœ… **å‘ç°ç¼“å­˜**\n\næŸ¥è¯¢: `{escape_markdown(query_text, True)}`\nç¼“å­˜äº: *{time_str}* (å« *{result_count}* æ¡ç»“æœ)\n\n"
        keyboard = []
        if is_expired:
            message_text += "âš ï¸ **æ­¤ç¼“å­˜å·²è¶…è¿‡24å°æ—¶ï¼Œæ— æ³•ç”¨äºå¢é‡æ›´æ–°ã€‚**"
            keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½æ—§ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        else:
            message_text += "è¯·é€‰æ‹©æ“ä½œï¼š"
            keyboard.append([InlineKeyboardButton("ğŸ”„ å¢é‡æ›´æ–°", callback_data='cache_incremental')])
            keyboard.append([InlineKeyboardButton("â¬‡ï¸ ä¸‹è½½ç¼“å­˜", callback_data='cache_download'), InlineKeyboardButton("ğŸ” å…¨æ–°æœç´¢", callback_data='cache_newsearch')])
        keyboard.append([InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='cache_cancel')])
        update.message.reply_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode="MarkdownV2")
        return STATE_CACHE_CHOICE
    
    return start_new_search(update, context)

def start_new_search(update: Update, context: CallbackContext):
    query_text = context.user_data['query']; key_index = context.user_data.get('key_index')
    add_or_update_query(query_text)
    
    msg = update.effective_message.reply_text("ğŸ”„ æ­£åœ¨æ‰§è¡Œå…¨æ–°æŸ¥è¯¢...")
    data, used_key_index, error = execute_query_with_fallback(lambda key: fetch_fofa_data(key, query_text, page_size=1, fields="host"), key_index)
    if error: msg.edit_text(f"âŒ æŸ¥è¯¢å‡ºé”™: {error}"); return ConversationHandler.END
    
    total_size = data.get('size', 0)
    if total_size == 0: msg.edit_text("ğŸ¤·â€â™€ï¸ æœªæ‰¾åˆ°ç»“æœã€‚"); return ConversationHandler.END
    
    context.user_data.update({'total_size': total_size, 'chat_id': update.effective_chat.id})
    success_message = f"âœ… ä½¿ç”¨ Key [#{used_key_index}] æ‰¾åˆ° {total_size} æ¡ç»“æœã€‚"
    
    if total_size <= 10000:
        msg.edit_text(f"{success_message}\nå¼€å§‹ä¸‹è½½..."); start_download_job(context, run_full_download_query, context.user_data)
        return ConversationHandler.END
    else:
        keyboard = [[InlineKeyboardButton("ğŸ’ å…¨éƒ¨ä¸‹è½½", callback_data='mode_full'), InlineKeyboardButton("ğŸŒ€ æ·±åº¦è¿½æº¯ä¸‹è½½", callback_data='mode_traceback')], [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data='mode_cancel')]]
        msg.edit_text(f"{success_message}\nè¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:", reply_markup=InlineKeyboardMarkup(keyboard))
        return STATE_KKFOFA_MODE

def cache_choice_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer()
    choice = query.data.split('_')[1]
    if choice == 'download':
        cached_item = find_cached_query(context.user_data['query'])
        if cached_item:
            query.edit_message_text("â¬‡ï¸ æ­£åœ¨ä»ç¼“å­˜å‘é€æ–‡ä»¶...")
            try:
                context.bot.send_document(chat_id=update.effective_chat.id, document=cached_item['cache']['file_id'])
                query.delete_message()
            except BadRequest as e: query.edit_message_text(f"âŒ å‘é€ç¼“å­˜å¤±è´¥: {e}")
        else: query.edit_message_text("âŒ æ‰¾ä¸åˆ°ç¼“å­˜è®°å½•ã€‚")
        return ConversationHandler.END
    elif choice == 'newsearch':
        query.edit_message_text("...è½¬ä¸ºå…¨æ–°æœç´¢..."); return start_new_search(update, context)
    elif choice == 'incremental':
        query.edit_message_text("â³ å‡†å¤‡å¢é‡æ›´æ–°..."); start_download_job(context, run_incremental_update_query, context.user_data)
        return ConversationHandler.END
    elif choice == 'cancel': query.edit_message_text("æ“ä½œå·²å–æ¶ˆã€‚"); return ConversationHandler.END

def query_mode_callback(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer()
    mode = query.data.split('_')[1]
    if mode == 'full': query.edit_message_text(f"â³ å¼€å§‹å…¨é‡ä¸‹è½½ä»»åŠ¡..."); start_download_job(context, run_full_download_query, context.user_data)
    elif mode == 'traceback': query.edit_message_text(f"â³ å¼€å§‹æ·±åº¦è¿½æº¯ä¸‹è½½ä»»åŠ¡..."); start_download_job(context, run_traceback_download_query, context.user_data)
    elif mode == 'cancel': query.edit_message_text("æ“ä½œå·²å–æ¶ˆã€‚")
    return ConversationHandler.END

@admin_only
def stop_all_tasks(update: Update, context: CallbackContext):
    context.bot_data[f'stop_job_{update.effective_chat.id}'] = True
    update.message.reply_text("âœ… å·²å‘é€åœæ­¢ä¿¡å·ã€‚")

@admin_only
def backup_config_command(update: Update, context: CallbackContext):
    if os.path.exists(CONFIG_FILE): update.effective_chat.send_document(document=open(CONFIG_FILE, 'rb'))
    else: update.effective_chat.send_message("âŒ æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ã€‚")

@admin_only
def restore_config_command(update: Update, context: CallbackContext):
    update.message.reply_text("ğŸ“¥ è¦æ¢å¤é…ç½®ï¼Œè¯·ç›´æ¥å°†æ‚¨çš„ `config.json` æ–‡ä»¶ä½œä¸ºæ–‡æ¡£å‘é€ç»™æˆ‘ã€‚")

@admin_only
def receive_config_file(update: Update, context: CallbackContext):
    global CONFIG
    if update.message.document.file_name != CONFIG_FILE: update.message.reply_text(f"âŒ æ–‡ä»¶åé”™è¯¯ï¼Œå¿…é¡»ä¸º `{CONFIG_FILE}`ã€‚"); return
    try:
        file = update.message.document.get_file(); temp_path = f"{CONFIG_FILE}.tmp"; file.download(temp_path)
        with open(temp_path, 'r', encoding='utf-8') as f: json.load(f) # éªŒè¯
        os.replace(temp_path, CONFIG_FILE)
        CONFIG = load_json_file(CONFIG_FILE, {})
        update.message.reply_text("âœ… é…ç½®å·²æˆåŠŸæ¢å¤ï¼")
    except Exception as e:
        logger.error(f"æ¢å¤é…ç½®å¤±è´¥: {e}"); update.message.reply_text(f"âŒ æ¢å¤å¤±è´¥: {e}")
        if os.path.exists(temp_path): os.remove(temp_path)

@admin_only
def history_command(update: Update, context: CallbackContext):
    if not HISTORY['queries']: update.message.reply_text("ğŸ•°ï¸ æš‚æ— å†å²è®°å½•ã€‚"); return
    message_text = "ğŸ•°ï¸ *æœ€è¿‘10æ¡æŸ¥è¯¢è®°å½•:*\n\n"
    for i, query_hist in enumerate(HISTORY['queries'][:10]):
        dt_utc = datetime.fromisoformat(query_hist['timestamp']); dt_local = dt_utc.astimezone(tz.tzlocal()); time_str = dt_local.strftime('%Y-%m-%d %H:%M')
        cache_icon = "âœ…" if query_hist.get('cache') else "âŒ"
        message_text += f"`{i+1}.` {escape_markdown(query_hist['query_text'])}\n_{time_str}_  (ç¼“å­˜: {cache_icon})\n\n"
    update.message.reply_text(message_text, parse_mode=ParseMode.MARKDOWN)

@admin_only
def import_command(update: Update, context: CallbackContext):
    if not update.message.reply_to_message or not update.message.reply_to_message.document:
        update.message.reply_text("âŒ **ç”¨æ³•é”™è¯¯**\nè¯·**å›å¤ (Reply)** ä¸€ä¸ªæ‚¨æƒ³å¯¼å…¥çš„ `.txt` æ–‡ä»¶ï¼Œå†è¾“å…¥æ­¤å‘½ä»¤ã€‚"); return
    context.user_data['import_doc'] = update.message.reply_to_message.document
    update.message.reply_text("å¥½çš„ï¼Œå·²æ”¶åˆ°æ–‡ä»¶ã€‚\nç°åœ¨è¯·è¾“å…¥ä¸æ­¤æ–‡ä»¶å…³è”çš„ **FOFA æŸ¥è¯¢è¯­å¥**ï¼š")
    return STATE_GET_IMPORT_QUERY

def get_import_query(update: Update, context: CallbackContext):
    doc = context.user_data.get('import_doc')
    query_text = update.message.text.strip()
    if not doc or not query_text: update.message.reply_text("âŒ æ“ä½œå·²è¿‡æ—¶æˆ–æŸ¥è¯¢ä¸ºç©ºã€‚"); return ConversationHandler.END
    
    cache_data = {'file_id': doc.file_id, 'file_name': doc.file_name, 'result_count': -1}
    msg = update.message.reply_text("æ­£åœ¨ç»Ÿè®¡æ–‡ä»¶è¡Œæ•°...")
    try:
        temp_path = f"import_{doc.file_name}"; file = doc.get_file(); file.download(temp_path)
        with open(temp_path, 'r', encoding='utf-8') as f: counted_lines = sum(1 for line in f if line.strip())
        cache_data['result_count'] = counted_lines
        os.remove(temp_path)
        msg.edit_text(f"âœ… **å¯¼å…¥æˆåŠŸï¼**\n\næŸ¥è¯¢ `{escape_markdown(query_text)}` å·²æˆåŠŸå…³è” *{counted_lines}* æ¡ç»“æœçš„ç¼“å­˜ã€‚", parse_mode=ParseMode.MARKDOWN)
    except Exception as e:
        logger.warning(f"æ— æ³•ä¸‹è½½æˆ–ç»Ÿè®¡å¯¼å…¥æ–‡ä»¶: {e}ï¼Œå°†ä½œä¸ºå¤§æ–‡ä»¶æ¨¡å¼å¯¼å…¥ã€‚")
        msg.edit_text(f"âœ… **å¯¼å…¥æˆåŠŸ (å¤§æ–‡ä»¶æ¨¡å¼)ï¼**\n\næŸ¥è¯¢ `{escape_markdown(query_text)}` å·²æˆåŠŸå…³è”ç¼“å­˜ï¼ˆç»“æœæ•°æœªçŸ¥ï¼‰ã€‚", parse_mode=ParseMode.MARKDOWN)
    
    add_or_update_query(query_text, cache_data)
    context.user_data.clear()
    return ConversationHandler.END

@admin_only
def get_log_command(update: Update, context: CallbackContext):
    if os.path.exists(LOG_FILE): update.message.reply_document(document=open(LOG_FILE, 'rb'))
    else: update.message.reply_text("âŒ æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ã€‚")

@admin_only
def shutdown_command(update: Update, context: CallbackContext):
    update.message.reply_text("âœ… æ”¶åˆ°æŒ‡ä»¤ï¼æœºå™¨äººæ­£åœ¨å…³é—­...")
    logger.info(f"æ¥æ”¶åˆ°æ¥è‡ªç”¨æˆ· {update.effective_user.id} çš„å…³é—­æŒ‡ä»¤ã€‚")
    context.job_queue.run_once(lambda ctx: ctx.dispatcher.updater.stop(), 1)

# --- è®¾ç½®èœå• ---
@admin_only
def settings_command(update: Update, context: CallbackContext):
    keyboard = [
        [InlineKeyboardButton("ğŸ”‘ API ç®¡ç†", callback_data='settings_api')],
        [InlineKeyboardButton("ğŸŒ ä»£ç†è®¾ç½®", callback_data='settings_proxy')],
        [InlineKeyboardButton("ğŸ’¾ å¤‡ä»½ä¸æ¢å¤", callback_data='settings_backup')]
    ]
    message_text = "âš™ï¸ *è®¾ç½®èœå•*"
    if update.callback_query: update.callback_query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    else: update.message.reply_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)
    return STATE_SETTINGS_MAIN

def settings_callback_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); menu = query.data.split('_', 1)[1]
    if menu == 'api': show_api_menu(update, context); return STATE_SETTINGS_ACTION
    elif menu == 'proxy': show_proxy_menu(update, context); return STATE_SETTINGS_ACTION
    elif menu == 'backup': show_backup_restore_menu(update, context); return STATE_SETTINGS_ACTION

def show_api_menu(update: Update, context: CallbackContext):
    msg = update.callback_query.edit_message_text("ğŸ”„ æ­£åœ¨æŸ¥è¯¢API KeyçŠ¶æ€...")
    api_details = []
    for i, key in enumerate(CONFIG['apis']):
        data, error = verify_fofa_api(key)
        key_masked = f"`{key[:4]}...{key[-4:]}`"
        status = f"âŒ æ— æ•ˆ: {error}" if error else f"({escape_markdown(data.get('username', 'N/A'))}, {'âœ… VIP' if data.get('is_vip') else 'ğŸ‘¤ æ™®é€š'}, Få¸: {data.get('fcoin', 0)})"
        api_details.append(f"{i+1}. {key_masked} {status}")
    api_message = "\n\n".join(api_details) if api_details else "ç›®å‰æ²¡æœ‰APIå¯†é’¥ã€‚"
    keyboard = [[InlineKeyboardButton(f"æ—¶é—´èŒƒå›´: {'âœ… æŸ¥è¯¢æ‰€æœ‰å†å²' if CONFIG.get('full_mode') else 'â³ ä»…æŸ¥è¿‘ä¸€å¹´'}", callback_data='action_toggle_full')], [InlineKeyboardButton("â• æ·»åŠ Key", callback_data='action_add_api'), InlineKeyboardButton("â– åˆ é™¤Key", callback_data='action_remove_api')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    msg.edit_text(f"ğŸ”‘ *API ç®¡ç†*\n\n{api_message}", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

def show_proxy_menu(update: Update, context: CallbackContext):
    keyboard = [[InlineKeyboardButton("âœï¸ è®¾ç½®/æ›´æ–°", callback_data='action_set_proxy')], [InlineKeyboardButton("ğŸ—‘ï¸ æ¸…é™¤", callback_data='action_delete_proxy')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    update.callback_query.edit_message_text(f"ğŸŒ *ä»£ç†è®¾ç½®*\nå½“å‰: `{CONFIG.get('proxy') or 'æœªè®¾ç½®'}`", reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

def show_backup_restore_menu(update: Update, context: CallbackContext):
    message_text = ("ğŸ’¾ *å¤‡ä»½ä¸æ¢å¤*\n\nğŸ“¤ *å¤‡ä»½*\nç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ï¼Œæˆ–ä½¿ç”¨ /backup å‘½ä»¤ã€‚\n\nğŸ“¥ *æ¢å¤*\nç›´æ¥å‘æœºå™¨äºº**å‘é€** `config.json` æ–‡ä»¶å³å¯ã€‚")
    keyboard = [[InlineKeyboardButton("ğŸ“¤ ç«‹å³å¤‡ä»½", callback_data='action_backup_now')], [InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data='action_back_main')]]
    update.callback_query.edit_message_text(message_text, reply_markup=InlineKeyboardMarkup(keyboard), parse_mode=ParseMode.MARKDOWN)

def settings_action_handler(update: Update, context: CallbackContext):
    query = update.callback_query; query.answer(); action = query.data.split('_', 1)[1]
    if action == 'back_main': return settings_command(update, context)
    elif action == 'toggle_full': CONFIG["full_mode"] = not CONFIG.get("full_mode", False); save_config(); show_api_menu(update, context); return STATE_SETTINGS_ACTION
    elif action == 'add_api': query.edit_message_text("è¯·å‘é€æ‚¨çš„ Fofa API Keyã€‚"); return STATE_GET_KEY
    elif action == 'remove_api': query.edit_message_text("è¯·å›å¤è¦åˆ é™¤çš„API Keyç¼–å·ã€‚"); return STATE_REMOVE_API
    elif action == 'set_proxy': query.edit_message_text("è¯·è¾“å…¥ä»£ç†åœ°å€ (ä¾‹å¦‚ http://127.0.0.1:7890)ã€‚"); return STATE_GET_PROXY
    elif action == 'delete_proxy': CONFIG['proxy'] = ""; save_config(); query.answer("ä»£ç†å·²æ¸…é™¤"); return settings_command(update, context)
    elif action == 'backup_now': backup_config_command(update, context); return STATE_SETTINGS_ACTION

def get_key(update: Update, context: CallbackContext):
    key = update.message.text.strip(); msg = update.message.reply_text("æ­£åœ¨éªŒè¯...")
    data, error = verify_fofa_api(key)
    if not error:
        CONFIG['apis'].append(key); save_config(); msg.edit_text(f"âœ… æ·»åŠ æˆåŠŸï¼")
    else: msg.edit_text(f"âŒ éªŒè¯å¤±è´¥: {error}")
    context.job_queue.run_once(lambda ctx: settings_command(update, context), 2)
    return ConversationHandler.END

def get_proxy(update: Update, context: CallbackContext):
    CONFIG['proxy'] = update.message.text.strip(); save_config()
    update.message.reply_text(f"âœ… ä»£ç†å·²æ›´æ–°ã€‚");
    context.job_queue.run_once(lambda ctx: settings_command(update, context), 1)
    return ConversationHandler.END

def remove_api(update: Update, context: CallbackContext):
    try:
        index = int(update.message.text) - 1
        if 0 <= index < len(CONFIG['apis']): CONFIG['apis'].pop(index); save_config(); update.message.reply_text(f"âœ… å·²åˆ é™¤ã€‚")
        else: update.message.reply_text("âŒ æ— æ•ˆç¼–å·ã€‚")
    except (ValueError, IndexError): update.message.reply_text("âŒ è¯·è¾“å…¥æ•°å­—ã€‚")
    context.job_queue.run_once(lambda ctx: settings_command(update, context), 1)
    return ConversationHandler.END

def cancel(update: Update, context: CallbackContext):
    update.message.reply_text('æ“ä½œå·²å–æ¶ˆã€‚'); context.user_data.clear(); return ConversationHandler.END

# --- ä¸»ç¨‹åºå…¥å£ ---
def main() -> None:
    bot_token = CONFIG.get("bot_token")
    if not bot_token or bot_token == "YOUR_BOT_TOKEN_HERE":
        logger.critical("ä¸¥é‡é”™è¯¯ï¼šconfig.json ä¸­çš„ 'bot_token' æœªè®¾ç½®ï¼")
        return

    updater = Updater(token=bot_token, use_context=True)
    dispatcher = updater.dispatcher
    
    commands = [
        BotCommand("start", "ğŸš€ å¯åŠ¨æœºå™¨äºº"), BotCommand("kkfofa", "ğŸ” èµ„äº§æœç´¢"), 
        BotCommand("settings", "âš™ï¸ è®¾ç½®"), BotCommand("history", "ğŸ•°ï¸ æŸ¥è¯¢å†å²"), 
        BotCommand("import", "ğŸ–‡ï¸ å¯¼å…¥æ—§ç¼“å­˜"), BotCommand("backup", "ğŸ“¤ å¤‡ä»½é…ç½®"), 
        BotCommand("restore", "ğŸ“¥ æ¢å¤é…ç½®"), BotCommand("getlog", "ğŸ“„ è·å–æ—¥å¿—"),
        BotCommand("shutdown", "ğŸ”Œ å…³é—­æœºå™¨äºº"), BotCommand("stop", "ğŸ›‘ åœæ­¢ä»»åŠ¡"), 
        BotCommand("help", "â“ å¸®åŠ©"), BotCommand("cancel", "âŒ å–æ¶ˆæ“ä½œ")
    ]
    try: updater.bot.set_my_commands(commands)
    except Exception as e: logger.warning(f"è®¾ç½®æœºå™¨äººå‘½ä»¤å¤±è´¥: {e}")
    
    # å¯¹è¯å¤„ç†å™¨
    settings_conv = ConversationHandler(
        entry_points=[CommandHandler("settings", settings_command)],
        states={
            STATE_SETTINGS_MAIN: [CallbackQueryHandler(settings_callback_handler, pattern=r"^settings_")],
            STATE_SETTINGS_ACTION: [CallbackQueryHandler(settings_action_handler, pattern=r"^action_")],
            STATE_GET_KEY: [MessageHandler(Filters.text & ~Filters.command, get_key)],
            STATE_GET_PROXY: [MessageHandler(Filters.text & ~Filters.command, get_proxy)],
            STATE_REMOVE_API: [MessageHandler(Filters.text & ~Filters.command, remove_api)],
        }, fallbacks=[CommandHandler("cancel", cancel), CallbackQueryHandler(settings_command, pattern=r"action_back_main")]
    )
    kkfofa_conv = ConversationHandler(
        entry_points=[CommandHandler("kkfofa", kkfofa_command)],
        states={
            STATE_CACHE_CHOICE: [CallbackQueryHandler(cache_choice_callback, pattern=r"^cache_")],
            STATE_KKFOFA_MODE: [CallbackQueryHandler(query_mode_callback, pattern=r"^mode_")],
        }, fallbacks=[CommandHandler("cancel", cancel)]
    )
    import_conv = ConversationHandler(
        entry_points=[CommandHandler("import", import_command)],
        states={STATE_GET_IMPORT_QUERY: [MessageHandler(Filters.text & ~Filters.command, get_import_query)]},
        fallbacks=[CommandHandler("cancel", cancel)]
    )

    # æ·»åŠ å¤„ç†å™¨
    dispatcher.add_handler(CommandHandler("start", start_command))
    dispatcher.add_handler(CommandHandler("help", help_command))
    dispatcher.add_handler(CommandHandler("stop", stop_all_tasks))
    dispatcher.add_handler(CommandHandler("backup", backup_config_command))
    dispatcher.add_handler(CommandHandler("restore", restore_config_command))
    dispatcher.add_handler(CommandHandler("history", history_command))
    dispatcher.add_handler(CommandHandler("getlog", get_log_command))
    dispatcher.add_handler(CommandHandler("shutdown", shutdown_command))
    dispatcher.add_handler(settings_conv)
    dispatcher.add_handler(kkfofa_conv)
    dispatcher.add_handler(import_conv)
    dispatcher.add_handler(MessageHandler(Filters.document.mime_type("application/json"), receive_config_file))
    
    logger.info("ğŸš€ ç»ˆæç‰ˆæœºå™¨äººå·²å¯åŠ¨...")
    updater.start_polling()
    updater.idle()
    logger.info("æœºå™¨äººå·²å…³é—­ã€‚")

if __name__ == "__main__":
    main()

